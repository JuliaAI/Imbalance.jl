{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this installs Julia 1.7\n",
    "%%capture\n",
    "%%shell\n",
    "wget -O - https://raw.githubusercontent.com/JuliaAI/Imbalance.jl/dev/docs/src/examples/colab.sh | bash\n",
    "#This should take around one minute to finish. Once it does, change the runtime to `Julia` by choosing `Runtime` \n",
    "# from the toolbar then `Change runtime type`. You can then delete this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbf3a7",
   "metadata": {},
   "source": [
    "# Balanced Bagging for Cerebral Stroke Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42f0ab84",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import Pkg;\n",
    "Pkg.add([\"Random\", \"CSV\", \"DataFrames\", \"MLJ\", \"Imbalance\", \"MLJBalancing\", \n",
    "         \"ScientificTypes\",\"Impute\", \"StatsBase\",  \"Plots\", \"Measures\", \"HTTP\"])\n",
    "\n",
    "using Random\n",
    "using CSV\n",
    "using DataFrames\n",
    "using MLJ\n",
    "using Imbalance\n",
    "using MLJBalancing\n",
    "using StatsBase\n",
    "using ScientificTypes\n",
    "using Plots, Measures\n",
    "using Impute\n",
    "using HTTP: download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7952e",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "In this example, we will consider the [Cerebral Stroke Prediction Dataset](https://www.kaggle.com/datasets/shashwatwork/cerebral-stroke-predictionimbalaced-dataset) found on Kaggle for the objective of predicting where a stroke has occurred given medical features about patients.\n",
    "\n",
    "`CSV` gives us the ability to easily read the dataset after it's downloaded as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5113b2f",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬─────────┬────────────┬──────────────┬───────────────┬──────────────┬──────────────┬────────────────┬───────────────────┬────────────────────────────┬──────────────────────────┬────────┐\n",
      "│\u001b[1m id    \u001b[0m│\u001b[1m gender  \u001b[0m│\u001b[1m age        \u001b[0m│\u001b[1m hypertension \u001b[0m│\u001b[1m heart_disease \u001b[0m│\u001b[1m ever_married \u001b[0m│\u001b[1m work_type    \u001b[0m│\u001b[1m Residence_type \u001b[0m│\u001b[1m avg_glucose_level \u001b[0m│\u001b[1m bmi                        \u001b[0m│\u001b[1m smoking_status           \u001b[0m│\u001b[1m stroke \u001b[0m│\n",
      "│\u001b[90m Int64 \u001b[0m│\u001b[90m String7 \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Int64        \u001b[0m│\u001b[90m Int64         \u001b[0m│\u001b[90m String3      \u001b[0m│\u001b[90m String15     \u001b[0m│\u001b[90m String7        \u001b[0m│\u001b[90m Float64           \u001b[0m│\u001b[90m Union{Missing, Float64}    \u001b[0m│\u001b[90m Union{Missing, String15} \u001b[0m│\u001b[90m Int64  \u001b[0m│\n",
      "│\u001b[90m Count \u001b[0m│\u001b[90m Textual \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Count        \u001b[0m│\u001b[90m Count         \u001b[0m│\u001b[90m Textual      \u001b[0m│\u001b[90m Textual      \u001b[0m│\u001b[90m Textual        \u001b[0m│\u001b[90m Continuous        \u001b[0m│\u001b[90m Union{Missing, Continuous} \u001b[0m│\u001b[90m Union{Missing, Textual}  \u001b[0m│\u001b[90m Count  \u001b[0m│\n",
      "├───────┼─────────┼────────────┼──────────────┼───────────────┼──────────────┼──────────────┼────────────────┼───────────────────┼────────────────────────────┼──────────────────────────┼────────┤\n",
      "│ 30669 │ Male    │ 3.0        │ 0            │ 0             │ No           │ children     │ Rural          │ 95.12             │ 18.0                       │ missing                  │ 0      │\n",
      "│ 30468 │ Male    │ 58.0       │ 1            │ 0             │ Yes          │ Private      │ Urban          │ 87.96             │ 39.2                       │ never smoked             │ 0      │\n",
      "│ 16523 │ Female  │ 8.0        │ 0            │ 0             │ No           │ Private      │ Urban          │ 110.89            │ 17.6                       │ missing                  │ 0      │\n",
      "│ 56543 │ Female  │ 70.0       │ 0            │ 0             │ Yes          │ Private      │ Rural          │ 69.04             │ 35.9                       │ formerly smoked          │ 0      │\n",
      "│ 46136 │ Male    │ 14.0       │ 0            │ 0             │ No           │ Never_worked │ Rural          │ 161.28            │ 19.1                       │ missing                  │ 0      │\n",
      "└───────┴─────────┴────────────┴──────────────┴───────────────┴──────────────┴──────────────┴────────────────┴───────────────────┴────────────────────────────┴──────────────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "download(\"https://raw.githubusercontent.com/JuliaAI/Imbalance.jl/dev/docs/src/examples/cerebral_ensemble/cerebral.csv\")\n",
    "df = CSV.read(\"./cerebral.csv\", DataFrame)\n",
    "\n",
    "# Display the first 5 rows with DataFrames\n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdb6270",
   "metadata": {},
   "source": [
    "It's obvious that the `id` column is useless for predictions so we may as well drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7afb9b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬────────────┬──────────────┬───────────────┬──────────────┬──────────────┬────────────────┬───────────────────┬────────────────────────────┬──────────────────────────┬────────┐\n",
      "│\u001b[1m gender  \u001b[0m│\u001b[1m age        \u001b[0m│\u001b[1m hypertension \u001b[0m│\u001b[1m heart_disease \u001b[0m│\u001b[1m ever_married \u001b[0m│\u001b[1m work_type    \u001b[0m│\u001b[1m Residence_type \u001b[0m│\u001b[1m avg_glucose_level \u001b[0m│\u001b[1m bmi                        \u001b[0m│\u001b[1m smoking_status           \u001b[0m│\u001b[1m stroke \u001b[0m│\n",
      "│\u001b[90m String7 \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Int64        \u001b[0m│\u001b[90m Int64         \u001b[0m│\u001b[90m String3      \u001b[0m│\u001b[90m String15     \u001b[0m│\u001b[90m String7        \u001b[0m│\u001b[90m Float64           \u001b[0m│\u001b[90m Union{Missing, Float64}    \u001b[0m│\u001b[90m Union{Missing, String15} \u001b[0m│\u001b[90m Int64  \u001b[0m│\n",
      "│\u001b[90m Textual \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Count        \u001b[0m│\u001b[90m Count         \u001b[0m│\u001b[90m Textual      \u001b[0m│\u001b[90m Textual      \u001b[0m│\u001b[90m Textual        \u001b[0m│\u001b[90m Continuous        \u001b[0m│\u001b[90m Union{Missing, Continuous} \u001b[0m│\u001b[90m Union{Missing, Textual}  \u001b[0m│\u001b[90m Count  \u001b[0m│\n",
      "├─────────┼────────────┼──────────────┼───────────────┼──────────────┼──────────────┼────────────────┼───────────────────┼────────────────────────────┼──────────────────────────┼────────┤\n",
      "│ Male    │ 3.0        │ 0            │ 0             │ No           │ children     │ Rural          │ 95.12             │ 18.0                       │ missing                  │ 0      │\n",
      "│ Male    │ 58.0       │ 1            │ 0             │ Yes          │ Private      │ Urban          │ 87.96             │ 39.2                       │ never smoked             │ 0      │\n",
      "│ Female  │ 8.0        │ 0            │ 0             │ No           │ Private      │ Urban          │ 110.89            │ 17.6                       │ missing                  │ 0      │\n",
      "│ Female  │ 70.0       │ 0            │ 0             │ Yes          │ Private      │ Rural          │ 69.04             │ 35.9                       │ formerly smoked          │ 0      │\n",
      "│ Male    │ 14.0       │ 0            │ 0             │ No           │ Never_worked │ Rural          │ 161.28            │ 19.1                       │ missing                  │ 0      │\n",
      "└─────────┴────────────┴──────────────┴───────────────┴──────────────┴──────────────┴────────────────┴───────────────────┴────────────────────────────┴──────────────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "df = df[:, Not(:id)]\n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b4e7a",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "Since this dataset is composed mostly of categorical features, a bar chart for each categorical column is a good way to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e70ef0",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar chart for each column\n",
    "bar_charts = []\n",
    "for col in names(df)\n",
    " counts = countmap(df[!, col])\n",
    "  k, v = collect(keys(counts)), collect(values(counts))\n",
    "   if length(k) < 20\n",
    "     push!(bar_charts, bar(k, v, legend=false, title=col, color=\"turquoise3\", xrotation=90, margin=6mm))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Combine bar charts into a grid layout with specified plot size\n",
    "plot_res = plot(bar_charts..., layout=(3, 4),\n",
    "                size=(1300, 500),\n",
    "                dpi=200\n",
    "                )\n",
    "savefig(plot_res, \"./assets/cerebral-charts.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f43217",
   "metadata": {},
   "source": [
    "![Mushroom Features Plots](./assets/cerebral-charts.png)\n",
    "\n",
    "Our target her is the `Stroke` variable; notice how imbalanced it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7eea8",
   "metadata": {},
   "source": [
    "## Coercing Data\n",
    "Typical models from `MLJ` assume that elements in each column of a table have some `scientific type` as defined by the [ScientificTypes.jl](https://juliaai.github.io/ScientificTypes.jl/dev/) package. It's often necessary to coerce the types found by default to the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbabcca7",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────────┬────────────────────────────┬──────────────────────────┐\n",
       "│\u001b[22m names             \u001b[0m│\u001b[22m scitypes                   \u001b[0m│\u001b[22m types                    \u001b[0m│\n",
       "├───────────────────┼────────────────────────────┼──────────────────────────┤\n",
       "│ gender            │ Textual                    │ String7                  │\n",
       "│ age               │ Continuous                 │ Float64                  │\n",
       "│ hypertension      │ Count                      │ Int64                    │\n",
       "│ heart_disease     │ Count                      │ Int64                    │\n",
       "│ ever_married      │ Textual                    │ String3                  │\n",
       "│ work_type         │ Textual                    │ String15                 │\n",
       "│ Residence_type    │ Textual                    │ String7                  │\n",
       "│ avg_glucose_level │ Continuous                 │ Float64                  │\n",
       "│ bmi               │ Union{Missing, Continuous} │ Union{Missing, Float64}  │\n",
       "│ smoking_status    │ Union{Missing, Textual}    │ Union{Missing, String15} │\n",
       "│ stroke            │ Count                      │ Int64                    │\n",
       "└───────────────────┴────────────────────────────┴──────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ScientificTypes.schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0603ea",
   "metadata": {},
   "source": [
    "For instance, here we need to coerce all the data to `Multiclass` as they are all nominal variables except for `Age`, `avg_glucose_level` and `bmi` which we can treat as continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5a694ab8",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────────┬───────────────┬────────────────────────────────────┐\n",
       "│\u001b[22m names             \u001b[0m│\u001b[22m scitypes      \u001b[0m│\u001b[22m types                              \u001b[0m│\n",
       "├───────────────────┼───────────────┼────────────────────────────────────┤\n",
       "│ gender            │ Multiclass{3} │ CategoricalValue{String7, UInt32}  │\n",
       "│ age               │ Continuous    │ Float64                            │\n",
       "│ hypertension      │ Multiclass{2} │ CategoricalValue{Int64, UInt32}    │\n",
       "│ heart_disease     │ Multiclass{2} │ CategoricalValue{Int64, UInt32}    │\n",
       "│ ever_married      │ Multiclass{2} │ CategoricalValue{String3, UInt32}  │\n",
       "│ work_type         │ Multiclass{5} │ CategoricalValue{String15, UInt32} │\n",
       "│ Residence_type    │ Multiclass{2} │ CategoricalValue{String7, UInt32}  │\n",
       "│ avg_glucose_level │ Continuous    │ Float64                            │\n",
       "│ bmi               │ Continuous    │ Float64                            │\n",
       "│ smoking_status    │ Multiclass{3} │ CategoricalValue{String15, UInt32} │\n",
       "│ stroke            │ Multiclass{2} │ CategoricalValue{Int64, UInt32}    │\n",
       "└───────────────────┴───────────────┴────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = coerce(df, :gender => Multiclass, :age => Continuous, :hypertension => Multiclass,\n",
    "\t:heart_disease => Multiclass, :ever_married => Multiclass, :work_type => Multiclass,\n",
    "\t:Residence_type => Multiclass, :avg_glucose_level => Continuous,\n",
    "\t:bmi => Continuous, :smoking_status => Multiclass, :stroke => Multiclass,\n",
    ")\n",
    "ScientificTypes.schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f6c170",
   "metadata": {},
   "source": [
    "As shown in the types, some columns have missing values we will impute them using simple random sampling as dropping their rows would mean that we lose a big chunk of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61c700f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────────────────┬────────────┬─────────────────────────────────┬─────────────────────────────────┬───────────────────────────────────┬────────────────────────────────────┬───────────────────────────────────┬───────────────────┬────────────┬────────────────────────────────────┬─────────────────────────────────┐\n",
      "│\u001b[1m gender                            \u001b[0m│\u001b[1m age        \u001b[0m│\u001b[1m hypertension                    \u001b[0m│\u001b[1m heart_disease                   \u001b[0m│\u001b[1m ever_married                      \u001b[0m│\u001b[1m work_type                          \u001b[0m│\u001b[1m Residence_type                    \u001b[0m│\u001b[1m avg_glucose_level \u001b[0m│\u001b[1m bmi        \u001b[0m│\u001b[1m smoking_status                     \u001b[0m│\u001b[1m stroke                          \u001b[0m│\n",
      "│\u001b[90m CategoricalValue{String7, UInt32} \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m CategoricalValue{Int64, UInt32} \u001b[0m│\u001b[90m CategoricalValue{Int64, UInt32} \u001b[0m│\u001b[90m CategoricalValue{String3, UInt32} \u001b[0m│\u001b[90m CategoricalValue{String15, UInt32} \u001b[0m│\u001b[90m CategoricalValue{String7, UInt32} \u001b[0m│\u001b[90m Float64           \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m CategoricalValue{String15, UInt32} \u001b[0m│\u001b[90m CategoricalValue{Int64, UInt32} \u001b[0m│\n",
      "│\u001b[90m Multiclass{3}                     \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Multiclass{2}                   \u001b[0m│\u001b[90m Multiclass{2}                   \u001b[0m│\u001b[90m Multiclass{2}                     \u001b[0m│\u001b[90m Multiclass{5}                      \u001b[0m│\u001b[90m Multiclass{2}                     \u001b[0m│\u001b[90m Continuous        \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Multiclass{3}                      \u001b[0m│\u001b[90m Multiclass{2}                   \u001b[0m│\n",
      "├───────────────────────────────────┼────────────┼─────────────────────────────────┼─────────────────────────────────┼───────────────────────────────────┼────────────────────────────────────┼───────────────────────────────────┼───────────────────┼────────────┼────────────────────────────────────┼─────────────────────────────────┤\n",
      "│ Male                              │ 3.0        │ 0                               │ 0                               │ No                                │ children                           │ Rural                             │ 95.12             │ 18.0       │ formerly smoked                    │ 0                               │\n",
      "│ Male                              │ 58.0       │ 1                               │ 0                               │ Yes                               │ Private                            │ Urban                             │ 87.96             │ 39.2       │ never smoked                       │ 0                               │\n",
      "│ Female                            │ 8.0        │ 0                               │ 0                               │ No                                │ Private                            │ Urban                             │ 110.89            │ 17.6       │ never smoked                       │ 0                               │\n",
      "│ Female                            │ 70.0       │ 0                               │ 0                               │ Yes                               │ Private                            │ Rural                             │ 69.04             │ 35.9       │ formerly smoked                    │ 0                               │\n",
      "│ Male                              │ 14.0       │ 0                               │ 0                               │ No                                │ Never_worked                       │ Rural                             │ 161.28            │ 19.1       │ formerly smoked                    │ 0                               │\n",
      "└───────────────────────────────────┴────────────┴─────────────────────────────────┴─────────────────────────────────┴───────────────────────────────────┴────────────────────────────────────┴───────────────────────────────────┴───────────────────┴────────────┴────────────────────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = Impute.srs(df); disallowmissing!(df)\n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222f3e8",
   "metadata": {},
   "source": [
    "## Unpacking and Splitting Data\n",
    "\n",
    "Both `MLJ` and the pure functional interface of `Imbalance` assume that the observations table `X` and target vector `y` are separate. We can accomplish that by using `unpack` from `MLJ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e2cccaa",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────────────────┬────────────┬─────────────────────────────────┬─────────────────────────────────┬───────────────────────────────────┬────────────────────────────────────┬───────────────────────────────────┬───────────────────┬────────────┬────────────────────────────────────┐\n",
      "│\u001b[1m gender                            \u001b[0m│\u001b[1m age        \u001b[0m│\u001b[1m hypertension                    \u001b[0m│\u001b[1m heart_disease                   \u001b[0m│\u001b[1m ever_married                      \u001b[0m│\u001b[1m work_type                          \u001b[0m│\u001b[1m Residence_type                    \u001b[0m│\u001b[1m avg_glucose_level \u001b[0m│\u001b[1m bmi        \u001b[0m│\u001b[1m smoking_status                     \u001b[0m│\n",
      "│\u001b[90m CategoricalValue{String7, UInt32} \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m CategoricalValue{Int64, UInt32} \u001b[0m│\u001b[90m CategoricalValue{Int64, UInt32} \u001b[0m│\u001b[90m CategoricalValue{String3, UInt32} \u001b[0m│\u001b[90m CategoricalValue{String15, UInt32} \u001b[0m│\u001b[90m CategoricalValue{String7, UInt32} \u001b[0m│\u001b[90m Float64           \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m CategoricalValue{String15, UInt32} \u001b[0m│\n",
      "│\u001b[90m Multiclass{3}                     \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Multiclass{2}                   \u001b[0m│\u001b[90m Multiclass{2}                   \u001b[0m│\u001b[90m Multiclass{2}                     \u001b[0m│\u001b[90m Multiclass{5}                      \u001b[0m│\u001b[90m Multiclass{2}                     \u001b[0m│\u001b[90m Continuous        \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Multiclass{3}                      \u001b[0m│\n",
      "├───────────────────────────────────┼────────────┼─────────────────────────────────┼─────────────────────────────────┼───────────────────────────────────┼────────────────────────────────────┼───────────────────────────────────┼───────────────────┼────────────┼────────────────────────────────────┤\n",
      "│ Female                            │ 37.0       │ 0                               │ 0                               │ Yes                               │ Private                            │ Urban                             │ 103.66            │ 36.1       │ smokes                             │\n",
      "│ Female                            │ 78.0       │ 0                               │ 0                               │ No                                │ Private                            │ Rural                             │ 83.97             │ 39.6       │ formerly smoked                    │\n",
      "│ Female                            │ 2.0        │ 0                               │ 0                               │ No                                │ children                           │ Urban                             │ 98.66             │ 17.0       │ smokes                             │\n",
      "│ Female                            │ 62.0       │ 0                               │ 0                               │ No                                │ Private                            │ Rural                             │ 205.41            │ 27.8       │ smokes                             │\n",
      "│ Male                              │ 14.0       │ 0                               │ 0                               │ No                                │ Private                            │ Rural                             │ 118.18            │ 24.5       │ never smoked                       │\n",
      "└───────────────────────────────────┴────────────┴─────────────────────────────────┴─────────────────────────────────┴───────────────────────────────────┴────────────────────────────────────┴───────────────────────────────────┴───────────────────┴────────────┴────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "y, X = unpack(df, ==(:stroke); rng=123);\n",
    "first(X, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f96987",
   "metadata": {},
   "source": [
    "Splitting the data into train and test portions is also easy using `MLJ`'s `partition` function. `stratify=y` guarantees that the data is distributed in the same proportions as the original dataset in both splits which is more representative of the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f3564",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "(X_train, X_test), (y_train, y_test) = partition(\n",
    "\t(X, y),\n",
    "\t0.8,\n",
    "\tmulti = true,\n",
    "\tshuffle = true,\n",
    "\tstratify = y,\n",
    "\trng = Random.Xoshiro(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c41cc39",
   "metadata": {},
   "source": [
    "⚠️ Always split the data before oversampling. If your test data has oversampled observations then train-test contamination has occurred; novel observations will not come from the oversampling function.\n",
    "\n",
    "## Oversampling\n",
    "\n",
    "\n",
    "\n",
    "It was obvious from the bar charts that there is a severe imbalance problem. Let's look at that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e4d51b0",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ▇ 783 (1.8%) \n",
      "0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 42617 (100.0%) \n"
     ]
    }
   ],
   "source": [
    "checkbalance(y)         # comes from Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f38fd0",
   "metadata": {},
   "source": [
    "Indeed, may be too severe for most models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4010523",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "\n",
    "\n",
    "Because we have scientific types setup, we can easily check what models will be able to train on our data. This should guarantee that the model we choose won't throw an error due to types after feeding it the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2099caba",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n",
       " (name = CatBoostClassifier, package_name = CatBoost, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = BetaML, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = OneRuleClassifier, package_name = OneRule, ... )\n",
       " (name = RandomForestClassifier, package_name = BetaML, ... )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ms = models(matching(Xover, yover))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5cb35",
   "metadata": {},
   "source": [
    "Let's go for a `DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4845a7d",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJBalancing ─ v0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Documents/GitHub/Imbalance.jl/docs/Project.toml`\n",
      " \u001b[90m [45f359ea] \u001b[39m\u001b[92m+ MLJBalancing v0.1.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Documents/GitHub/Imbalance.jl/docs/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \u001b[90m [45f359ea] \u001b[39m\u001b[92m+ MLJBalancing v0.1.0\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mMLJBalancing\n",
      "  1 dependency successfully precompiled in 25 seconds. 262 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"BetaML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b0ffc",
   "metadata": {},
   "source": [
    "#### Load and Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0fed8ffe",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import BetaML ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/essam/.julia/packages/MLJModels/EkXIe/src/loading.jl:159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "  max_depth = 4, \n",
       "  min_gain = 0.0, \n",
       "  min_records = 2, \n",
       "  max_features = 0, \n",
       "  splitting_criterion = BetaML.Utils.gini, \n",
       "  rng = Random._GLOBAL_RNG())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load the model\n",
    "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=BetaML\n",
    "\n",
    "# 2. Instantiate it\n",
    "model = DecisionTreeClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5769e",
   "metadata": {},
   "source": [
    "#### Wrap in a machine and fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cb46f370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: DecisionTreeClassifier(max_depth = 4, …)\n",
       "  args: \n",
       "    1:\tSource @245 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{5}}, AbstractVector{Multiclass{2}}, AbstractVector{Multiclass{3}}}}\n",
       "    2:\tSource @251 ⏎ AbstractVector{Multiclass{2}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Wrap it with the data in a machine\n",
    "mach = machine(model, X_train, y_train)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach, verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c312617",
   "metadata": {},
   "source": [
    "#### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "36087524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = MLJ.predict_mode(mach, X_test)                         \n",
    "\n",
    "score = round(balanced_accuracy(y_pred, y_test), digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b043cc",
   "metadata": {},
   "source": [
    "## Training BalancedBagging Model\n",
    "\n",
    "The results suggest that the model is just as good as random guessing. Let's see if this gets better by using a `BalancedBaggingClassifier`. This classifier trains `T` of the given `model` on `T` undersampled versions of the dataset where in each undersampled version there are as much majority examples as there are minority examples.\n",
    "\n",
    "This approach can allow us to workaround the imbalance issue without losing any data. For instance, if we set `T=Int(100/1.8)` (which is the default) then on average all majority examples will be used in one of the `T` bags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b8f39",
   "metadata": {},
   "source": [
    "#### Load and Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fc8141b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedBaggingClassifier(\n",
       "  model = DecisionTreeClassifier(\n",
       "        max_depth = 4, \n",
       "        min_gain = 0.0, \n",
       "        min_records = 2, \n",
       "        max_features = 0, \n",
       "        splitting_criterion = BetaML.Utils.gini, \n",
       "        rng = Random._GLOBAL_RNG()), \n",
       "  T = 30, \n",
       "  rng = Xoshiro(0xa379de7eeeb2a4e8, 0x953dccb6b532b3af, 0xf597b8ff8cfd652a, 0xccd7337c571680d1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bagging_model = BalancedBaggingClassifier(model=model, T=30, rng=Random.Xoshiro(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b73c3",
   "metadata": {},
   "source": [
    "#### Wrap in a machine and fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "532b06b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trained Machine; does not cache data\n",
       "  model: BalancedBaggingClassifier(model = DecisionTreeClassifier(max_depth = 4, …), …)\n",
       "  args: \n",
       "    1:\tSource @005 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{5}}, AbstractVector{Multiclass{2}}, AbstractVector{Multiclass{3}}}}\n",
       "    2:\tSource @531 ⏎ AbstractVector{Multiclass{2}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Wrap it with the data in a machine\n",
    "mach_over = machine(bagging_model, X_train, y_train)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach_over, verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab476b",
   "metadata": {},
   "source": [
    "#### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1fad054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = MLJ.predict_mode(mach_over, X_test)                         \n",
    "\n",
    "score = round(balanced_accuracy(y_pred, y_test), digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075c422",
   "metadata": {},
   "source": [
    "This is a dramatic improvement over what we had before. Let's confirm with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "30747fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  20%[=====>                   ]  ETA: 0:01:23\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  30%[=======>                 ]  ETA: 0:01:13\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  40%[==========>              ]  ETA: 0:01:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  50%[============>            ]  ETA: 0:00:51\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  60%[===============>         ]  ETA: 0:00:40\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  70%[=================>       ]  ETA: 0:00:30\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  80%[====================>    ]  ETA: 0:00:20\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  90%[======================>  ]  ETA: 0:00:10\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds: 100%[=========================] Time: 0:01:40\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  model, measure, operation, measurement, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_rows, resampling, repeats\n",
       "Extract:\n",
       "┌─────────────────────┬──────────────┬─────────────┬─────────┬──────────────────\n",
       "│\u001b[22m measure             \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\u001b[22m per_fold       \u001b[0m ⋯\n",
       "├─────────────────────┼──────────────┼─────────────┼─────────┼──────────────────\n",
       "│ BalancedAccuracy(   │ predict_mode │ 0.772       │ 0.0146  │ [0.738, 0.769,  ⋯\n",
       "│   adjusted = false) │              │             │         │                 ⋯\n",
       "└─────────────────────┴──────────────┴─────────────┴─────────┴──────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv=CV(nfolds=10)\n",
    "evaluate!(mach_over, resampling=cv, measure=balanced_accuracy, operation=predict_mode) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4de9b",
   "metadata": {},
   "source": [
    "Under the normality of scores, the `95%` confidence interval is `77.2±1.4%` for the balanced accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881967ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook cerebral_ensemble.ipynb to markdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied cerebral-charts.png to ../assets/cerebral-charts.png\n",
      "Conversion Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Writing 26298 bytes to cerebral_ensemble.md\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "from convert import convert_to_md\n",
    "convert_to_md('cerebral_ensemble')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
