@Inbook{Cunningham:2008,
author="Cunningham, P{\'a}draig
and Cord, Matthieu
and Delany, Sarah Jane",
editor="Cord, Matthieu
and Cunningham, P{\'a}draig",
title="Supervised Learning",
bookTitle="Machine Learning Techniques for Multimedia: Case Studies on Organization and Retrieval",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="21--49",
abstract="Supervised learning accounts for a lot of research activity in machine learning and many supervised learning techniques have found application in the processing of multimedia content. The defining characteristic of supervised learning is the availability of annotated training data. The name invokes the idea of a `supervisor' that instructs the learning system on the labels to associate with training examples. Typically these labels are class labels in classification problems. Supervised learning algorithms induce models from these training data and these models can be used to classify other unlabelled data. In this chapter we ground or analysis of supervised learning on the theory of risk minimization. We provide an overview of support vector machines and nearest neighbour classifiers{\textasciitilde}-- probably the two most popular supervised learning techniques employed in multimedia research.",
isbn="978-3-540-75171-7",
doi="10.1007/978-3-540-75171-7_2",
url="https://doi.org/10.1007/978-3-540-75171-7_2"
}

@inproceedings{Ali:2015,
  title={Classification with class imbalance problem: A review},
  author={Aida Ali and Siti Mariyam Hj. Shamsuddin and Anca L. Ralescu},
  booktitle={Soft Computing Models in Industrial and Environmental Applications},
  year={2015},
  url={https://api.semanticscholar.org/CorpusID:26644563}
}

@article{Zeng:2016,
  title={Effective prediction of three common diseases by combining SMOTE with Tomek links technique for imbalanced medical data},
  author={Min Zeng and Beiji Zou and Faran Wei and Xiyao Liu and Lei Wang},
  journal={2016 IEEE International Conference of Online Analysis and Computing Science (ICOACS)},
  doi={10.1109/ICOACS.2016.7563084},
  year={2016},
  pages={225-228},
  url={https://api.semanticscholar.org/CorpusID:25184489}
}


@article{Liu:2009,
  title={Exploratory Undersampling for Class-Imbalance Learning},
  author={Xu-Ying Liu and Jianxin Wu and Zhi-Hua Zhou},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  doi={10.1109/TSMCB.2008.2007853},
  year={2009},
  volume={39},
  pages={539-550},
  url={https://api.semanticscholar.org/CorpusID:62808464}
}

@article{Picek:2018,
  title={The Curse of Class Imbalance and Conflicting Metrics with Machine Learning for Side-channel Evaluations},
  author={Stjepan Picek and Annelie Heuser and Alan Jovi{\'c} and Shivam Bhasin and Francesco Regazzoni},
  journal={IACR Trans. Cryptogr. Hardw. Embed. Syst.},
  doi={10.13154/tches.v2019.i1.209-237},
  year={2018},
  volume={2019},
  pages={209-237},
  url={https://api.semanticscholar.org/CorpusID:44136202}
}


@inproceedings{Kubt:1997,
  title={Addressing the Curse of Imbalanced Training Sets: One-Sided Selection},
  author={Miroslav Kub{\'a}t and Stan Matwin},
  booktitle={International Conference on Machine Learning},
  year={1997},
  url={https://api.semanticscholar.org/CorpusID:18370956}
}

@article{Chawla:2002,
  title={SMOTE: Synthetic Minority Over-sampling Technique},
  author={N. Chawla and K. Bowyer and Lawrence O. Hall and W. Philip Kegelmeyer},
  doi={10.1613/jair.953},
  journal={ArXiv},
  year={2002},
  volume={abs/1106.1813},
  url={https://api.semanticscholar.org/CorpusID:1554582}
}


@inproceedings{Han:2005,
  title={Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning},
  author={Hui Han and Wenyuan Wang and Binghuan Mao},
  booktitle={International Conference on Intelligent Computing},
  doi={10.1007/11538059_91},
  year={2005},
  url={https://api.semanticscholar.org/CorpusID:12126950}
}

@article{Zhang:2014,
  title={RWO-Sampling: A random walk over-sampling approach to imbalanced data classification},
  author={Huaxiang Zhang and Mingfang Li},
  journal={Inf. Fusion},
  year={2014},
  volume={20},
  doi={10.1016/j.inffus.2013.12.003},
  pages={99-116},
  url={https://api.semanticscholar.org/CorpusID:205432428}
}


@article{Menardi:2012,
  title={Training and assessing classification rules with imbalanced data},
  author={Giovanna Menardi and Nicola Torelli},
  journal={Data Mining and Knowledge Discovery},
  year={2012},
  volume={28},
  doi={10.1007/s10618-012-0295-5},
  pages={92-122},
  url={https://api.semanticscholar.org/CorpusID:18164904}
}

@article{Lin:2016,
  title={Clustering-based undersampling in class-imbalanced data},
  author={Wei-Chao Lin and Chih-Fong Tsai and Ya-Han Hu and Jing-Shang Jhang},
  journal={Inf. Sci.},
  doi={10.1016/j.ins.2017.05.008},
  year={2016},
  volume={409},
  pages={17-26},
  url={https://api.semanticscholar.org/CorpusID:424467}
}


@article{Hart:1968,
  title={The condensed nearest neighbor rule (Corresp.)},
  author={Peter E. Hart},
  journal={IEEE Trans. Inf. Theory},
  year={1968},
  doi={10.1109/TIT.1968.1054155},
  volume={14},
  pages={515-516},
  url={https://api.semanticscholar.org/CorpusID:206729609}
}

@article{Lematre:2016,
  title={Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
  author={Guillaume Lema{\^i}tre and Fernando Nogueira and Christos K. Aridas},
  journal={ArXiv},
  year={2016},
  volume={abs/1609.06570},
  url={https://api.semanticscholar.org/CorpusID:1426815}
}


@article{Kovács:2019,
title = {Smote-variants: A python implementation of 85 minority oversampling techniques},
journal = {Neurocomputing},
volume = {366},
pages = {352-354},
year = {2019},
issn = {0925-2312},
doi = {10.1016/j.neucom.2019.06.100},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219311622},
author = {György Kovács},
keywords = {Imbalanced learning, SMOTE, Synthetic minority oversampling, Python, Smote-variants},
abstract = {Imbalanced classification problems are definitely around He and Gracia (2009), and a successful approach to avoid the overfitting of majority classes is the synthetic generation of minority training samples Fernandez et al. (2018). Despite the large number of minority oversampling algorithms proposed, open source implementations are available for only a handful of techniques. The package smote-variants provides a Python implementation of 85 oversampling techniques to boost the applications and development in the field of imbalanced learning. The source code, documentation and examples are available in the GitHub repository http://github.com/gykovacs/smote_variants/.}
}

@online{DataCamp:2023,
  author = {Bekhruz Tuychiev},
  title = {The Rise of Julia},
  year = {2023},
  url = {https://www.datacamp.com/blog/the-rise-of-julia-is-it-worth-learning-in-2022},
  note = {Accessed on Oct 11, 2023}
}


@article{Fernández:2013,
  title={Analysing the classification of imbalanced data-sets with multiple classes: Binarization techniques and ad-hoc approaches},
  author={Alberto Fern{\'a}ndez and Victoria L{\'o}pez and Mikel Galar and Mar{\'i}a Jos{\'e} del Jes{\'u}s and Francisco Herrera},
  journal={Knowl. Based Syst.},
  doi={10.1016/J.KNOSYS.2013.01.018},
  year={2013},
  volume={42},
  pages={97-110},
  url={https://api.semanticscholar.org/CorpusID:131286}
}