var documenterSearchIndex = {"docs":
[{"location":"contributing/#Directory-Structure","page":"Contributing","title":"Directory Structure","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"The folder structure is as follows:","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":".\n├── Imbalance.jl             # entry point to package\n├── generic_oversample.jl    # used in all resampling methods\n├── generic_encoder.jl       # used in all resampling methods that deal with categorical data\n├── table_wrappers.jl        # generalizes a function that operates on matrices to tables\n├── class_counts.jl          # used to compute number of data points to add\n├── resample_method          # contains implementation and interface for a resampling method\n│   ├── interface_mlj.jl     # implements MLJ interface for the method\n│   ├── interface_tables.jl  # implements Tables.jl interface for the method\n│   └── resample_method.jl   # implements the method itself\n├── common_smote.jl          # implementation functions shared by different variants of SMOTE\n├── commondocs.jl            # documentation that is common over many functions\n├── errors.jl                # any error or warning used in the package\n├── utils.jl                 # utility functions \n└── mlj_interface.jl         # registers metadata for the MLJ interface of each method","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"The purpose of each file is further documented therein at the beginning of the file. The files are ordered here in the recommended order of checking.","category":"page"},{"location":"contributing/#Adding-New-Resampling-Methods","page":"Contributing","title":"Adding New Resampling Methods","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Make a new folder resample_method for the method\nImplement in resample_method/resample_method.jl the method over matrices for one minority class (else skip next step if that's not possible) and document implemented functions\nUse generic_oversample.jl to generalize it to work on the whole data\nUse table_wrapper.jl to generalize the method to work on tables and possibly generic_encoder.jl\nMake a test file test/resample_method.jl and test the implemented functions\nImplement the MLJ interface for the method in resample_method/interface_mlj\nImplement the TableTransforms interface for the method in resample_method/interface_tables.jl\nUse the rest of the files according to their description","category":"page"},{"location":"contributing/#Adding-New-Tutorials","page":"Contributing","title":"Adding New Tutorials","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Make a new notebook with the tutorial in the examples folder\nRun the notebook so that the output is shown below each cell\nIf the notebook produces visuals then save and load them in the notebook\nRun the Python script found in the last cell of other tutorials. Now it's in the docs folder in markdown\nSet a title, description, image and links for it in the dictionary found in docs/examples.jl\nFor the colab link, you do not need to upload anything just follow the link pattern in the file","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"using Random\nusing CSV\nusing DataFrames\nusing MLJ\nusing Imbalance\nusing ScientificTypes\nusing Plots\nusing StatsBase","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Loading-Data","page":"-","title":"Loading Data","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"In this example, we will consider the Mushroom dataset found on Kaggle for the objective of predicting mushroom odour given various features about the mushroom.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"CSV gives us the ability to easily read the dataset after it's downloaded as follows","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"df = CSV.read(\"../datasets/mushrooms.csv\", DataFrame)\n\n# Display the first 5 rows with DataFrames\nfirst(df, 5) |> pretty","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"┌─────────┬───────────┬─────────────┬───────────┬─────────┬─────────┬─────────────────┬──────────────┬───────────┬────────────┬─────────────┬────────────┬──────────────────────────┬──────────────────────────┬────────────────────────┬────────────────────────┬───────────┬────────────┬─────────────┬───────────┬───────────────────┬────────────┬─────────┐\n│ class   │ cap-shape │ cap-surface │ cap-color │ bruises │ odor    │ gill-attachment │ gill-spacing │ gill-size │ gill-color │ stalk-shape │ stalk-root │ stalk-surface-above-ring │ stalk-surface-below-ring │ stalk-color-above-ring │ stalk-color-below-ring │ veil-type │ veil-color │ ring-number │ ring-type │ spore-print-color │ population │ habitat │\n│ String1 │ String1   │ String1     │ String1   │ String1 │ String1 │ String1         │ String1      │ String1   │ String1    │ String1     │ String1    │ String1                  │ String1                  │ String1                │ String1                │ String1   │ String1    │ String1     │ String1   │ String1           │ String1    │ String1 │\n│ Textual │ Textual   │ Textual     │ Textual   │ Textual │ Textual │ Textual         │ Textual      │ Textual   │ Textual    │ Textual     │ Textual    │ Textual                  │ Textual                  │ Textual                │ Textual                │ Textual   │ Textual    │ Textual     │ Textual   │ Textual           │ Textual    │ Textual │\n├─────────┼───────────┼─────────────┼───────────┼─────────┼─────────┼─────────────────┼──────────────┼───────────┼────────────┼─────────────┼────────────┼──────────────────────────┼──────────────────────────┼────────────────────────┼────────────────────────┼───────────┼────────────┼─────────────┼───────────┼───────────────────┼────────────┼─────────┤\n│ p       │ x         │ s           │ n         │ t       │ p       │ f               │ c            │ n         │ k          │ e           │ e          │ s                        │ s                        │ w                      │ w                      │ p         │ w          │ o           │ p         │ k                 │ s          │ u       │\n│ e       │ x         │ s           │ y         │ t       │ a       │ f               │ c            │ b         │ k          │ e           │ c          │ s                        │ s                        │ w                      │ w                      │ p         │ w          │ o           │ p         │ n                 │ n          │ g       │\n│ e       │ b         │ s           │ w         │ t       │ l       │ f               │ c            │ b         │ n          │ e           │ c          │ s                        │ s                        │ w                      │ w                      │ p         │ w          │ o           │ p         │ n                 │ n          │ m       │\n│ p       │ x         │ y           │ w         │ t       │ p       │ f               │ c            │ n         │ n          │ e           │ e          │ s                        │ s                        │ w                      │ w                      │ p         │ w          │ o           │ p         │ k                 │ s          │ u       │\n│ e       │ x         │ s           │ g         │ f       │ n       │ f               │ w            │ b         │ k          │ t           │ e          │ s                        │ s                        │ w                      │ w                      │ p         │ w          │ o           │ e         │ n                 │ a          │ g       │\n└─────────┴───────────┴─────────────┴───────────┴─────────┴─────────┴─────────────────┴──────────────┴───────────┴────────────┴─────────────┴────────────┴──────────────────────────┴──────────────────────────┴────────────────────────┴────────────────────────┴───────────┴────────────┴─────────────┴───────────┴───────────────────┴────────────┴─────────┘","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Visualize-the-Data","page":"-","title":"Visualize the Data","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Since this dataset is composed only of categorical features, a bar chart for each column is a good way to visualize the data.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"# Create a bar chart for each column\nbar_charts = []\nfor col in names(df)\n    counts = countmap(df[!, col])\n    k, v = collect(keys(counts)), collect(values(counts))\n    if length(k) < 20\n        push!(bar_charts, bar(k, v, legend=false, title=col))\n    end\nend\n\n# Combine bar charts into a grid layout with specified plot size\nplot_res = plot(bar_charts..., layout=(5, 5), \n                size=(1300, 1200), \n                plot_title=\"Value Frequencies for each Categorical Variable\")\nsavefig(plot_res, \"./mushroom-bar-charts.png\")","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"<img src=\"./mushroom-bar-charts.png\" />","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"We will take the mushroom odour as our target and all the rest as features. ","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Coercing-Data","page":"-","title":"Coercing Data","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Typical models from MLJ assume that elements in each column of a table have some scientific type as defined by the ScientificTypes.jl package. It's often necessary to coerce the types inferred by default to the appropriate type.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"ScientificTypes.schema(df)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"┌──────────────────────────┬──────────┬─────────┐\n│ names                    │ scitypes │ types   │\n├──────────────────────────┼──────────┼─────────┤\n│ class                    │ Textual  │ String1 │\n│ cap-shape                │ Textual  │ String1 │\n│ cap-surface              │ Textual  │ String1 │\n│ cap-color                │ Textual  │ String1 │\n│ bruises                  │ Textual  │ String1 │\n│ odor                     │ Textual  │ String1 │\n│ gill-attachment          │ Textual  │ String1 │\n│ gill-spacing             │ Textual  │ String1 │\n│ gill-size                │ Textual  │ String1 │\n│ gill-color               │ Textual  │ String1 │\n│ stalk-shape              │ Textual  │ String1 │\n│ stalk-root               │ Textual  │ String1 │\n│ stalk-surface-above-ring │ Textual  │ String1 │\n│ stalk-surface-below-ring │ Textual  │ String1 │\n│ stalk-color-above-ring   │ Textual  │ String1 │\n│ stalk-color-below-ring   │ Textual  │ String1 │\n│            ⋮             │    ⋮     │    ⋮    │\n└──────────────────────────┴──────────┴─────────┘\n                                   7 rows omitted","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"For instance, here we need to coerce all the data to Multiclass as they are all nominal variables. Textual would be the right type for natural language processing models. Instead of typing in each column manually, autotype lets us perform mass conversion using pre-defined rules.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"df = coerce(df, autotype(df, :few_to_finite))\nScientificTypes.schema(df)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"┌──────────────────────────┬────────────────┬───────────────────────────────────\n│ names                    │ scitypes       │ types                            ⋯\n├──────────────────────────┼────────────────┼───────────────────────────────────\n│ class                    │ Multiclass{2}  │ CategoricalValue{String1, UInt32 ⋯\n│ cap-shape                │ Multiclass{6}  │ CategoricalValue{String1, UInt32 ⋯\n│ cap-surface              │ Multiclass{4}  │ CategoricalValue{String1, UInt32 ⋯\n│ cap-color                │ Multiclass{10} │ CategoricalValue{String1, UInt32 ⋯\n│ bruises                  │ Multiclass{2}  │ CategoricalValue{String1, UInt32 ⋯\n│ odor                     │ Multiclass{9}  │ CategoricalValue{String1, UInt32 ⋯\n│ gill-attachment          │ Multiclass{2}  │ CategoricalValue{String1, UInt32 ⋯\n│ gill-spacing             │ Multiclass{2}  │ CategoricalValue{String1, UInt32 ⋯\n│ gill-size                │ Multiclass{2}  │ CategoricalValue{String1, UInt32 ⋯\n│ gill-color               │ Multiclass{12} │ CategoricalValue{String1, UInt32 ⋯\n│ stalk-shape              │ Multiclass{2}  │ CategoricalValue{String1, UInt32 ⋯\n│ stalk-root               │ Multiclass{5}  │ CategoricalValue{String1, UInt32 ⋯\n│ stalk-surface-above-ring │ Multiclass{4}  │ CategoricalValue{String1, UInt32 ⋯\n│ stalk-surface-below-ring │ Multiclass{4}  │ CategoricalValue{String1, UInt32 ⋯\n│ stalk-color-above-ring   │ Multiclass{9}  │ CategoricalValue{String1, UInt32 ⋯\n│ stalk-color-below-ring   │ Multiclass{9}  │ CategoricalValue{String1, UInt32 ⋯\n│            ⋮             │       ⋮        │                 ⋮                ⋱\n└──────────────────────────┴────────────────┴───────────────────────────────────\n                                                     1 column and 7 rows omitted","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Unpacking-and-Splitting-Data","page":"-","title":"Unpacking and Splitting Data","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Both MLJ and the pure functional interface of Imbalance assume that the observations table X and target vector y are separate. We can accomplish that by using unpack from MLJ","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"y, X = unpack(df, ==(:odor); rng=123);\nfirst(X, 5) |> pretty","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"┌───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┐\n│ class                             │ cap-shape                         │ cap-surface                       │ cap-color                         │ bruises                           │ gill-attachment                   │ gill-spacing                      │ gill-size                         │ gill-color                        │ stalk-shape                       │ stalk-root                        │ stalk-surface-above-ring          │ stalk-surface-below-ring          │ stalk-color-above-ring            │ stalk-color-below-ring            │ veil-type                         │ veil-color                        │ ring-number                       │ ring-type                         │ spore-print-color                 │ population                        │ habitat                           │\n│ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │ CategoricalValue{String1, UInt32} │\n│ Multiclass{2}                     │ Multiclass{6}                     │ Multiclass{4}                     │ Multiclass{10}                    │ Multiclass{2}                     │ Multiclass{2}                     │ Multiclass{2}                     │ Multiclass{2}                     │ Multiclass{12}                    │ Multiclass{2}                     │ Multiclass{5}                     │ Multiclass{4}                     │ Multiclass{4}                     │ Multiclass{9}                     │ Multiclass{9}                     │ Multiclass{1}                     │ Multiclass{4}                     │ Multiclass{3}                     │ Multiclass{5}                     │ Multiclass{9}                     │ Multiclass{6}                     │ Multiclass{7}                     │\n├───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┤\n│ e                                 │ f                                 │ f                                 │ n                                 │ t                                 │ f                                 │ c                                 │ b                                 │ w                                 │ t                                 │ b                                 │ s                                 │ s                                 │ g                                 │ g                                 │ p                                 │ w                                 │ o                                 │ p                                 │ k                                 │ v                                 │ d                                 │\n│ e                                 │ f                                 │ f                                 │ n                                 │ t                                 │ f                                 │ c                                 │ b                                 │ w                                 │ t                                 │ b                                 │ s                                 │ s                                 │ w                                 │ p                                 │ p                                 │ w                                 │ o                                 │ p                                 │ n                                 │ y                                 │ d                                 │\n│ e                                 │ b                                 │ s                                 │ y                                 │ t                                 │ f                                 │ c                                 │ b                                 │ k                                 │ e                                 │ c                                 │ s                                 │ s                                 │ w                                 │ w                                 │ p                                 │ w                                 │ o                                 │ p                                 │ k                                 │ s                                 │ g                                 │\n│ p                                 │ f                                 │ y                                 │ e                                 │ f                                 │ f                                 │ c                                 │ b                                 │ w                                 │ e                                 │ c                                 │ k                                 │ y                                 │ c                                 │ c                                 │ p                                 │ w                                 │ n                                 │ n                                 │ w                                 │ c                                 │ d                                 │\n│ e                                 │ x                                 │ y                                 │ n                                 │ f                                 │ f                                 │ w                                 │ n                                 │ w                                 │ e                                 │ b                                 │ f                                 │ f                                 │ w                                 │ n                                 │ p                                 │ w                                 │ o                                 │ e                                 │ w                                 │ v                                 │ l                                 │\n└───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┘","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Splitting the data into train and test portions is also easy using MLJ's partition function. stratify=y guarantees that the data is distributed in the same proportions as the original dataset in both splits which is more representative of the real world.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"train_inds, test_inds = partition(eachindex(y), 0.8, shuffle=true, stratify=y, rng=Random.Xoshiro(42))\nX_train, X_test = X[train_inds, :], X[test_inds, :]\ny_train, y_test = y[train_inds], y[test_inds]","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"(CategoricalArrays.CategoricalValue{String1, UInt32}[String1(\"s\"), String1(\"s\"), String1(\"n\"), String1(\"s\"), String1(\"s\"), String1(\"n\"), String1(\"s\"), String1(\"n\"), String1(\"n\"), String1(\"n\")  …  String1(\"f\"), String1(\"n\"), String1(\"n\"), String1(\"n\"), String1(\"f\"), String1(\"f\"), String1(\"n\"), String1(\"n\"), String1(\"n\"), String1(\"s\")], CategoricalArrays.CategoricalValue{String1, UInt32}[String1(\"f\"), String1(\"y\"), String1(\"a\"), String1(\"c\"), String1(\"f\"), String1(\"n\"), String1(\"f\"), String1(\"n\"), String1(\"n\"), String1(\"n\")  …  String1(\"f\"), String1(\"f\"), String1(\"n\"), String1(\"n\"), String1(\"f\"), String1(\"y\"), String1(\"f\"), String1(\"n\"), String1(\"n\"), String1(\"n\")])","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"⚠️ Always split the data before oversampling. If your test data has oversampled observations then train-test contamination has occurred; novel observations will not come from the oversampling function.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Oversampling","page":"-","title":"Oversampling","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"It was obvious from the bar charts that there is a severe imbalance problem. Let's look at that again.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"checkbalance(y)         # comes from Imbalance","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"m: ▇ 36 (1.0%) \nc: ▇▇▇ 192 (5.4%) \np: ▇▇▇▇ 256 (7.3%) \na: ▇▇▇▇▇▇ 400 (11.3%) \nl: ▇▇▇▇▇▇ 400 (11.3%) \ny: ▇▇▇▇▇▇▇▇ 576 (16.3%) \ns: ▇▇▇▇▇▇▇▇ 576 (16.3%) \nf: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 2160 (61.2%) \nn: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 3528 (100.0%)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Let's set our desired ratios as follows. these are set relative to the size of the majority class.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"ratios = Dict(\"m\"=>0.3, \n              \"c\"=>0.4,\n              \"p\"=>0.5,\n              \"a\"=>0.5,\n              \"l\"=>0.5,\n              \"y\"=>0.7,\n              \"s\"=>0.7,\n              \"f\"=>0.8\n              )","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Dict{String, Float64} with 8 entries:\n  \"s\" => 0.7\n  \"f\" => 0.8\n  \"c\" => 0.4\n  \"m\" => 0.3\n  \"l\" => 0.5\n  \"a\" => 0.5\n  \"p\" => 0.5\n  \"y\" => 0.7","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"We have used gut feeling to set them here but usually this is one of the most important hyperparameters to tune over. ","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"The easy option ratios=1.0 always exists and would mean that we want to oversample data in each class so that they all match the majority class. It may or may not be the most optimal due to overfitting problems.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Xover, yover = smoten(X_train, y_train; k=2, ratios=ratios, rng=Random.Xoshiro(42))","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Progress:  22%|█████████▏                               |  ETA: 0:00:06\u001b[K\nProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[K\n\n\n\n(15239×22 DataFrame\n   Row │ class  cap-shape  cap-surface  cap-color  bruises  gill-attachment  g ⋯\n       │ Cat…   Cat…       Cat…         Cat…       Cat…     Cat…             C ⋯\n───────┼────────────────────────────────────────────────────────────────────────\n     1 │ p      f          s            e          f        f                c ⋯\n     2 │ p      f          y            e          f        f                c\n     3 │ e      f          f            w          f        f                w\n     4 │ p      f          s            e          f        f                c\n     5 │ p      f          y            e          f        f                c ⋯\n     6 │ e      s          f            g          f        f                c\n     7 │ p      f          s            n          f        f                c\n     8 │ e      x          y            g          t        f                c\n   ⋮   │   ⋮        ⋮           ⋮           ⋮         ⋮            ⋮           ⋱\n 15233 │ p      x          y            c          f        a                c ⋯\n 15234 │ p      x          y            e          f        a                c\n 15235 │ p      x          y            n          f        a                c\n 15236 │ p      k          y            c          f        f                c\n 15237 │ p      x          y            c          f        a                c ⋯\n 15238 │ p      k          y            c          f        f                c\n 15239 │ p      x          y            e          f        f                c\n                                               16 columns and 15224 rows omitted, CategoricalArrays.CategoricalValue{String1, UInt32}[String1(\"s\"), String1(\"s\"), String1(\"n\"), String1(\"s\"), String1(\"s\"), String1(\"n\"), String1(\"s\"), String1(\"n\"), String1(\"n\"), String1(\"n\")  …  String1(\"m\"), String1(\"m\"), String1(\"m\"), String1(\"m\"), String1(\"m\"), String1(\"m\"), String1(\"m\"), String1(\"m\"), String1(\"m\"), String1(\"m\")])","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"SMOTEN uses a very specialized distance metric to decide the nearest neighbors which explains why it may be a bit slow as it's nontrivial to optimize KNN over such metric.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Now let's check the balance of the data","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"checkbalance(yover)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"m: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 847 (30.0%) \nc: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1129 (40.0%) \na: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1411 (50.0%) \nl: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1411 (50.0%) \np: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1411 (50.0%) \ny: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1975 (70.0%) \ns: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1975 (70.0%) \nf: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 2258 (80.0%) \nn: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 2822 (100.0%)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Training-the-Model","page":"-","title":"Training the Model","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Because we have scientific types setup, we can easily check what models will be able to train on our data. This should guarantee that the model we choose won't throw an error due to types after feeding it the data.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"ms = models(matching(Xover, yover))","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"6-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n (name = CatBoostClassifier, package_name = CatBoost, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = DecisionTreeClassifier, package_name = BetaML, ... )\n (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n (name = OneRuleClassifier, package_name = OneRule, ... )\n (name = RandomForestClassifier, package_name = BetaML, ... )","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"Let's go for a OneRuleClassifier","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"import Pkg; Pkg.add(\"OneRule\")","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Before-Oversampling","page":"-","title":"Before Oversampling","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"# 1. Load the model\nOneRuleClassifier= @load OneRuleClassifier pkg=OneRule\n\n# 2. Instantiate it\nmodel = OneRuleClassifier()\n\n# 3. Wrap it with the data in a machine\nmach = machine(model, X_train, y_train)\n\n# 4. fit the machine learning model\nfit!(mach, verbosity=0)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"┌ Info: For silent loading, specify `verbosity=0`. \n└ @ Main /Users/essam/.julia/packages/MLJModels/7apZ3/src/loading.jl:159\n\n\nimport OneRule ✔\n\n\n\ntrained Machine; caches model-specific representations of data\n  model: OneRuleClassifier()\n  args: \n    1:\tSource @385 ⏎ Table{Union{AbstractVector{Multiclass{10}}, AbstractVector{Multiclass{12}}, AbstractVector{Multiclass{2}}, AbstractVector{Multiclass{1}}, AbstractVector{Multiclass{4}}, AbstractVector{Multiclass{3}}, AbstractVector{Multiclass{5}}, AbstractVector{Multiclass{9}}, AbstractVector{Multiclass{6}}, AbstractVector{Multiclass{7}}}}\n    2:\tSource @936 ⏎ AbstractVector{Multiclass{9}}","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#After-Oversampling","page":"-","title":"After Oversampling","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"# 3. Wrap it with the data in a machine\nmach_over = machine(model, Xover, yover)\n\n# 4. fit the machine learning model\nfit!(mach_over, verbosity=0)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"trained Machine; caches model-specific representations of data\n  model: OneRuleClassifier()\n  args: \n    1:\tSource @452 ⏎ Table{Union{AbstractVector{Multiclass{10}}, AbstractVector{Multiclass{12}}, AbstractVector{Multiclass{2}}, AbstractVector{Multiclass{1}}, AbstractVector{Multiclass{4}}, AbstractVector{Multiclass{3}}, AbstractVector{Multiclass{5}}, AbstractVector{Multiclass{9}}, AbstractVector{Multiclass{6}}, AbstractVector{Multiclass{7}}}}\n    2:\tSource @817 ⏎ AbstractVector{Multiclass{9}}","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Evaluating-the-Model","page":"-","title":"Evaluating the Model","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"To evaluate the model, we will use the balanced accuracy metric which equally account for all classes.","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#Before-Oversampling-2","page":"-","title":"Before Oversampling","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"y_pred = MLJ.predict(mach, X_test)                         \n\nscore = round(balanced_accuracy(y_pred, y_test), digits=2)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"0.22","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/#After-Oversampling-2","page":"-","title":"After Oversampling","text":"","category":"section"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"y_pred_over = MLJ.predict(mach_over, X_test)\n\nscore = round(balanced_accuracy(y_pred_over, y_test), digits=2)","category":"page"},{"location":"examples/smoten_mushroom/smoten_mushroom/","page":"-","title":"-","text":"0.4","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#Imports","page":"Imports","title":"Imports","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"using Random\nusing CSV\nusing DataFrames\nusing MLJ\nusing ScientificTypes\nusing Imbalance\nusing Plots","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#Loading-Data","page":"Imports","title":"Loading Data","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Let's load the Iris dataset, the objective of this dataset is to predict the type of flower as one of \"virginica\", \"versicolor\" and \"setosa\" using its sepal and petal length and width. ","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"We don't need to so from a CSV file this time because MLJ has a macro for loading it already! The only difference is that we will need to explictly convert it to a dataframe as MLJ loads it as a named tuple of vectors.","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"X, y = @load_iris\nX = DataFrame(X)\nfirst(X, 5) |> pretty","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"┌──────────────┬─────────────┬──────────────┬─────────────┐\n│ sepal_length │ sepal_width │ petal_length │ petal_width │\n│ Float64      │ Float64     │ Float64      │ Float64     │\n│ Continuous   │ Continuous  │ Continuous   │ Continuous  │\n├──────────────┼─────────────┼──────────────┼─────────────┤\n│ 5.1          │ 3.5         │ 1.4          │ 0.2         │\n│ 4.9          │ 3.0         │ 1.4          │ 0.2         │\n│ 4.7          │ 3.2         │ 1.3          │ 0.2         │\n│ 4.6          │ 3.1         │ 1.5          │ 0.2         │\n│ 5.0          │ 3.6         │ 1.4          │ 0.2         │\n└──────────────┴─────────────┴──────────────┴─────────────┘","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Our purpose for this tutorial is primarily visuallization. Thus, let's select two of the continuous features only to work with. It's known that the sepal length and width play a much bigger role in classifying the type of flower so let's keep those only.","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"X = select(X, :petal_width, :petal_length)\nfirst(X, 5) |> pretty","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"┌─────────────┬──────────────┐\n│ petal_width │ petal_length │\n│ Float64     │ Float64      │\n│ Continuous  │ Continuous   │\n├─────────────┼──────────────┤\n│ 0.2         │ 1.4          │\n│ 0.2         │ 1.4          │\n│ 0.2         │ 1.3          │\n│ 0.2         │ 1.5          │\n│ 0.2         │ 1.4          │\n└─────────────┴──────────────┘","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#Coercing-Data","page":"Imports","title":"Coercing Data","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"ScientificTypes.schema(X)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"┌──────────────┬────────────┬─────────┐\n│ names        │ scitypes   │ types   │\n├──────────────┼────────────┼─────────┤\n│ petal_width  │ Continuous │ Float64 │\n│ petal_length │ Continuous │ Float64 │\n└──────────────┴────────────┴─────────┘","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Things look good, no coercion is needed.","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#Oversampling","page":"Imports","title":"Oversampling","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Iris, by default has no imbalance problem","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"checkbalance(y)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"virginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%) \nsetosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%) \nversicolor: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"To simulate that there is a balance problem, we will consider a random sample of 100 observations. A random sample does not guarantee perserving the proportion of classes; in this, we actually set the seed to get a very unlikely random sample that suffers from strong imbalance.","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Random.seed!(803429)\nsubset_indices = rand(1:size(X, 1), 100)\nX, y = X[subset_indices, :], y[subset_indices]\ncheckbalance(y)         # comes from Imbalance","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"versicolor: ▇▇▇▇▇▇▇▇▇▇▇ 12 (22.6%) \nsetosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 35 (66.0%) \nvirginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"We will treat this as our training set going forward so we don't need to partition. Now let's oversample it with ROSE.","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Xover, yover = rose(X, y; s=0.3, ratios=Dict(\"versicolor\" => 1.0, \"setosa\"=>1.0))\ncheckbalance(yover)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Progress:  67%|███████████████████████████▍             |  ETA: 0:00:00\u001b[K\n\u001b[A\n\nvirginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%) \nsetosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%) \nversicolor: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#Training-the-Model","page":"Imports","title":"Training the Model","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"models(matching(Xover, yover))","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"53-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n (name = AdaBoostClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n (name = BaggingClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = BayesianLDA, package_name = MLJScikitLearnInterface, ... )\n (name = BayesianLDA, package_name = MultivariateStats, ... )\n (name = BayesianQDA, package_name = MLJScikitLearnInterface, ... )\n (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n (name = CatBoostClassifier, package_name = CatBoost, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = DecisionTreeClassifier, package_name = BetaML, ... )\n ⋮\n (name = SGDClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = SVC, package_name = LIBSVM, ... )\n (name = SVMClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = SVMLinearClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = SVMNuClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = StableForestClassifier, package_name = SIRUS, ... )\n (name = StableRulesClassifier, package_name = SIRUS, ... )\n (name = SubspaceLDA, package_name = MultivariateStats, ... )\n (name = XGBoostClassifier, package_name = XGBoost, ... )","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Let's go for a Decision Tree. This is just like the normal perceptron but it learns the separating hyperplane in a higher dimensional space using the kernel trick so that it corresponds to a nonlinear separating hypersurface in the original space. This isn't necessarily helpful in our case, but just to experiment.","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"import Pkg; Pkg.add(\"MultivariateStats\")","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"   Resolving package versions...\n    Updating `~/Documents/GitHub/Imbalance.jl/Project.toml`\n  [6f286f6a] + MultivariateStats v0.10.2\n    Updating `~/Documents/GitHub/Imbalance.jl/Manifest.toml`\n  [7d9fca2a] + Arpack v0.5.4\n  [6f286f6a] + MultivariateStats v0.10.2\n⌅ [68821587] + Arpack_jll v3.5.1+1\n        Info Packages marked with ⌅ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#Before-Oversampling","page":"Imports","title":"Before Oversampling","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"# 1. Load the model\nBayesianLDA = @load BayesianLDA pkg=MultivariateStats\n\n# 2. Instantiate it \nmodel = BayesianLDA()\n\n# 3. Wrap it with the data in a machine\nmach = machine(model, X, y)\n\n# 4. fit the machine learning model\nfit!(mach, verbosity=0)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"import MLJMultivariateStatsInterface ✔\n\n\n┌ Info: For silent loading, specify `verbosity=0`. \n└ @ Main /Users/essam/.julia/packages/MLJModels/7apZ3/src/loading.jl:159\n\n\n\ntrained Machine; caches model-specific representations of data\n  model: BayesianLDA(method = gevd, …)\n  args: \n    1:\tSource @008 ⏎ Table{AbstractVector{Continuous}}\n    2:\tSource @604 ⏎ AbstractVector{Multiclass{3}}","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#After-Oversampling","page":"Imports","title":"After Oversampling","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"# 3. Wrap it with the data in a machine\nmach_over = machine(model, Xover, yover)\n\n# 4. fit the machine learning model\nfit!(mach_over, verbosity=0)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"trained Machine; caches model-specific representations of data\n  model: BayesianLDA(method = gevd, …)\n  args: \n    1:\tSource @447 ⏎ Table{AbstractVector{Continuous}}\n    2:\tSource @477 ⏎ AbstractVector{Multiclass{3}}","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#Plot-Decision-Boundaries","page":"Imports","title":"Plot Decision Boundaries","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Construct ranges for each feature and consecutively a grid","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"petal_width_range =\n\trange(minimum(X.petal_width) - 1, maximum(X.petal_width) + 1, length = 200)\npetal_length_range =\n\trange(minimum(X.petal_length) - 1, maximum(X.petal_length) + 1, length = 200)\ngrid_points = [(pw, pl) for pw in petal_width_range, pl in petal_length_range]\n","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"200×200 Matrix{Tuple{Float64, Float64}}:\n (-0.9, 0.2)       (-0.9, 0.238693)       …  (-0.9, 7.9)\n (-0.878894, 0.2)  (-0.878894, 0.238693)     (-0.878894, 7.9)\n (-0.857789, 0.2)  (-0.857789, 0.238693)     (-0.857789, 7.9)\n (-0.836683, 0.2)  (-0.836683, 0.238693)     (-0.836683, 7.9)\n (-0.815578, 0.2)  (-0.815578, 0.238693)     (-0.815578, 7.9)\n (-0.794472, 0.2)  (-0.794472, 0.238693)  …  (-0.794472, 7.9)\n (-0.773367, 0.2)  (-0.773367, 0.238693)     (-0.773367, 7.9)\n (-0.752261, 0.2)  (-0.752261, 0.238693)     (-0.752261, 7.9)\n (-0.731156, 0.2)  (-0.731156, 0.238693)     (-0.731156, 7.9)\n (-0.71005, 0.2)   (-0.71005, 0.238693)      (-0.71005, 7.9)\n ⋮                                        ⋱  \n (3.13116, 0.2)    (3.13116, 0.238693)       (3.13116, 7.9)\n (3.15226, 0.2)    (3.15226, 0.238693)       (3.15226, 7.9)\n (3.17337, 0.2)    (3.17337, 0.238693)       (3.17337, 7.9)\n (3.19447, 0.2)    (3.19447, 0.238693)       (3.19447, 7.9)\n (3.21558, 0.2)    (3.21558, 0.238693)    …  (3.21558, 7.9)\n (3.23668, 0.2)    (3.23668, 0.238693)       (3.23668, 7.9)\n (3.25779, 0.2)    (3.25779, 0.238693)       (3.25779, 7.9)\n (3.27889, 0.2)    (3.27889, 0.238693)       (3.27889, 7.9)\n (3.3, 0.2)        (3.3, 0.238693)           (3.3, 7.9)","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Evaluate the grid with the machine before and after oversampling","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"grid_predictions = [\n\tpredict_mode(mach, Tables.table(reshape(collect(point), 1, 2)))[1] for\n\tpoint in grid_points\n]\ngrid_predictions_over = [\n\tpredict_mode(mach_over, Tables.table(reshape(collect(point), 1, 2)))[1] for\n\tpoint in grid_points\n]","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"200×200 CategoricalArrays.CategoricalArray{String,2,UInt32}:\n \"setosa\"     \"setosa\"     \"setosa\"     …  \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"     …  \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n ⋮                                      ⋱                \n \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n \"virginica\"  \"virginica\"  \"virginica\"  …  \"virginica\"   \"virginica\"\n \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Make two contour plots using the grid predictions before and after oversampling","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"p = contourf(petal_length_range, petal_width_range, grid_predictions,\n\tlevels = 3, color = :Set3_3, colorbar = false)\np_over = contourf(petal_length_range, petal_width_range, grid_predictions_over,\n\tlevels = 3, color = :Set3_3, colorbar = false)\nprintln()","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"Scatter plot the data before and after oversampling","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"labels = unique(y)\ncolors = Dict(\"setosa\" => \"green\", \"versicolor\" => \"yellow\",\n\t\"virginica\" => \"purple\")\n\nfor label in labels\n\tscatter!(p, X.petal_length[y.==label], X.petal_width[y.==label],\n\t\tcolor = colors[label], label = label,\n\t\ttitle = \"Before Oversampling\")\n\tscatter!(p_over, Xover.petal_length[yover.==label], Xover.petal_width[yover.==label],\n\t\tcolor = colors[label], label = label,\n\t\ttitle = \"After Oversampling\")\nend\n\nplot_res = plot(\n\tp,\n\tp_over,\n\tlayout = (1, 2),\n\txlabel = \"petal length\",\n\tylabel = \"petal width\",\n\tsize = (900, 300),\n)\nsavefig(plot_res, \"./ROSE-before-after.png\")","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"<img src=\"./ROSE-before-after.png\"/>","category":"page"},{"location":"examples/effect_of_s/effect_of_s/#Effect-of-Increasing-s","page":"Imports","title":"Effect of Increasing s","text":"","category":"section"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"anim = @animate for s ∈ 0:0.03:6.0\n\t# oversample\n\tXover, yover =\n\t\trose(X, y; s = s, ratios = Dict(\"setosa\" => 1.0, \"versicolor\" => 1.0), rng = 42)\n\n\tmodel = BayesianLDA()\t\n\tmach_over = machine(model, Xover, yover)\n\tfit!(mach_over, verbosity = 0)\n\n\t# grid predictions\n\tgrid_predictions_over = [\n\t\tpredict_mode(mach_over, Tables.table(reshape(collect(point), 1, 2)))[1] for\n\t\tpoint in grid_points\n\t]\n\n\tp_over = contourf(petal_length_range, petal_width_range, grid_predictions_over,\n\t\tlevels = 3, color = :Set3_3, colorbar = false)\n\n\tfor label in labels\n\t\tscatter!(p_over, Xover.petal_length[yover.==label],\n\t\t\tXover.petal_width[yover.==label],\n\t\t\tcolor = colors[label], label = label,\n\t\t\ttitle = \"Oversampling with s=$s\")\n\tend\n\tplot!(dpi = 150)\nend","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"gif(anim, \"./rose-animation.gif\", fps=6)\nprintln()","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"┌ Info: Saved animation to /Users/essam/Documents/GitHub/Imbalance.jl/docs/src/examples/effect_of_s/rose-animation.gif\n└ @ Plots /Users/essam/.julia/packages/Plots/3BCH5/src/animation.jl:156","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"<img src=\"./rose-anim.gif\"/>","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"As we can see, the larger s is the more spread out are the oversampled points. This is expected because what ROSE does is oversample by sampling from the distribution that corresponds to placing Gaussians on the existing points and s is a hyperparameter proportional to the bandwidth of the Gaussians. When s=0 the only points that can be generated lie on top of others; i.e., ROSE becomes equivalent to random oversampling","category":"page"},{"location":"examples/effect_of_s/effect_of_s/","page":"Imports","title":"Imports","text":"The decision boundary is mainly unstable because we used a small number of epochs with the perceptron to generate this animation. It still took plenty of time.","category":"page"},{"location":"about/#Credits","page":"About","title":"Credits","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"This package was created by Essam Wisam as a Google Summer of Code project, under the mentorship of Anthony Blaom. Additionally, Rik Huijzer and his binary SMOTE implementation in Resample.jl have also been helpful.","category":"page"},{"location":"release_history/#Version-0.0.1","page":"Version 0.0.1","title":"Version 0.0.1","text":"","category":"section"},{"location":"release_history/#Changelog","page":"Version 0.0.1","title":"Changelog","text":"","category":"section"},{"location":"release_history/#Bug-Fixes","page":"Version 0.0.1","title":"Bug Fixes","text":"","category":"section"},{"location":"release_history/#Deprecated-Features","page":"Version 0.0.1","title":"Deprecated Features","text":"","category":"section"},{"location":"release_history/#Added-Features","page":"Version 0.0.1","title":"Added Features","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/#Imports","page":"Imports","title":"Imports","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"using Random\nusing CSV\nusing DataFrames\nusing MLJ\nusing ScientificTypes\nusing Imbalance\nusing Plots","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/#Loading-Data","page":"Imports","title":"Loading Data","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Let's load the Iris dataset, the objective of this dataset is to predict the type of flower as one of \"virginica\", \"versicolor\" and \"setosa\" using its sepal and petal length and width.","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"We don't need to so from a CSV file this time because MLJ has a macro for loading it already! The only difference is that we will need to explictly convert it to a dataframe as MLJ loads it as a named tuple of vectors.","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"X, y = @load_iris\nX = DataFrame(X)\nfirst(X, 5) |> pretty","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"┌──────────────┬─────────────┬──────────────┬─────────────┐\n│ sepal_length │ sepal_width │ petal_length │ petal_width │\n│ Float64      │ Float64     │ Float64      │ Float64     │\n│ Continuous   │ Continuous  │ Continuous   │ Continuous  │\n├──────────────┼─────────────┼──────────────┼─────────────┤\n│ 5.1          │ 3.5         │ 1.4          │ 0.2         │\n│ 4.9          │ 3.0         │ 1.4          │ 0.2         │\n│ 4.7          │ 3.2         │ 1.3          │ 0.2         │\n│ 4.6          │ 3.1         │ 1.5          │ 0.2         │\n│ 5.0          │ 3.6         │ 1.4          │ 0.2         │\n└──────────────┴─────────────┴──────────────┴─────────────┘","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Our purpose for this tutorial is primarily visuallization. Thus, let's select two of the continuous features only to work with. It's known that the sepal length and width play a much bigger role in classifying the type of flower so let's keep those only.","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"X = select(X, :petal_width, :petal_length)\nfirst(X, 5) |> pretty","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"┌─────────────┬──────────────┐\n│ petal_width │ petal_length │\n│ Float64     │ Float64      │\n│ Continuous  │ Continuous   │\n├─────────────┼──────────────┤\n│ 0.2         │ 1.4          │\n│ 0.2         │ 1.4          │\n│ 0.2         │ 1.3          │\n│ 0.2         │ 1.5          │\n│ 0.2         │ 1.4          │\n└─────────────┴──────────────┘","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/#Coercing-Data","page":"Imports","title":"Coercing Data","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"ScientificTypes.schema(X)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"┌──────────────┬────────────┬─────────┐\n│ names        │ scitypes   │ types   │\n├──────────────┼────────────┼─────────┤\n│ petal_width  │ Continuous │ Float64 │\n│ petal_length │ Continuous │ Float64 │\n└──────────────┴────────────┴─────────┘","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Things look good, no coercion is needed.","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/#Oversampling","page":"Imports","title":"Oversampling","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Iris, by default has no imbalance problem","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"checkbalance(y)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"virginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%) \nsetosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%) \nversicolor: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"To simulate that there is a balance problem, we will consider a random sample of 100 observations. A random sample does not guarantee perserving the proportion of classes; in this, we actually set the seed to get a very unlikely random sample that suffers from moderate imbalance.","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Random.seed!(803429)\nsubset_indices = rand(1:size(X, 1), 100)\nX, y = X[subset_indices, :], y[subset_indices]\ncheckbalance(y)         # comes from Imbalance","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"versicolor: ▇▇▇▇▇▇▇▇▇▇▇ 12 (22.6%) \nsetosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 35 (66.0%) \nvirginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"We will treat this as our training set going forward so we don't need to partition. Now let's oversample it with SMOTE.","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Xover, yover = smote(X, y; k=5, ratios=Dict(\"versicolor\" => 0.7), rng=42)\ncheckbalance(yover)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"setosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 35 (66.0%) \nversicolor: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 37 (69.8%) \nvirginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/#Training-the-Model","page":"Imports","title":"Training the Model","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"models(matching(Xover, yover))","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Let's go for an SVM","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"import Pkg;\nPkg.add(\"MLJLIBSVMInterface\");","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/#Before-Oversampling","page":"Imports","title":"Before Oversampling","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"# 1. Load the model\nSVC = @load SVC pkg = LIBSVM\n\n# 2. Instantiate it (γ=0.01 is intentional)\nmodel = SVC(gamma=0.01)\n\n# 3. Wrap it with the data in a machine\nmach = machine(model, X, y)\n\n# 4. fit the machine learning model\nfit!(mach)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/#After-Oversampling","page":"Imports","title":"After Oversampling","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"# 3. Wrap it with the data in a machine\nmach_over = machine(model, Xover, yover)\n\n# 4. fit the machine learning model\nfit!(mach_over)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/#Plot-Decision-Boundaries","page":"Imports","title":"Plot Decision Boundaries","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Construct ranges for each feature and consecutively a grid","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"petal_width_range =\n\trange(minimum(X.petal_width) - 1, maximum(X.petal_width) + 1, length = 200)\npetal_length_range =\n\trange(minimum(X.petal_length) - 1, maximum(X.petal_length) + 1, length = 200)\ngrid_points = [(pw, pl) for pw in petal_width_range, pl in petal_length_range]","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Evaluate the grid with the machine before and after oversampling","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"grid_predictions =[\n    predict(mach, Tables.table(reshape(collect(point), 1, 2)))[1] for\n \tpoint in grid_points\n ]\ngrid_predictions_over = [\n    predict(mach_over, Tables.table(reshape(collect(point), 1, 2)))[1] for\n    point in grid_points\n]","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Make two contour plots using the grid predictions before and after oversampling","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"%%capture\np = contourf(petal_length_range, petal_width_range, grid_predictions,\n    levels=3, color=:Set3_3, colorbar=false)\np_over = contourf(petal_length_range, petal_width_range, grid_predictions_over,\n    levels=3, color=:Set3_3, colorbar=false)","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Scatter plot the data before and after oversampling","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"labels = unique(y)\ncolors = Dict(\"setosa\"=> \"green\", \"versicolor\" => \"yellow\",\n              \"virginica\"=> \"purple\")\n\nfor label in labels\nscatter!(p, X.petal_length[y. == label], X.petal_width[y. == label],\n         color=colors[label], label=label,\n         title=\"Before Oversampling\")\nscatter!(p_over, Xover.petal_length[yover. == label], Xover.petal_width[yover. == label],\n         color=colors[label], label=label,\n         title=\"After Oversampling\")\nend\n\nplot_res = plot(p, p_over, layout=(1, 2), xlabel=\"petal length\",\n                ylabel=\"petal width\", size=(900, 300))\nsavefig(plot_res, \"./before-after-smote.png\")\n","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"<img src=\"./before-after-SMOTE.png\"/>","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Notice how the minority class was completely ignore prior to oversampling. Not all models and hyperparameter settings are this delicate to class imbalance.","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/#Effect-of-Ratios-Hyperparameter","page":"Imports","title":"Effect of Ratios Hyperparameter","text":"","category":"section"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Now let's study the effect of the ratios hyperparameter. We will do this through an animated plot.","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"anim = @animate for versicolor_ratio ∈ 0.3:0.01:2\n\t# oversample\n\tXover, yover =\n\t\tsmote(X, y; k = 5, ratios = Dict(\"versicolor\" => versicolor_ratio), rng = 42)\n\n\t# fit machine\n\tmodel = SVC(gamma = 0.01)\n\tmach_over = machine(model, Xover, yover)\n\tfit!(mach_over, verbosity = 0)\n\n\t# grid predictions\n\tgrid_predictions_over = [\n\t\tpredict(mach_over, Tables.table(reshape(collect(point), 1, 2)))[1] for\n\t\tpoint in grid_points\n\t]\n\n\t# plot\n\tp_over = contourf(petal_length_range, petal_width_range, grid_predictions_over,\n\t\tlevels = 3, color = :Set3_3, colorbar = false)\n\tfor label in labels\n\t\tscatter!(p_over, Xover.petal_length[yover.==label],\n\t\t\tXover.petal_width[yover.==label],\n\t\t\tcolor = colors[label], label = label,\n\t\t\ttitle = \"Oversampling versicolor with ratio $versicolor_ratio\")\n\tend\n\tplot!(dpi = 150)\nend","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"gif(anim, \"./rose-animation.gif\", fps=6)\nprintln()","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"<img src=\"./smote-animation.gif\"/>","category":"page"},{"location":"examples/effect_of_ratios/effect_of_ratios/","page":"Imports","title":"Imports","text":"Notice how setting ratios greedily can lead to overfitting.","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"using Imbalance\nusing CSV\nusing DataFrames\nusing ScientificTypes\nusing CategoricalArrays\nusing MLJ\nusing Plots\nusing Random","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#Loading-Data","page":"-","title":"Loading Data","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"In this example, we will consider the Churn for Bank Customers found on Kaggle where the objective is to predict whether a customer is likely to leave a bank given financial and demographic features.","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"CSV gives us the ability to easily read the dataset after it's downloaded as follows","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"df = CSV.read(\"../datasets/churn.csv\", DataFrame)\nfirst(df, 5) |> pretty","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"┌───────────┬────────────┬──────────┬─────────────┬───────────┬─────────┬───────┬────────┬────────────┬───────────────┬───────────┬────────────────┬─────────────────┬────────┐\n│ RowNumber │ CustomerId │ Surname  │ CreditScore │ Geography │ Gender  │ Age   │ Tenure │ Balance    │ NumOfProducts │ HasCrCard │ IsActiveMember │ EstimatedSalary │ Exited │\n│ Int64     │ Int64      │ String31 │ Int64       │ String7   │ String7 │ Int64 │ Int64  │ Float64    │ Int64         │ Int64     │ Int64          │ Float64         │ Int64  │\n│ Count     │ Count      │ Textual  │ Count       │ Textual   │ Textual │ Count │ Count  │ Continuous │ Count         │ Count     │ Count          │ Continuous      │ Count  │\n├───────────┼────────────┼──────────┼─────────────┼───────────┼─────────┼───────┼────────┼────────────┼───────────────┼───────────┼────────────────┼─────────────────┼────────┤\n│ 1         │ 15634602   │ Hargrave │ 619         │ France    │ Female  │ 42    │ 2      │ 0.0        │ 1             │ 1         │ 1              │ 1.01349e5       │ 1      │\n│ 2         │ 15647311   │ Hill     │ 608         │ Spain     │ Female  │ 41    │ 1      │ 83807.9    │ 1             │ 0         │ 1              │ 1.12543e5       │ 0      │\n│ 3         │ 15619304   │ Onio     │ 502         │ France    │ Female  │ 42    │ 8      │ 1.59661e5  │ 3             │ 1         │ 0              │ 1.13932e5       │ 1      │\n│ 4         │ 15701354   │ Boni     │ 699         │ France    │ Female  │ 39    │ 1      │ 0.0        │ 2             │ 0         │ 0              │ 93826.6         │ 0      │\n│ 5         │ 15737888   │ Mitchell │ 850         │ Spain     │ Female  │ 43    │ 2      │ 1.25511e5  │ 1             │ 1         │ 1              │ 79084.1         │ 0      │\n└───────────┴────────────┴──────────┴─────────────┴───────────┴─────────┴───────┴────────┴────────────┴───────────────┴───────────┴────────────────┴─────────────────┴────────┘","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"There are plenty of useless columns that we can get rid of such as RowNumber and CustomerID. We also have to get rid of the cateogircal features because SMOTE won't be able to deal with those; however, other variants such as SMOTE-NC can which we will consider in another tutorial.","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"df = df[:, Not([:RowNumber, :CustomerId, :Surname, \n           :Geography, :Gender])]\n\nfirst(df, 5) |> pretty","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"┌─────────────┬───────┬────────┬────────────┬───────────────┬───────────┬────────────────┬─────────────────┬────────┐\n│ CreditScore │ Age   │ Tenure │ Balance    │ NumOfProducts │ HasCrCard │ IsActiveMember │ EstimatedSalary │ Exited │\n│ Int64       │ Int64 │ Int64  │ Float64    │ Int64         │ Int64     │ Int64          │ Float64         │ Int64  │\n│ Count       │ Count │ Count  │ Continuous │ Count         │ Count     │ Count          │ Continuous      │ Count  │\n├─────────────┼───────┼────────┼────────────┼───────────────┼───────────┼────────────────┼─────────────────┼────────┤\n│ 619.0       │ 42.0  │ 2.0    │ 0.0        │ 1.0           │ 1.0       │ 1.0            │ 1.01349e5       │ 1.0    │\n│ 608.0       │ 41.0  │ 1.0    │ 83807.9    │ 1.0           │ 0.0       │ 1.0            │ 1.12543e5       │ 0.0    │\n│ 502.0       │ 42.0  │ 8.0    │ 1.59661e5  │ 3.0           │ 1.0       │ 0.0            │ 1.13932e5       │ 1.0    │\n│ 699.0       │ 39.0  │ 1.0    │ 0.0        │ 2.0           │ 0.0       │ 0.0            │ 93826.6         │ 0.0    │\n│ 850.0       │ 43.0  │ 2.0    │ 1.25511e5  │ 1.0           │ 1.0       │ 1.0            │ 79084.1         │ 0.0    │\n└─────────────┴───────┴────────┴────────────┴───────────────┴───────────┴────────────────┴─────────────────┴────────┘","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Ideally, we may even remove ordinal variables because SMOTE will treat them as continuous and the synthetic data it generates will taking floating point values which will not occur in future data. Some models may be robust to this whatsoever and the main purpose of this tutorial is to later compare SMOTE-NC with SMOTE.","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#Coercing-Data","page":"-","title":"Coercing Data","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Let's coerce everything to continuous except for the target variable.","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"df = coerce(df, :Age=>Continuous,\n                :Tenure=>Continuous,\n                :Balance=>Continuous,\n                :NumOfProducts=>Continuous,\n                :HasCrCard=>Continuous,\n                :IsActiveMember=>Continuous,\n                :EstimatedSalary=>Continuous,\n                :Exited=>Multiclass)\n\nScientificTypes.schema(df)","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"┌─────────────────┬───────────────┬─────────────────────────────────┐\n│ names           │ scitypes      │ types                           │\n├─────────────────┼───────────────┼─────────────────────────────────┤\n│ CreditScore     │ Count         │ Int64                           │\n│ Age             │ Continuous    │ Float64                         │\n│ Tenure          │ Continuous    │ Float64                         │\n│ Balance         │ Continuous    │ Float64                         │\n│ NumOfProducts   │ Continuous    │ Float64                         │\n│ HasCrCard       │ Continuous    │ Float64                         │\n│ IsActiveMember  │ Continuous    │ Float64                         │\n│ EstimatedSalary │ Continuous    │ Float64                         │\n│ Exited          │ Multiclass{2} │ CategoricalValue{Int64, UInt32} │\n└─────────────────┴───────────────┴─────────────────────────────────┘","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#Unpacking-and-Splitting-Data","page":"-","title":"Unpacking and Splitting Data","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Both MLJ and the pure functional interface of Imbalance assume that the observations table X and target vector y are separate. We can accomplish that by using unpack from MLJ","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"y, X = unpack(df, ==(:Exited); rng=123);\nfirst(X, 5) |> pretty","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"┌─────────────┬────────────┬────────────┬────────────┬───────────────┬────────────┬────────────────┬─────────────────┐\n│ CreditScore │ Age        │ Tenure     │ Balance    │ NumOfProducts │ HasCrCard  │ IsActiveMember │ EstimatedSalary │\n│ Int64       │ Float64    │ Float64    │ Float64    │ Float64       │ Float64    │ Float64        │ Float64         │\n│ Count       │ Continuous │ Continuous │ Continuous │ Continuous    │ Continuous │ Continuous     │ Continuous      │\n├─────────────┼────────────┼────────────┼────────────┼───────────────┼────────────┼────────────────┼─────────────────┤\n│ 669.0       │ 31.0       │ 6.0        │ 1.13001e5  │ 1.0           │ 1.0        │ 0.0            │ 40467.8         │\n│ 822.0       │ 37.0       │ 3.0        │ 105563.0   │ 1.0           │ 1.0        │ 0.0            │ 1.82625e5       │\n│ 423.0       │ 36.0       │ 5.0        │ 97665.6    │ 1.0           │ 1.0        │ 0.0            │ 1.18373e5       │\n│ 623.0       │ 21.0       │ 10.0       │ 0.0        │ 2.0           │ 0.0        │ 1.0            │ 1.35851e5       │\n│ 691.0       │ 37.0       │ 7.0        │ 1.23068e5  │ 1.0           │ 1.0        │ 1.0            │ 98162.4         │\n└─────────────┴────────────┴────────────┴────────────┴───────────────┴────────────┴────────────────┴─────────────────┘","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Splitting the data into train and test portions is also easy using MLJ's partition function.","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"train_inds, test_inds = partition(eachindex(y), 0.8, shuffle=true, rng=Random.Xoshiro(42))\nX_train, X_test = X[train_inds, :], X[test_inds, :]\ny_train, y_test = y[train_inds], y[test_inds]","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"(CategoricalValue{Int64, UInt32}[0, 1, 1, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 1, 0, 0, 0, 0, 1, 0], CategoricalValue{Int64, UInt32}[0, 0, 0, 0, 0, 1, 1, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0])","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#Oversampling","page":"-","title":"Oversampling","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Before deciding to oversample, let's see how adverse is the imbalance problem, if it exists. Ideally, you may as well check if the classification model is robust to this problem.","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"checkbalance(y)         # comes from Imbalance","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"1: ▇▇▇▇▇▇▇▇▇▇▇▇▇ 2037 (25.6%) \n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 7963 (100.0%)","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Looks like we have a class imbalance problem. Let's oversample with SMOTE and set the desired ratios so that the positive minority class is 90% of the majority class","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Xover, yover = smote(X, y; k=3, ratios=Dict(1=>0.9), rng=42)\ncheckbalance(yover)","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 7167 (90.0%) \n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 7963 (100.0%)","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#Training-the-Model","page":"-","title":"Training the Model","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Because we have scientific types setup, we can easily check what models will be able to train on our data. This should guarantee that the model we choose won't throw an error due to types after feeding it the data.","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"models(matching(Xover, yover))","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"54-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n (name = AdaBoostClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n (name = BaggingClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = BayesianLDA, package_name = MLJScikitLearnInterface, ... )\n (name = BayesianLDA, package_name = MultivariateStats, ... )\n (name = BayesianQDA, package_name = MLJScikitLearnInterface, ... )\n (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n (name = CatBoostClassifier, package_name = CatBoost, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = DecisionTreeClassifier, package_name = BetaML, ... )\n ⋮\n (name = SGDClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = SVC, package_name = LIBSVM, ... )\n (name = SVMClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = SVMLinearClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = SVMNuClassifier, package_name = MLJScikitLearnInterface, ... )\n (name = StableForestClassifier, package_name = SIRUS, ... )\n (name = StableRulesClassifier, package_name = SIRUS, ... )\n (name = SubspaceLDA, package_name = MultivariateStats, ... )\n (name = XGBoostClassifier, package_name = XGBoost, ... )","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"Let's go for a logistic classifier form MLJLinearModels","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"import Pkg; Pkg.add(\"MLJLinearModels\")","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"    Updating registry at `~/.julia/registries/General.toml`\n┌ Error: Some registries failed to update:\n│     — /Users/essam/.julia/registries/General.toml — failed to download from https://pkg.julialang.org/registry/23338594-aafe-5451-b93e-139f81909106/95646b6cd2d61c2d6784757067e14d5bcb846090. Exception: HTTP/2 200 (Operation too slow. Less than 1 bytes/sec transferred the last 20 seconds) while requesting https://pkg.julialang.org/registry/23338594-aafe-5451-b93e-139f81909106/95646b6cd2d61c2d6784757067e14d5bcb846090\n└ @ Pkg.Registry /Users/julia/.julia/scratchspaces/a66863c6-20e8-4ff4-8a62-49f30b1f605e/agent-cache/default-macmini-aarch64-4.0/build/default-macmini-aarch64-4-0/julialang/julia-release-1-dot-8/usr/share/julia/stdlib/v1.8/Pkg/src/Registry/Registry.jl:449\n   Resolving package versions...\n    Updating `~/Documents/GitHub/Imbalance.jl/Project.toml`\n  [6ee0df7b] + MLJLinearModels v0.9.2\n    Updating `~/Documents/GitHub/Imbalance.jl/Manifest.toml`\n  [6a86dc24] + FiniteDiff v2.21.1\n  [42fd0dbc] + IterativeSolvers v0.9.2\n  [d3d80556] + LineSearches v7.2.0\n  [7a12625a] + LinearMaps v3.11.0\n  [6ee0df7b] + MLJLinearModels v0.9.2\n  [d41bc354] + NLSolversBase v7.8.3\n  [429524aa] + Optim v1.7.7\n  [85a6dd25] + PositiveFactorizations v0.2.4\n  [3cdcf5f2] + RecipesBase v1.3.4","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#Before-Oversampling","page":"-","title":"Before Oversampling","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"# 1. Load the model\nLogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0\n\n# 2. Instantiate it\nmodel = LogisticClassifier()\n\n# 3. Wrap it with the data in a machine\nmach = machine(model, X_train, y_train)\n\n# 4. fit the machine learning model\nfit!(mach, verbosity=0)","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"┌ Warning: The number and/or types of data arguments do not match what the specified model\n│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n│ \n│ Run `@doc MLJLinearModels.LogisticClassifier` to learn more about your model's requirements.\n│ \n│ Commonly, but non exclusively, supervised models are constructed using the syntax\n│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n│ sample or class weights.\n│ \n│ In general, data in `machine(model, data...)` is expected to satisfy\n│ \n│     scitype(data) <: MLJ.fit_data_scitype(model)\n│ \n│ In the present case:\n│ \n│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Multiclass{2}}}\n│ \n│ fit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{<:Finite}}\n└ @ MLJBase /Users/essam/.julia/packages/MLJBase/ByFwA/src/machines.jl:230\n\n\n\ntrained Machine; caches model-specific representations of data\n  model: LogisticClassifier(lambda = 2.220446049250313e-16, …)\n  args: \n    1:\tSource @148 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}\n    2:\tSource @042 ⏎ AbstractVector{Multiclass{2}}","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#After-Oversampling","page":"-","title":"After Oversampling","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"# 3. Wrap it with the data in a machine\nmach_over = machine(model, Xover, yover)\n\n# 4. fit the machine learning model\nfit!(mach_over)","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"┌ Info: Training machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …).\n└ @ MLJBase /Users/essam/.julia/packages/MLJBase/ByFwA/src/machines.jl:492\n┌ Info: Solver: MLJLinearModels.LBFGS{Optim.Options{Float64, Nothing}, NamedTuple{(), Tuple{}}}\n│   optim_options: Optim.Options{Float64, Nothing}\n│   lbfgs_options: NamedTuple{(), Tuple{}} NamedTuple()\n└ @ MLJLinearModels /Users/essam/.julia/packages/MLJLinearModels/zSQnL/src/mlj/interface.jl:72\n\n\n\ntrained Machine; caches model-specific representations of data\n  model: LogisticClassifier(lambda = 2.220446049250313e-16, …)\n  args: \n    1:\tSource @525 ⏎ Table{AbstractVector{Continuous}}\n    2:\tSource @636 ⏎ AbstractVector{Multiclass{2}}","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#Evaluating-the-Model","page":"-","title":"Evaluating the Model","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"To evaluate the model, we will use the balanced accuracy metric which equally account for all classes. ","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#Before-Oversampling-2","page":"-","title":"Before Oversampling","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"y_pred = predict_mode(mach, X_test)                         \n\nscore = round(balanced_accuracy(y_pred, y_test), digits=2)","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"0.5","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/#After-Oversampling-2","page":"-","title":"After Oversampling","text":"","category":"section"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"y_pred_over = predict_mode(mach_over, X_test)\n\nscore = round(balanced_accuracy(y_pred_over, y_test), digits=2)","category":"page"},{"location":"examples/smote_churn_dataset/smote_churn_dataset/","page":"-","title":"-","text":"0.66","category":"page"},{"location":"theory/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"theory/","page":"Introduction","title":"Introduction","text":"Most if not all machine learning algorithms can be viewed as a form of empirical risk minimization where the object is to find the parameters theta that for some loss function L minimize ","category":"page"},{"location":"theory/","page":"Introduction","title":"Introduction","text":"hattheta = argmin_theta frac1N sum_i=1^N L(f_theta(x_i) y_i)","category":"page"},{"location":"theory/","page":"Introduction","title":"Introduction","text":"where an underlying assumption is that minimizing this empirical risk corresponds to approximately minimizing the true risk which considers all examples in the populations which would imply that f_theta is approximately the true target function f.","category":"page"},{"location":"theory/","page":"Introduction","title":"Introduction","text":"In a multi-class setting, one can write","category":"page"},{"location":"theory/","page":"Introduction","title":"Introduction","text":"hattheta = argmin_theta left( frac1N_1 sum_i in mathcalC_1 L(f_theta(x_i) y_i) + frac1N_2 sum_i in mathcalC_2 L(f_theta(x_i) y_i) + ldots + frac1N_C sum_i in mathcalC_C L(f_theta(x_i) y_i) right)","category":"page"},{"location":"theory/","page":"Introduction","title":"Introduction","text":"Class imbalance occurs when some classes have much fewer examples than other classes. In this case, the corresponding terms contribute minimally to the sum which makes it easier for any learning algorithm to find an approximate solution to the empirical risk that mostly only minimizes the over the significant sums. This yields a hypothesis f_theta that may be very different from the true target f with respect to the minority classes which may be the most important for the application in question.","category":"page"},{"location":"theory/#Naive-Random-Oversampling","page":"Introduction","title":"Naive Random Oversampling","text":"","category":"section"},{"location":"theory/","page":"Introduction","title":"Introduction","text":"One obvious possible remedy is to weight the smaller sums so that a learning algorithm can avoid approximate solutions that exploit their insignificance. This can be shown to be equivalent (on average) to repeating examples by naive random oversampling of the observations in such classes which is offered by this package along with other more advanced oversampling methods.","category":"page"},{"location":"theory/#ROSE","page":"Introduction","title":"ROSE","text":"","category":"section"},{"location":"theory/#SMOTE","page":"Introduction","title":"SMOTE","text":"","category":"section"},{"location":"theory/#SMOTE-N","page":"Introduction","title":"SMOTE-N","text":"","category":"section"},{"location":"theory/#SMOTEN-C","page":"Introduction","title":"SMOTEN-C","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"using Imbalance\nusing CSV\nusing DataFrames\nusing ScientificTypes\nusing CategoricalArrays\nusing MLJ\nusing Plots\nusing Random","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#Loading-Data","page":"-","title":"Loading Data","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"In this example, we will consider the Churn for Bank Customers found on Kaggle where the objective is to predict whether a customer is likely to leave a bank given financial and demographic features. ","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"We already considered this dataset using SMOTE, in this example we see if the results are any better using SMOTE-NC.","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"df = CSV.read(\"datasets/churn.csv\", DataFrame)\nfirst(df, 5) |> pretty","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"┌───────────┬────────────┬──────────┬─────────────┬───────────┬─────────┬───────┬────────┬────────────┬───────────────┬───────────┬────────────────┬─────────────────┬────────┐\n│ RowNumber │ CustomerId │ Surname  │ CreditScore │ Geography │ Gender  │ Age   │ Tenure │ Balance    │ NumOfProducts │ HasCrCard │ IsActiveMember │ EstimatedSalary │ Exited │\n│ Int64     │ Int64      │ String31 │ Int64       │ String7   │ String7 │ Int64 │ Int64  │ Float64    │ Int64         │ Int64     │ Int64          │ Float64         │ Int64  │\n│ Count     │ Count      │ Textual  │ Count       │ Textual   │ Textual │ Count │ Count  │ Continuous │ Count         │ Count     │ Count          │ Continuous      │ Count  │\n├───────────┼────────────┼──────────┼─────────────┼───────────┼─────────┼───────┼────────┼────────────┼───────────────┼───────────┼────────────────┼─────────────────┼────────┤\n│ 1         │ 15634602   │ Hargrave │ 619         │ France    │ Female  │ 42    │ 2      │ 0.0        │ 1             │ 1         │ 1              │ 1.01349e5       │ 1      │\n│ 2         │ 15647311   │ Hill     │ 608         │ Spain     │ Female  │ 41    │ 1      │ 83807.9    │ 1             │ 0         │ 1              │ 1.12543e5       │ 0      │\n│ 3         │ 15619304   │ Onio     │ 502         │ France    │ Female  │ 42    │ 8      │ 1.59661e5  │ 3             │ 1         │ 0              │ 1.13932e5       │ 1      │\n│ 4         │ 15701354   │ Boni     │ 699         │ France    │ Female  │ 39    │ 1      │ 0.0        │ 2             │ 0         │ 0              │ 93826.6         │ 0      │\n│ 5         │ 15737888   │ Mitchell │ 850         │ Spain     │ Female  │ 43    │ 2      │ 1.25511e5  │ 1             │ 1         │ 1              │ 79084.1         │ 0      │\n└───────────┴────────────┴──────────┴─────────────┴───────────┴─────────┴───────┴────────┴────────────┴───────────────┴───────────┴────────────────┴─────────────────┴────────┘","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Let's get rid of useless columns such as RowNumber and CustomerId","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"df = df[:, Not([:Surname, :RowNumber, :CustomerId])]\n\nfirst(df, 5) |> pretty","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"┌─────────────┬───────────┬─────────┬───────┬────────┬────────────┬───────────────┬───────────┬────────────────┬─────────────────┬────────┐\n│ CreditScore │ Geography │ Gender  │ Age   │ Tenure │ Balance    │ NumOfProducts │ HasCrCard │ IsActiveMember │ EstimatedSalary │ Exited │\n│ Int64       │ String7   │ String7 │ Int64 │ Int64  │ Float64    │ Int64         │ Int64     │ Int64          │ Float64         │ Int64  │\n│ Count       │ Textual   │ Textual │ Count │ Count  │ Continuous │ Count         │ Count     │ Count          │ Continuous      │ Count  │\n├─────────────┼───────────┼─────────┼───────┼────────┼────────────┼───────────────┼───────────┼────────────────┼─────────────────┼────────┤\n│ 619         │ France    │ Female  │ 42    │ 2      │ 0.0        │ 1             │ 1         │ 1              │ 1.01349e5       │ 1      │\n│ 608         │ Spain     │ Female  │ 41    │ 1      │ 83807.9    │ 1             │ 0         │ 1              │ 1.12543e5       │ 0      │\n│ 502         │ France    │ Female  │ 42    │ 8      │ 1.59661e5  │ 3             │ 1         │ 0              │ 1.13932e5       │ 1      │\n│ 699         │ France    │ Female  │ 39    │ 1      │ 0.0        │ 2             │ 0         │ 0              │ 93826.6         │ 0      │\n│ 850         │ Spain     │ Female  │ 43    │ 2      │ 1.25511e5  │ 1             │ 1         │ 1              │ 79084.1         │ 0      │\n└─────────────┴───────────┴─────────┴───────┴────────┴────────────┴───────────────┴───────────┴────────────────┴─────────────────┴────────┘","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#Coercing-Data","page":"-","title":"Coercing Data","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Let's coerce the nominal data to Multiclass, the ordinal data to OrderedFactor and the continuous data to Continuous.","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"df = coerce(df, \n              :Geography => Multiclass, \n              :Gender=> Multiclass,\n              :CreditScore => OrderedFactor,\n              :Age => OrderedFactor,\n              :Tenure => OrderedFactor,\n              :Balance => Continuous,\n              :NumOfProducts => OrderedFactor,\n              :HasCrCard => Multiclass,\n              :IsActiveMember => Multiclass,\n              :EstimatedSalary => Continuous,\n              :Exited => Multiclass\n              )\n\nScientificTypes.schema(df)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"┌─────────────────┬────────────────────┬───────────────────────────────────┐\n│ names           │ scitypes           │ types                             │\n├─────────────────┼────────────────────┼───────────────────────────────────┤\n│ CreditScore     │ OrderedFactor{460} │ CategoricalValue{Int64, UInt32}   │\n│ Geography       │ Multiclass{3}      │ CategoricalValue{String7, UInt32} │\n│ Gender          │ Multiclass{2}      │ CategoricalValue{String7, UInt32} │\n│ Age             │ OrderedFactor{70}  │ CategoricalValue{Int64, UInt32}   │\n│ Tenure          │ OrderedFactor{11}  │ CategoricalValue{Int64, UInt32}   │\n│ Balance         │ Continuous         │ Float64                           │\n│ NumOfProducts   │ OrderedFactor{4}   │ CategoricalValue{Int64, UInt32}   │\n│ HasCrCard       │ Multiclass{2}      │ CategoricalValue{Int64, UInt32}   │\n│ IsActiveMember  │ Multiclass{2}      │ CategoricalValue{Int64, UInt32}   │\n│ EstimatedSalary │ Continuous         │ Float64                           │\n│ Exited          │ Multiclass{2}      │ CategoricalValue{Int64, UInt32}   │\n└─────────────────┴────────────────────┴───────────────────────────────────┘","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#Unpacking-and-Splitting-Data","page":"-","title":"Unpacking and Splitting Data","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"y, X = unpack(df, ==(:Exited); rng=123);\nfirst(X, 5) |> pretty","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"┌─────────────────────────────────┬───────────────────────────────────┬───────────────────────────────────┬─────────────────────────────────┬─────────────────────────────────┬────────────┬─────────────────────────────────┬─────────────────────────────────┬─────────────────────────────────┬─────────────────┐\n│ CreditScore                     │ Geography                         │ Gender                            │ Age                             │ Tenure                          │ Balance    │ NumOfProducts                   │ HasCrCard                       │ IsActiveMember                  │ EstimatedSalary │\n│ CategoricalValue{Int64, UInt32} │ CategoricalValue{String7, UInt32} │ CategoricalValue{String7, UInt32} │ CategoricalValue{Int64, UInt32} │ CategoricalValue{Int64, UInt32} │ Float64    │ CategoricalValue{Int64, UInt32} │ CategoricalValue{Int64, UInt32} │ CategoricalValue{Int64, UInt32} │ Float64         │\n│ OrderedFactor{460}              │ Multiclass{3}                     │ Multiclass{2}                     │ OrderedFactor{70}               │ OrderedFactor{11}               │ Continuous │ OrderedFactor{4}                │ Multiclass{2}                   │ Multiclass{2}                   │ Continuous      │\n├─────────────────────────────────┼───────────────────────────────────┼───────────────────────────────────┼─────────────────────────────────┼─────────────────────────────────┼────────────┼─────────────────────────────────┼─────────────────────────────────┼─────────────────────────────────┼─────────────────┤\n│ 669                             │ France                            │ Female                            │ 31                              │ 6                               │ 1.13001e5  │ 1                               │ 1                               │ 0                               │ 40467.8         │\n│ 822                             │ France                            │ Male                              │ 37                              │ 3                               │ 105563.0   │ 1                               │ 1                               │ 0                               │ 1.82625e5       │\n│ 423                             │ France                            │ Female                            │ 36                              │ 5                               │ 97665.6    │ 1                               │ 1                               │ 0                               │ 1.18373e5       │\n│ 623                             │ France                            │ Male                              │ 21                              │ 10                              │ 0.0        │ 2                               │ 0                               │ 1                               │ 1.35851e5       │\n│ 691                             │ Germany                           │ Female                            │ 37                              │ 7                               │ 1.23068e5  │ 1                               │ 1                               │ 1                               │ 98162.4         │\n└─────────────────────────────────┴───────────────────────────────────┴───────────────────────────────────┴─────────────────────────────────┴─────────────────────────────────┴────────────┴─────────────────────────────────┴─────────────────────────────────┴─────────────────────────────────┴─────────────────┘","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"train_inds, test_inds = partition(eachindex(y), 0.8, shuffle=true, \n                                  rng=Random.Xoshiro(42))\nX_train, X_test = X[train_inds, :], X[test_inds, :]\ny_train, y_test = y[train_inds], y[test_inds]","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"(CategoricalValue{Int64, UInt32}[0, 1, 1, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 1, 0, 0, 0, 0, 1, 0], CategoricalValue{Int64, UInt32}[0, 0, 0, 0, 0, 1, 1, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0])","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#Oversampling","page":"-","title":"Oversampling","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Before deciding to oversample, let's see how adverse is the imbalance problem, if it exists. Ideally, you may as well check if the classification model is robust to this problem.","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"checkbalance(y)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"1: ▇▇▇▇▇▇▇▇▇▇▇▇▇ 2037 (25.6%) \n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 7963 (100.0%)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Looks like we have a class imbalance problem. Let's oversample with SMOTE-NC and set the desired ratios so that the positive minority class is 90% of the majority class","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Xover, yover = smotenc(X, y; k=3, ratios=Dict(1=>0.9), rng=42)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"checkbalance(yover)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 7167 (90.0%) \n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 7963 (100.0%)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#Training-the-Model","page":"-","title":"Training the Model","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Let's find possible models","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"ms = models(matching(Xover, yover))","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"5-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n (name = CatBoostClassifier, package_name = CatBoost, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = DecisionTreeClassifier, package_name = BetaML, ... )\n (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n (name = RandomForestClassifier, package_name = BetaML, ... )","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Let's go for a logistic classifier form MLJLinearModels","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"import Pkg; Pkg.add(\"BetaML\")","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Let's go for a decision tree from BetaML. We can't go for logistic regression as we did in the SMOTE tutorial because it does not support categotical features.","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#Before-Oversampling","page":"-","title":"Before Oversampling","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"# 1. Load the model\nDecisionTreeClassifier = @load DecisionTreeClassifier pkg=BetaML\n\n# 2. Instantiate it\nmodel = DecisionTreeClassifier( max_depth=4, rng=Random.Xoshiro(42))\n\n# 3. Wrap it with the data in a machine\nmach = machine(model, X_train, y_train)\n\n# 4. fit the machine learning model\nfit!(mach, verbosity=0)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"import BetaML ✔\n\n\n┌ Info: For silent loading, specify `verbosity=0`. \n└ @ Main /Users/essam/.julia/packages/MLJModels/7apZ3/src/loading.jl:159\n\n\n\ntrained Machine; caches model-specific representations of data\n  model: DecisionTreeClassifier(max_depth = 4, …)\n  args: \n    1:\tSource @966 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{3}}, AbstractVector{Multiclass{2}}, AbstractVector{OrderedFactor{460}}, AbstractVector{OrderedFactor{70}}, AbstractVector{OrderedFactor{11}}, AbstractVector{OrderedFactor{4}}}}\n    2:\tSource @230 ⏎ AbstractVector{Multiclass{2}}","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#After-Oversampling","page":"-","title":"After Oversampling","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"# 3. Wrap it with the data in a machine\nmach_over = machine(model, Xover, yover)\n\n# 4. fit the machine learning model\nfit!(mach_over)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"┌ Info: Training machine(DecisionTreeClassifier(max_depth = 4, …), …).\n└ @ MLJBase /Users/essam/.julia/packages/MLJBase/0rn2V/src/machines.jl:492\n\n\n\ntrained Machine; caches model-specific representations of data\n  model: DecisionTreeClassifier(max_depth = 4, …)\n  args: \n    1:\tSource @511 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{3}}, AbstractVector{Multiclass{2}}, AbstractVector{OrderedFactor{460}}, AbstractVector{OrderedFactor{70}}, AbstractVector{OrderedFactor{11}}, AbstractVector{OrderedFactor{4}}}}\n    2:\tSource @112 ⏎ AbstractVector{Multiclass{2}}","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#Evaluating-the-Model","page":"-","title":"Evaluating the Model","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"To evaluate the model, we will use the balanced accuracy metric which equally accounts for all classes. ","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#Before-Oversampling-2","page":"-","title":"Before Oversampling","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"y_pred = predict_mode(mach, X_test)                         \n\nscore = round(balanced_accuracy(y_pred, y_test), digits=2)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"0.57","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/#After-Oversampling-2","page":"-","title":"After Oversampling","text":"","category":"section"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"y_pred_over = predict_mode(mach_over, X_test)\n\nscore = round(balanced_accuracy(y_pred_over, y_test), digits=2)","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"0.7","category":"page"},{"location":"examples/smotenc_churn_dataset/smotenc_churn_dataset/","page":"-","title":"-","text":"Although the results do get better compared to when we just used SMOTE, it holds in this case that the extra categorical features we took into account aren't that important. The difference can be attributed to the decision tree.","category":"page"},{"location":"walkthrough/#Introduction","page":"Walkthrough","title":"Introduction","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"In this section of the docs, we will walk you through some examples to demonstrate how you can use Imbalance.jl in your machine learning project. Although we focus on examples, you can learn more about how specific algorithms work by reading this series of blogposts on  Medium.","category":"page"},{"location":"walkthrough/#Prerequisites","page":"Walkthrough","title":"Prerequisites","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"In further examples, we will assume familiarity with the CSV, DataFrames, ScientificTypes and MLJ packages, all of which come with excellent documentation. This example is devoted to assuring and enforcing your familiarity with such packages. You can try this all examples in the docs on your browser using Google Colab and you can read more about that in the last section.","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"using Random\nusing CSV\nusing DataFrames\nusing MLJ\nusing Imbalance\nusing ScientificTypes","category":"page"},{"location":"walkthrough/#Loading-Data","page":"Walkthrough","title":"Loading Data","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"In this example, we will consider the BMI dataset found on Kaggle where the objective is to predict the BMI index of individuals given their gender, weight and height. ","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"CSV gives us the ability to easily read the dataset after it's downloaded as follows","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"df = CSV.read(\"datasets/bmi.csv\", DataFrame)\n\n# Display the first 5 rows with DataFrames\nfirst(df, 5) |> pretty","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"┌─────────┬────────┬────────┬───────┐\n│ Gender  │ Height │ Weight │ Index │\n│ String7 │ Int64  │ Int64  │ Int64 │\n│ Textual │ Count  │ Count  │ Count │\n├─────────┼────────┼────────┼───────┤\n│ Male    │ 174    │ 96     │ 4     │\n│ Male    │ 189    │ 87     │ 2     │\n│ Female  │ 185    │ 110    │ 4     │\n│ Female  │ 195    │ 104    │ 3     │\n│ Male    │ 149    │ 61     │ 3     │\n└─────────┴────────┴────────┴───────┘","category":"page"},{"location":"walkthrough/#Coercing-Data","page":"Walkthrough","title":"Coercing Data","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Typical models from MLJ assume that elements in each column of a table have some scientific type as defined by the ScientificTypes.jl package. Among the many types defined by the package, we are interested in Multiclass, OrderedFactor which fall under the Finite abstract type and Continuous and Count which fall under the Infinite abstract type.","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"One motivation for this package is that it's not generally obvious whether numerical data in an input table is of continuous type or categorical type given that numbers can describe both. Meanwhile, it's problematic if a model treats numerical data as say Continuous or Count when it's in reality nominal (i.e., Multiclass) or ordinal (i.e., OrderedFactor).","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"We can use schema(df) to see how each features is currently going to be interpreted by the resampling algorithms: ","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"ScientificTypes.schema(df)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"┌────────┬──────────┬─────────┐\n│ names  │ scitypes │ types   │\n├────────┼──────────┼─────────┤\n│ Gender │ Textual  │ String7 │\n│ Height │ Count    │ Int64   │\n│ Weight │ Count    │ Int64   │\n│ Index  │ Count    │ Int64   │\n└────────┴──────────┴─────────┘","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"To change encodings that are leading to incorrect interpretations (true for all variable in this example), we use the coerce method, as follows:","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"df = coerce(df,\n            :Gender => Multiclass,\n            :Height => Continuous,\n            :Weight => Continuous,\n            :Index => OrderedFactor)\nScientificTypes.schema(df)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"┌────────┬──────────────────┬───────────────────────────────────┐\n│ names  │ scitypes         │ types                             │\n├────────┼──────────────────┼───────────────────────────────────┤\n│ Gender │ Multiclass{2}    │ CategoricalValue{String7, UInt32} │\n│ Height │ Continuous       │ Float64                           │\n│ Weight │ Continuous       │ Float64                           │\n│ Index  │ OrderedFactor{6} │ CategoricalValue{Int64, UInt32}   │\n└────────┴──────────────────┴───────────────────────────────────┘","category":"page"},{"location":"walkthrough/#Unpacking-and-Splitting-Data","page":"Walkthrough","title":"Unpacking and Splitting Data","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Both MLJ and the pure functional interface of Imbalance assume that the observations table X and target vector y are separate. We can accomplish that by using unpack from MLJ","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"y, X = unpack(df, ==(:Index); rng=123);\nfirst(X, 5) |> pretty","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"┌───────────────────────────────────┬────────────┬────────────┐\n│ Gender                            │ Height     │ Weight     │\n│ CategoricalValue{String7, UInt32} │ Float64    │ Float64    │\n│ Multiclass{2}                     │ Continuous │ Continuous │\n├───────────────────────────────────┼────────────┼────────────┤\n│ Female                            │ 173.0      │ 82.0       │\n│ Female                            │ 187.0      │ 121.0      │\n│ Male                              │ 144.0      │ 145.0      │\n│ Male                              │ 156.0      │ 74.0       │\n│ Male                              │ 167.0      │ 151.0      │\n└───────────────────────────────────┴────────────┴────────────┘","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Splitting the data into train and test portions is also easy using MLJ's partition function. stratify=y guarantees that the data is distributed in the same proportions as the original dataset in both splits which is more representative of the real world.","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"train_inds, test_inds = partition(\n    eachindex(y), 0.8, shuffle=true, stratify=y, rng=Random.Xoshiro(42))\nX_train, X_test = X[train_inds, :], X[test_inds, :]\ny_train, y_test = y[train_inds], y[test_inds]\n","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"(CategoricalArrays.CategoricalValue{Int64, UInt32}[5, 5, 5, 4, 5, 3, 4, 5, 5, 5  …  5, 4, 4, 5, 4, 5, 5, 3, 5, 2], CategoricalArrays.CategoricalValue{Int64, UInt32}[2, 2, 5, 5, 4, 2, 2, 4, 3, 3  …  2, 0, 0, 5, 3, 5, 2, 4, 5, 5])","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"⚠️ Always split the data before oversampling. If your test data has oversampled observations then train-test contamination has occurred; novel observations will not come from the oversampling function.","category":"page"},{"location":"walkthrough/#Oversampling","page":"Walkthrough","title":"Oversampling","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Before deciding to oversample, let's see how adverse is the imbalance problem, if it exists. Ideally, you may as well check if the classification model is robust to this problem.","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"checkbalance(y)             # comes from Imbalance","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"0: ▇▇▇ 13 (6.6%) \n1: ▇▇▇▇▇▇ 22 (11.1%) \n3: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 68 (34.3%) \n2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 69 (34.8%) \n4: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 130 (65.7%) \n5: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 198 (100.0%)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Looks like we have a class imbalance problem. Let's set the desired ratios so that the first two classes are 30%     of the majority class, the second two are 50% of the majority class and the rest as is (ignore in the dictionary)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"ratios = Dict(0=>0.3, 1=>0.3, 2=>0.5, 3=>0.5)              ","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Dict{Int64, Float64} with 4 entries:\n  0 => 0.3\n  2 => 0.5\n  3 => 0.5\n  1 => 0.3","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Let's use random oversampling to oversample the data. This particular model does not care about the scientific types of the data. It takes X and y as positional arguments and ratios and rng are the main keyword arguments","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Xover, yover = random_oversample(X, y; ratios, rng=42)        ","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Progress:  33%|█████████████▋                           |  ETA: 0:00:01\u001b[K\n\u001b[A\n\n\n(644×3 DataFrame\n Row │ Gender  Height   Weight  \n     │ Cat…    Float64  Float64 \n─────┼──────────────────────────\n   1 │ Female    173.0     82.0\n   2 │ Female    187.0    121.0\n   3 │ Male      144.0    145.0\n   4 │ Male      156.0     74.0\n   5 │ Male      167.0    151.0\n   6 │ Female    146.0    147.0\n   7 │ Female    157.0    153.0\n   8 │ Male      187.0    140.0\n  ⋮  │   ⋮        ⋮        ⋮\n 638 │ Female    183.0     50.0\n 639 │ Female    163.0     57.0\n 640 │ Female    190.0     50.0\n 641 │ Male      181.0     51.0\n 642 │ Male      188.0     54.0\n 643 │ Female    191.0     54.0\n 644 │ Male      198.0     50.0\n                629 rows omitted, CategoricalArrays.CategoricalValue{Int64, UInt32}[2, 4, 5, 4, 5, 5, 5, 5, 5, 2  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0])","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"checkbalance(yover)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 59 (29.8%) \n1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 59 (29.8%) \n2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 99 (50.0%) \n3: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 99 (50.0%) \n4: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 130 (65.7%) \n5: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 198 (100.0%)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"This indeeds aligns with the desired ratios we have set earlier.","category":"page"},{"location":"walkthrough/#Training-the-Model","page":"Walkthrough","title":"Training the Model","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Because we have scientific types setup, we can easily check what models will be able to train on our data. This should guarantee that the model we choose won't throw an error due to types after feeding it the data.","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"models(matching(Xover, yover))","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"5-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n (name = CatBoostClassifier, package_name = CatBoost, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = DecisionTreeClassifier, package_name = BetaML, ... )\n (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n (name = RandomForestClassifier, package_name = BetaML, ... )","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Let's go for a decision tree form BetaML","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"import Pkg; Pkg.add(\"BetaML\")","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n  No Changes to `~/Documents/GitHub/Imbalance.jl/Project.toml`\n  No Changes to `~/Documents/GitHub/Imbalance.jl/Manifest.toml`","category":"page"},{"location":"walkthrough/#Before-Oversampling","page":"Walkthrough","title":"Before Oversampling","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"# 1. Load the model\nDecisionTreeClassifier = @load DecisionTreeClassifier pkg=BetaML verbosity=0\n\n# 2. Instantiate it\nmodel = DecisionTreeClassifier(max_depth=5, rng=Random.Xoshiro(42))\n\n# 3. Wrap it with the data in a machine\nmach = machine(model, X_train, y_train)\n\n# 4. fit the machine learning model\nfit!(mach)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"┌ Info: Training machine(DecisionTreeClassifier(max_depth = 5, …), …).\n└ @ MLJBase /Users/essam/.julia/packages/MLJBase/0rn2V/src/machines.jl:492\n\n\n\ntrained Machine; caches model-specific representations of data\n  model: DecisionTreeClassifier(max_depth = 5, …)\n  args: \n    1:\tSource @636 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{2}}}}\n    2:\tSource @264 ⏎ AbstractVector{OrderedFactor{6}}","category":"page"},{"location":"walkthrough/#After-Oversampling","page":"Walkthrough","title":"After Oversampling","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"# 3. Wrap it with the data in a machine\nmach_over = machine(model, Xover, yover)\n\n# 4. fit the machine learning model\nfit!(mach_over)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"┌ Info: Training machine(DecisionTreeClassifier(max_depth = 5, …), …).\n└ @ MLJBase /Users/essam/.julia/packages/MLJBase/0rn2V/src/machines.jl:492\n\n\n\ntrained Machine; caches model-specific representations of data\n  model: DecisionTreeClassifier(max_depth = 5, …)\n  args: \n    1:\tSource @373 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{2}}}}\n    2:\tSource @042 ⏎ AbstractVector{OrderedFactor{6}}","category":"page"},{"location":"walkthrough/#Evaluating-the-Model","page":"Walkthrough","title":"Evaluating the Model","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"To evaluate the model, we will use the balanced accuracy metric which equally account for all classes. For instance, if we have two classes and we correctly classify 100% of the examples in the first and 50% of the examples in the second then the balanced accuracy is (100+50)2=75. This holds regardless to how big or small each class is.","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"The predict_mode will return a vector of predictions given X_test and the fitted machine. It's different in that predict in not returning probablities the model assigns to each class; instead, it returns the classes with the maximum probabilities; i.e., the modes.","category":"page"},{"location":"walkthrough/#Before-Oversampling-2","page":"Walkthrough","title":"Before Oversampling","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"y_pred = predict_mode(mach, X_test)                         \n\nscore = round(balanced_accuracy(y_pred, y_test), digits=2)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"0.62","category":"page"},{"location":"walkthrough/#After-Oversampling-2","page":"Walkthrough","title":"After Oversampling","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"y_pred_over = predict_mode(mach_over, X_test)\n\nscore = round(balanced_accuracy(y_pred_over, y_test), digits=2)","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"0.77","category":"page"},{"location":"walkthrough/#Google-Colab","page":"Walkthrough","title":"Google Colab","text":"","category":"section"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"It is possible to run this tutorial and others in the examples section on Google Colab.","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Click the Colab icon link as your hover on the example\nPaste and run the following in the first cell","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"%%capture\n%%shell\nif ! command -v julia 3>&1 > /dev/null\nthen\n    wget -q 'https://julialang-s3.julialang.org/bin/linux/x64/1.7/julia-1.7.2-linux-x86_64.tar.gz' \\\n        -O /tmp/julia.tar.gz\n    tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n    rm /tmp/julia.tar.gz\nfi\njulia -e 'using Pkg; pkg\"add IJulia; precompile;\"'\necho 'Done'","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Change the runtime to Julia from the toolbar\nPkg.add Imbalance and any needed packages (those being used)\nClick the folder icon on the left, make a datasets folder and drag and drop it in there\nRun the notebook","category":"page"},{"location":"walkthrough/","page":"Walkthrough","title":"Walkthrough","text":"Sincere thanks to Julia-on-Colab for making this possible","category":"page"},{"location":"algorithms/#Imbalance-Algorithms","page":"Algorithms","title":"Imbalance Algorithms","text":"","category":"section"},{"location":"algorithms/#List-of-Algorithms-Implemented","page":"Algorithms","title":"List of Algorithms Implemented","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"Order = [:type, :function]\nModules = Imbalance]\nPages = [\"api.md\"]","category":"page"},{"location":"algorithms/#Random-Oversampler","page":"Algorithms","title":"Random Oversampler","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"random_oversample","category":"page"},{"location":"algorithms/#Imbalance.random_oversample","page":"Algorithms","title":"Imbalance.random_oversample","text":"random_oversample(\n    X, y; \n    ratios=nothing, rng=default_rng(), \n    try_preserve_type=true\n)\n\nDescription\n\nNaively oversample a dataset by randomly repeating existing observations with replacement.\n\nPositional Arguments\n\nX: A matrix or table of floats where each row is an observation from the dataset \ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\n\nKeyword Arguments\n\nratios=1.0: A parameter that controls the amount of oversampling to be done for each class\nCan be a float and in this case each class will be oversampled to the size of the majority class times the float. By default, all classes are oversampled to the size of the majority class\nCan be a dictionary mapping each class label to the float ratio for that class\n\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nXover: A matrix or table that includes original data and the new observations    due to oversampling. depending on whether the input X is a matrix or table respectively\nyover: An abstract vector of labels corresponding to Xover\n\nExample\n\nusing Imbalance\nusing StatsBase\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows, num_continuous_feats = 100, 5\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, rng=42)                       \njulia> StatsBase.countmap(y)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 33\n1 => 19\n\n# apply random oversampling\nXover, yover = random_oversample(X, y; ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\njulia> StatsBase.countmap(yover)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 38\n1 => 43\n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the RandomOversampler model and pass the      positional arguments to the transform method. \n\nusing MLJ\nRandomOversampler = @load RandomOversampler pkg=Imbalance\n\n# Wrap the model in a machine\noversampler = RandomOversampler(ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nmach = machine(oversampler)\n\n# Provide the data to transform (there is nothing to fit)\nXover, yover = transform(mach, X, y)\n\nYou can read more about this MLJ interface here.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 100\nnum_features = 5\ny_ind = 3\nXy, _ = generate_imbalanced_data(num_rows, num_features; \n                                 probs=[0.5, 0.2, 0.3], insert_y=y_ind, rng=42)\n\n# Initiate Random Oversampler model\noversampler = RandomOversampler(y_ind; ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nXyover = Xy |> oversampler                    \nXyover, cache = TableTransforms.apply(oversampler, Xy)    # equivalently\n\nThe reapply(oversampler, Xy, cache) method from TableTransforms simply falls back to apply(oversample, Xy) and the revert(oversampler, Xy, cache) reverts the transform by removing the oversampled observations from the table.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#ROSE","page":"Algorithms","title":"ROSE","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"rose","category":"page"},{"location":"algorithms/#Imbalance.rose","page":"Algorithms","title":"Imbalance.rose","text":"rose(\n    X, y; \n    s=0.1, ratios=nothing, rng=default_rng(),\n    try_perserve_type=true\n)\n\nDescription\n\nOversamples a dataset using ROSE (Random Oversampling Examples) algorithm to      correct for class imbalance as presented in [1]\n\nPositional Arguments\n\nX: A matrix or table of floats where each row is an observation from the dataset \ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\n\nKeyword Arguments\n\ns::float: A parameter that proportionally controls the bandwidth of the Gaussian kernel\nratios=1.0: A parameter that controls the amount of oversampling to be done for each class\nCan be a float and in this case each class will be oversampled to the size of the majority class times the float. By default, all classes are oversampled to the size of the majority class\nCan be a dictionary mapping each class label to the float ratio for that class\n\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nXover: A matrix or table that includes original data and the new observations    due to oversampling. depending on whether the input X is a matrix or table respectively\nyover: An abstract vector of labels corresponding to Xover\n\nExample\n\nusing Imbalance\nusing StatsBase\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows, num_continuous_feats = 100, 5\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, rng=42)                       \njulia> StatsBase.countmap(y)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 33\n1 => 19\n\n# apply ROSE\nXover, yover = rose(X, y; s=0.3, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\njulia> StatsBase.countmap(yover)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 38\n1 => 43\n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the ROSE model and pass the      positional arguments to the transform method. \n\nusing MLJ\nROSE = @load ROSE pkg=Imbalance\n\n# Wrap the model in a machine\noversampler = ROSE(s=0.3, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nmach = machine(oversampler)\n\n# Provide the data to transform (there is nothing to fit)\nXover, yover = transform(mach, X, y)\n\nYou can read more about this MLJ interface here.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 200\nnum_features = 5\ny_ind = 3\nXy, _ = generate_imbalanced_data(num_rows, num_features; \n                                 probs=[0.5, 0.2, 0.3], insert_y=y_ind, rng=42)\n\n# Initiate Random Oversampler model\noversampler = ROSE(y_ind; s=0.3, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nXyover = Xy |> oversampler                              \nXyover, cache = TableTransforms.apply(oversampler, Xy)    # equivalently\n\nThe reapply(oversampler, Xy, cache) method from TableTransforms simply falls back to apply(oversample, Xy) and the revert(oversampler, Xy, cache) reverts the transform by removing the oversampled observations from the table.\n\nReferences\n\n[1] G Menardi, N. Torelli, “Training and assessing classification rules with imbalanced data,”  Data Mining and Knowledge Discovery, 28(1), pp.92-122, 2014.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#SMOTE","page":"Algorithms","title":"SMOTE","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"smote","category":"page"},{"location":"algorithms/#Imbalance.smote","page":"Algorithms","title":"Imbalance.smote","text":"smote(\n    X, y;\n    k=5, ratios=nothing, rng=default_rng(),\n    try_perserve_type=true\n)\n\nDescription\n\nOversamples a dataset using SMOTE (Synthetic Minority Oversampling Techniques) algorithm to      correct for class imbalance as presented in [1]\n\nPositional Arguments\n\nX: A matrix or table of floats where each row is an observation from the dataset \ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\n\nKeyword Arguments\n\nk::Integer=5: Number of nearest neighbors to consider in the algorithm. Should be within the range 0 < k < n where n is the number of observations in the smallest class. It will be automatically set to n-1 for any class where n ≤ k.\n\nratios=1.0: A parameter that controls the amount of oversampling to be done for each class\nCan be a float and in this case each class will be oversampled to the size of the majority class times the float. By default, all classes are oversampled to the size of the majority class\nCan be a dictionary mapping each class label to the float ratio for that class\n\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nXover: A matrix or table that includes original data and the new observations    due to oversampling. depending on whether the input X is a matrix or table respectively\nyover: An abstract vector of labels corresponding to Xover\n\nExample\n\nusing Imbalance\nusing StatsBase\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows, num_continuous_feats = 100, 5\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, rng=42)                       \njulia> StatsBase.countmap(y)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 33\n1 => 19\n\n# apply SMOTE\nXover, yover = smote(X, y; k = 5, ratios = Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng = 42)\njulia> StatsBase.countmap(yover)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 38\n1 => 43\n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the SMOTEN model and pass the      positional arguments to the transform method. \n\nusing MLJ\nSMOTE = @load SMOTE pkg=Imbalance\n\n# Wrap the model in a machine\noversampler = SMOTE(k=5, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nmach = machine(oversampler)\n\n# Provide the data to transform (there is nothing to fit)\nXover, yover = transform(mach, X, y)\n\nYou can read more about this MLJ interface here.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 200\nnum_features = 5\ny_ind = 3\nXy, _ = generate_imbalanced_data(num_rows, num_features; \n                                 probs=[0.5, 0.2, 0.3], insert_y=y_ind, rng=42)\n\n# Initiate Random Oversampler model\noversampler = SMOTE(y_ind; k=5, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nXyover = Xy |> oversampler                              \nXyover, cache = TableTransforms.apply(oversampler, Xy)    # equivalently\n\nThe reapply(oversampler, Xy, cache) method from TableTransforms simply falls back to apply(oversample, Xy) and the revert(oversampler, Xy, cache) reverts the transform by removing the oversampled observations from the table.\n\nReferences\n\n[1] N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, “SMOTE: synthetic minority over-sampling technique,” Journal of artificial intelligence research, 321-357, 2002.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#SMOTE-N","page":"Algorithms","title":"SMOTE-N","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"smoten","category":"page"},{"location":"algorithms/#Imbalance.smoten","page":"Algorithms","title":"Imbalance.smoten","text":"smoten(\n    X, y;\n    k, ratios=nothing, rng=default_rng(),\n    try_perserve_type=true\n)\n\nDescription\n\nOversamples a dataset using SMOTE-N (Synthetic Minority Oversampling Techniques-Nominal) algorithm to      correct for class imbalance as presented in [1]. This is a variant of SMOTE to deal with datasets      where all the features are nominal.\n\nPositional Arguments\n\nX: A matrix of integers or a table with elementscitypes that subtype Finite.     That is, for table inputs each column should have either OrderedFactor or Multiclass as the element scitype.\ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\n\nKeyword Arguments\n\nk::Integer=5: Number of nearest neighbors to consider in the algorithm. Should be within the range 0 < k < n where n is the number of observations in the smallest class. It will be automatically set to n-1 for any class where n ≤ k.\n\nratios=1.0: A parameter that controls the amount of oversampling to be done for each class\nCan be a float and in this case each class will be oversampled to the size of the majority class times the float. By default, all classes are oversampled to the size of the majority class\nCan be a dictionary mapping each class label to the float ratio for that class\n\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nXover: A matrix or table that includes original data and the new observations    due to oversampling. depending on whether the input X is a matrix or table respectively\nyover: An abstract vector of labels corresponding to Xover\n\nExample\n\nusing Imbalance\nusing StatsBase\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows = 100\nnum_continuous_feats = 0\n# want two categorical features with three and two possible values respectively\ncat_feats_num_vals = [3, 2]\n\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, cat_feats_num_vals, rng=42)                      \njulia> StatsBase.countmap(y)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 33\n1 => 19\n\njulia> ScientificTypes.schema(X).scitypes\n(Count, Count)\n\n# coerce to a finite scitype (multiclass or ordered factor)\nX = coerce(X, autotype(X, :few_to_finite))\n\n# apply SMOTEN\nXover, yover = smoten(X, y; k=5, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\njulia> StatsBase.countmap(yover)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 33\n1 => 19\n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the SMOTEN model and pass the      positional arguments to the transform method. \n\nusing MLJ\nSMOTEN = @load SMOTEN pkg=Imbalance\n\n# Wrap the model in a machine\noversampler = SMOTEN(k=5, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nmach = machine(oversampler)\n\n# Provide the data to transform (there is nothing to fit)\nXover, yover = transform(mach, X, y)\n\nYou can read more about this MLJ interface here.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing ScientificTypes\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 100\nnum_continuous_feats = 0\ny_ind = 2\n# generate a table and categorical vector accordingly\nXy, _ = generate_imbalanced_data(num_rows, num_continuous_feats; insert_y=y_ind,\n                                probs= [0.5, 0.2, 0.3], cat_feats_num_vals=[3, 2],\n                                 rng=42)  \n\n# Table must have only finite scitypes                                \nXy = coerce(Xy, :Column1=>Multiclass, :Column2=>Multiclass, :Column3=>Multiclass)\n\n# Initiate Random Oversampler model\noversampler = SMOTEN(y_ind; k=5, ratios=Dict(1=>1.0, 2=> 0.9, 3=>0.9), rng=42)\nXyover = Xy |> oversampler                               \nXyover, cache = TableTransforms.apply(oversampler, Xy)    # equivalently\n\nThe reapply(oversampler, Xy, cache) method from TableTransforms simply falls back to apply(oversample, Xy) and the revert(oversampler, Xy, cache) reverts the transform by removing the oversampled observations from the table.\n\nReferences\n\n[1] N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, “SMOTE: synthetic minority over-sampling technique,” Journal of artificial intelligence research, 321-357, 2002.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#SMOTE-NC","page":"Algorithms","title":"SMOTE-NC","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"smotenc","category":"page"},{"location":"algorithms/#Imbalance.smotenc","page":"Algorithms","title":"Imbalance.smotenc","text":"smotenc(\n    X, y, split_ind;\n    k=5, ratios=nothing, rng=default_rng(),\n    try_perserve_type=true\n)\n\nDescription\n\nOversamples a dataset using SMOTE-NC (Synthetic Minority Oversampling Techniques-Nominal Continuous)      algorithm to correct for class imbalance as presented in [1]. This is a variant of SMOTE      to deal with datasets with both nominal and continuous features. \n\nwarning: SMOTE-NC Assumes Continuous Features Exist\nSMOTE-NC will not work if the dataset is purely nominal. In that case, refer to SMOTE-N instead.     Meanwhile, if the dataset is purely continuous then it's equivalent to the standard SMOTE`.\n\nPositional Arguments\n\nX: A matrix of floats or a table with element scitypes that subtype Union{Finite, Infinite}.     Elements in nominal columns should subtype Finite (i.e., have scitype OrderedFactor or Multiclass) and    elements in continuous columns should subtype Infinite (i.e., have scitype Count or Continuous).\ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\ncat_inds::AbstractVector{<:Int}: A vector of the indices of the nominal features. Supplied only if X is a matrix.       Otherwise, they are inferred from the table's scitypes.\n\nKeyword Arguments\n\nk::Integer=5: Number of nearest neighbors to consider in the algorithm. Should be within the range 0 < k < n where n is the number of observations in the smallest class. It will be automatically set to n-1 for any class where n ≤ k.\n\nratios=1.0: A parameter that controls the amount of oversampling to be done for each class\nCan be a float and in this case each class will be oversampled to the size of the majority class times the float. By default, all classes are oversampled to the size of the majority class\nCan be a dictionary mapping each class label to the float ratio for that class\n\nknn_tree: Decides the tree used in KNN computations. Either \"Brute\" or \"Ball\".   BallTree can be much faster but may lead to innacurate results.\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nXover: A matrix or table that includes original data and the new observations    due to oversampling. depending on whether the input X is a matrix or table respectively\nyover: An abstract vector of labels corresponding to Xover\n\nExample\n\nusing Imbalance\nusing StatsBase\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows = 100\nnum_continuous_feats = 3\n# want two categorical features with three and two possible values respectively\ncat_feats_num_vals = [3, 2]\n\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, cat_feats_num_vals, rng=42)                      \njulia> StatsBase.countmap(y)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 33\n1 => 19\n\njulia> ScientificTypes.schema(X).scitypes\n(Continuous, Continuous, Continuous, Continuous, Continuous)\n# coerce nominal columns to a finite scitype (multiclass or ordered factor)\nX = coerce(X, :Column4=>Multiclass, :Column5=>Multiclass)\n\n# apply SMOTE-NC\nXover, yover = smotenc(X, y; k = 5, ratios = Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng = 42)\njulia>StatsBase.countmap(yover)\nDict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Int64} with 3 entries:\n0 => 48\n2 => 33\n1 => 19\n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the SMOTENC model and pass the      positional arguments (excluding cat_inds) to the transform method. \n\nusing MLJ\nSMOTEN = @load SMOTEN pkg=Imbalance\n\n# Wrap the model in a machine\noversampler = SMOTENC(k=5, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nmach = machine(oversampler)\n\n# Provide the data to transform (there is nothing to fit)\nXover, yover = transform(mach, X, y)\n\nYou can read more about this MLJ interface here. Note that only Table input is supported for this method.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing ScientificTypes\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 100\nnum_continuous_feats = 3\ny_ind = 2\n# generate a table and categorical vector accordingly\nXy, _ = generate_imbalanced_data(num_rows, num_continuous_feats; insert_y=y_ind,\n                                probs= [0.5, 0.2, 0.3], cat_feats_num_vals=[3, 2],\n                                 rng=42)  \n\n# Table must have only finite or continuous scitypes                                \nXy = coerce(Xy, :Column2=>Multiclass, :Column5=>Multiclass, :Column6=>Multiclass)\n\n# Initiate Random Oversampler model\noversampler = SMOTENC(y_ind; k=5, ratios=Dict(1=>1.0, 2=> 0.9, 3=>0.9), rng=42)\nXyover = Xy |> oversampler                               \nXyover, cache = TableTransforms.apply(oversampler, Xy)    # equivalently\n\nReferences\n\n[1] N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, “SMOTE: synthetic minority over-sampling technique,” Journal of artificial intelligence research, 321-357, 2002.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#Random-Undersampler","page":"Algorithms","title":"Random Undersampler","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"random_undersample","category":"page"},{"location":"algorithms/#Imbalance.random_undersample","page":"Algorithms","title":"Imbalance.random_undersample","text":"random_undersample(\n    X, y; \n    ratios=1.0, rng=default_rng(), \n    try_preserve_type=true\n)\n\nDescription\n\nNaively undersample a dataset by randomly deleting existing observations.\n\nPositional Arguments\n\nX: A matrix or table of floats where each row is an observation from the dataset \ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\n\nKeyword Arguments\n\nratios=1.0: A parameter that controls the amount of undersampling to be done for each class\nCan be a float and in this case each class will be undersampled to the size of the minority class times the float. By default, all classes are undersampled to the size of the minority class\nCan be a dictionary mapping each class label to the float ratio for that class\n\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nX_under: A matrix or table that includes the data after undersampling    depending on whether the input X is a matrix or table respectively\ny_under: An abstract vector of labels corresponding to X_under\n\nExample\n\nusing Imbalance\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows, num_continuous_feats = 100, 5\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, rng=42)                       \njulia> checkbalance(y; ref=\"minority\")\n 1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n 2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 33 (173.7%) \n 0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 48 (252.6%) \n\n# apply randomundersampling\nX_under, y_under = random_undersample(X, y; ratios=Dict(0=>1.0, 1=> 1.0, 2=>1.0), \n                                      rng=42)\njulia> checkbalance(y_under)\n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the RandomUndersampler model and pass the      positional arguments to the transform method. \n\nusing MLJ\nRandomUndersampler = @load RandomUndersampler pkg=Imbalance\n\n# Wrap the model in a machine\nundersampler = RandomUndersampler(ratios=Dict(0=>1.0, 1=> 1.0, 2=>1.0), \n               rng=42)\nmach = machine(undersampler)\n\n# Provide the data to transform (there is nothing to fit)\nX_under, y_under = transform(mach, X, y)\n\nYou can read more about this MLJ interface here.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 100\nnum_features = 5\ny_ind = 3\nXy, _ = generate_imbalanced_data(num_rows, num_features; \n                                 probs=[0.5, 0.2, 0.3], insert_y=y_ind, rng=42)\n\n# Initiate Random Undersampler model\nundersampler = RandomUndersampler(y_ind; ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nXy_under = Xy |> undersampler                    \nXy_under, cache = TableTransforms.apply(undersampler, Xy)    # equivalently\n\nThe reapply(undersampler, Xy, cache) method from TableTransforms simply falls back to apply(undersample, Xy) and the revert(undersampler, Xy, cache) is not supported.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#Cluster-Undersampler","page":"Algorithms","title":"Cluster Undersampler","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"cluster_undersample","category":"page"},{"location":"algorithms/#Imbalance.cluster_undersample","page":"Algorithms","title":"Imbalance.cluster_undersample","text":"cluster_undersample(\n    X, y; \n    mode= \"nearest\", ratios = 1.0, maxiter = 100,\n    rng=default_rng(), try_preserve_type=true\n)\n\nDescription\n\nUndersample a dataset using clustering undersampling as presented in [1] using K-means as the clustering algorithm.\n\nPositional Arguments\n\nX: A matrix or table of floats where each row is an observation from the dataset \ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\n\nKeyword Arguments\n\nmode::AbstractString=\"nearest: If \"center\" then the undersampled data will consist of the centriods of    each cluster found; meanwhile, if \"nearest\" then it will consist of the nearest neighbor of each centroid.\nratios=1.0: A parameter that controls the amount of undersampling to be done for each class\nCan be a float and in this case each class will be undersampled to the size of the minority class times the float. By default, all classes are undersampled to the size of the minority class\nCan be a dictionary mapping each class label to the float ratio for that class\n\nmaxiter::Integer=100: Maximum number of iterations to run K-means\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nX_under: A matrix or table that includes the data after undersampling    depending on whether the input X is a matrix or table respectively\ny_under: An abstract vector of labels corresponding to X_under\n\nExample\n\nusing Imbalance\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows, num_continuous_feats = 100, 5\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, rng=42)                       \njulia> checkbalance(y; ref=\"minority\")\n 1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n 2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 33 (173.7%) \n 0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 48 (252.6%) \n\n# apply cluster_undersampling\nX_under, y_under = cluster_undersample(X, y; mode=\"nearest\", \n                                       ratios=Dict(0=>1.0, 1=> 1.0, 2=>1.0), rng=42)\njulia> checkbalance(y_under)\n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the ClusterUndersampler model and pass the      positional arguments to the transform method. \n\nusing MLJ\nClusterUndersampler = @load ClusterUndersampler pkg=Imbalance\n\n# Wrap the model in a machine\nundersampler = ClusterUndersampler(mode=\"nearest\", ratios=Dict(0=>1.0, 1=> 1.0, 2=>1.0), rng=42)\nmach = machine(undersampler)\n\n# Provide the data to transform (there is nothing to fit)\nX_under, y_under = transform(mach, X, y)\n\nYou can read more about this MLJ interface here.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 100\nnum_features = 5\ny_ind = 3\nXy, _ = generate_imbalanced_data(num_rows, num_features; \n                                 probs=[0.5, 0.2, 0.3], insert_y=y_ind, rng=42)\n\n# Initiate ClusterUndersampler model\nundersampler = ClusterUndersampler(y_ind; mode=\"nearest\", \n                                   ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nXy_under = Xy |> undersampler                    \nXy_under, cache = TableTransforms.apply(undersampler, Xy)    # equivalently\n\nThe reapply(undersampler, Xy, cache) method from TableTransforms simply falls back to apply(undersample, Xy) and the revert(undersampler, Xy, cache) is not supported.\n\nReferences\n\n[1] Wei-Chao, L., Chih-Fong, T., Ya-Han, H., & Jing-Shang, J. (2017).      Clustering-based undersampling in class-imbalanced data. Information Sciences, 409–410, 17–26.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#Edited-Nearest-Neighbors-Undersampler","page":"Algorithms","title":"Edited Nearest Neighbors Undersampler","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"enn_undersample","category":"page"},{"location":"algorithms/#Imbalance.enn_undersample","page":"Algorithms","title":"Imbalance.enn_undersample","text":"enn_undersample(\n    X, y; k = 5, keep_condition = \"mode\",\n    min_ratios = 1.0, force_min_ratios = false,\n    rng = default_rng(), try_preserve_type=true\n)\n\nDescription\n\nUndersample a dataset by removing points that violate a certain condition such as     belonging to a different class compared to the majority of the neighbors, as proposed in [1].\n\nPositional Arguments\n\nX: A matrix or table of floats where each row is an observation from the dataset \ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\n\nKeyword Arguments\n\nk::Integer=5: Number of nearest neighbors to consider in the algorithm. Should be within the range 0 < k < n where n is the number of observations in the data. It will be automatically set to n-1 if n ≤ k.\n\nkeep_condition::AbstractString=\"mode\": The condition that leads to removing a point upon violation. Takes one of \"exists\", \"mode\", \"only mode\" and \"all\"\n\"exists\": the point has at least one neighbor from the same class\n\"mode\": the class of the point is one of the most frequent classes of the neighbors (there may be many)\n\"only mode\": the class of the point is the single most frequent class of the neighbors\n\"all\": the class of the point is the same as all the neighbors\n\nmin_ratios=1.0: A parameter that controls the maximum amount of undersampling to be done for each class. If this algorithm   cleans the data to an extent that this is violated, some of the cleaned points will be revived randomly so that it is satisfied.\nCan be a float and in this case each class will be at most undersampled to the size of the minority class times the float. By default, all classes are undersampled to the size of the minority class\nCan be a dictionary mapping each class label to the float minimum ratio for that class\n\nforce_min_ratios=false: If true, and this algorithm cleans the data such that the ratios for each class   exceed those specified in min_ratios then further undersampling will be perform so that the final ratios   are equal to min_ratios.\n\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nX_under: A matrix or table that includes the data after undersampling    depending on whether the input X is a matrix or table respectively\ny_under: An abstract vector of labels corresponding to X_under\n\nExample\n\nusing Imbalance\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows, num_continuous_feats = 100, 5\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, rng=42)                       \njulia> checkbalance(y; ref=\"minority\")\n1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 33 (173.7%) \n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 48 (252.6%) \n\n# apply enn undersampling\nX_under, y_under = enn_undersample(X, y; k=3, keep_condition=\"only mode\", \n                                   min_ratios=0.5, rng=42)\njulia> checkbalance(y_under)\n2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 10 (37.0%) \n1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 10 (37.0%) \n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 27 (100.0%) \n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the ENNUndersampler model and pass the      positional arguments to the transform method. \n\nusing MLJ\nENNUndersampler = @load ENNUndersampler pkg=Imbalance\n\n# Wrap the model in a machine\nundersampler = ENNUndersampler(k=5, min_ratios=1.0, rng=42)\nmach = machine(undersampler)\n\n# Provide the data to transform (there is nothing to fit)\nX_under, y_under = transform(mach, X, y)\n\nYou can read more about this MLJ interface here.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 100\nnum_features = 5\ny_ind = 3\nXy, _ = generate_imbalanced_data(num_rows, num_features; \n                                 probs=[0.5, 0.2, 0.3], insert_y=y_ind, rng=42)\n\n# Initiate ENN Undersampler model\nundersampler = ENNUndersampler(y_ind; min_ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nXy_under = Xy |> undersampler                    \nXy_under, cache = TableTransforms.apply(undersampler, Xy)    # equivalently\n\nThe reapply(undersampler, Xy, cache) method from TableTransforms simply falls back to apply(undersample, Xy) and the revert(undersampler, Xy, cache) is not supported.\n\nReferences\n\n[1] Dennis L Wilson. Asymptotic properties of nearest neighbor rules using edited data.  \tIEEE Transactions on Systems, Man, and Cybernetics, pages 408–421, 1972.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#Tomek-Links-Undersampler","page":"Algorithms","title":"Tomek Links Undersampler","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms","title":"Algorithms","text":"tomek_undersample","category":"page"},{"location":"algorithms/#Imbalance.tomek_undersample","page":"Algorithms","title":"Imbalance.tomek_undersample","text":"tomek_undersample(\n    X, y;\n    min_ratios = 1.0, force_min_ratios = false,\n    rng = default_rng(), try_preserve_type=true\n)\n\nDescription\n\nUndersample a dataset by removing (\"cleaning\") any point that is part of a tomek link in the data.  \tTomek links are presented in [1].\n\nPositional Arguments\n\nX: A matrix or table of floats where each row is an observation from the dataset \ny: An abstract vector of labels (e.g., strings) that correspond to the observations in X\n\nKeyword Arguments\n\nmin_ratios=1.0: A parameter that controls the maximum amount of undersampling to be done for each class. If this algorithm   cleans the data to an extent that this is violated, some of the cleaned points will be revived randomly so that it is satisfied.\nCan be a float and in this case each class will be at most undersampled to the size of the minority class times the float. By default, all classes are undersampled to the size of the minority class\nCan be a dictionary mapping each class label to the float minimum ratio for that class\n\nforce_min_ratios=false: If true, and this algorithm cleans the data such that the ratios for each class   exceed those specified in min_ratios then further undersampling will be perform so that the final ratios   are equal to min_ratios.\n\nrng::Union{AbstractRNG, Integer}: Either an AbstractRNG object or an Integer    seed to be used with Xoshiro\n\ntry_preserve_type::Bool=true: Defaults to true and means that the function will try to preserve the type of the input    table (e.g., DataFrame). However, for some tables this may not succeed and in this case the table returned will   be a column table (named-tuple of vectors).\n\nReturns\n\nX_under: A matrix or table that includes the data after undersampling    depending on whether the input X is a matrix or table respectively\ny_under: An abstract vector of labels corresponding to X_under\n\nExample\n\nusing Imbalance\n\n# set probability of each class\nprobs = [0.5, 0.2, 0.3]                         \nnum_rows, num_continuous_feats = 100, 5\n# generate a table and categorical vector accordingly\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; \n                                probs, rng=42)                       \njulia> checkbalance(y; ref=\"minority\")\n1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 33 (173.7%) \n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 48 (252.6%) \n\n# apply enn undersampling\nX_under, y_under = tomek_undersample(X, y; min_ratios=1.0, rng=42)\njulia> checkbalance(y_under)\n1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 19 (100.0%) \n2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 22 (115.8%) \n0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 36 (189.5%) \n\nMLJ Model Interface\n\nSimply pass the keyword arguments while initiating the TomekUndersampler model and pass the      positional arguments to the transform method. \n\nusing MLJ\nTomekUndersampler = @load TomekUndersampler pkg=Imbalance\n\n# Wrap the model in a machine\nundersampler = TomekUndersampler(ratios=1.0, rng=42)\nmach = machine(undersampler)\n\n# Provide the data to transform (there is nothing to fit)\nX_under, y_under = transform(mach, X, y)\n\nYou can read more about this MLJ interface here.\n\nTableTransforms Interface\n\nThis interface assumes that the input is one table Xy and that y is one of the columns. Hence, an integer y_ind     must be specified to the constructor to specify which column y is followed by other keyword arguments.      Only Xy is provided while applying the transform.\n\nusing Imbalance\nusing Imbalance.TableTransforms\n\n# Generate imbalanced data\nnum_rows = 100\nnum_features = 5\ny_ind = 3\nXy, _ = generate_imbalanced_data(num_rows, num_features; \n                                 probs=[0.5, 0.2, 0.3], insert_y=y_ind, rng=42)\n\n# Initiate TomekUndersampler model\nundersampler = TomekUndersampler(y_ind; min_ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nXy_under = Xy |> undersampler                    \nXy_under, cache = TableTransforms.apply(undersampler, Xy)    # equivalently\n\nThe reapply(undersampler, Xy, cache) method from TableTransforms simply falls back to apply(undersample, Xy) and the revert(undersampler, Xy, cache) is not supported.\n\nReferences\n\n[1] Ivan Tomek. Two modifications of cnn. IEEE Trans. Systems, Man and Cybernetics, 6:769–772, 1976.\n\n\n\n\n\n","category":"function"},{"location":"examples/","page":"Examples","title":"Examples","text":"\n\n  <div class=\"grid\">\n    <div class=\"grid-item\">\n  <a href=\"https://colab.research.google.com/github/JuliaAI/Imbalance.jl/blob/Doc-Examples/examples/effect_of_ratios.ipynb\"><img id=\"colab\" src=\"./assets/colab.png\"/></a>\n  <a href=\"./effect_of_ratios/effect_of_ratios\">\n  <img src=\"./assets/iris smote.jpeg\" alt=\"Image\">\n  <div class=\"item-title\">Effect of Ratios Hyperparameter\n  <p>In this tutorial we use an SVM and SMOTE and the Iris data to study \n                      how the decision regions change with the amount of oversampling</p>\n  </div>\n  </a>\n</div>\n  <div class=\"grid-item\">\n  <a href=\"https://colab.research.google.com/github/JuliaAI/Imbalance.jl/blob/Doc-Examples/examples/effect_of_s.ipynb\"><img id=\"colab\" src=\"./assets/colab.png\"/></a>\n  <a href=\"./effect_of_s/effect_of_s\">\n  <img src=\"./assets/iris rose.jpeg\" alt=\"Image\">\n  <div class=\"item-title\">From Random Oversampling to ROSE\n  <p>In this tutorial we study the `s` parameter in rose and the effect\n                        of increasing it.</p>\n  </div>\n  </a>\n</div>\n  <div class=\"grid-item\">\n  <a href=\"https://colab.research.google.com/github/JuliaAI/Imbalance.jl/blob/Doc-Examples/examples/smote_churn_dataset.ipynb\"><img id=\"colab\" src=\"./assets/colab.png\"/></a>\n  <a href=\"./smote_churn_dataset/smote_churn_dataset\">\n  <img src=\"./assets/churn smote.jpeg\" alt=\"Image\">\n  <div class=\"item-title\">SMOTE on Customer Churn Data\n  <p>In this tutorial we apply SMOTE and random forest to predict customer churn based \n                        on continuous attributes.</p>\n  </div>\n  </a>\n</div>\n  <div class=\"grid-item\">\n  <a href=\"https://colab.research.google.com/github/JuliaAI/Imbalance.jl/blob/Doc-Examples/examples/smoten_mushroom.ipynb\"><img id=\"colab\" src=\"./assets/colab.png\"/></a>\n  <a href=\"./smoten_mushroom/smoten_mushroom\">\n  <img src=\"./assets/mushy.jpeg\" alt=\"Image\">\n  <div class=\"item-title\">SMOTEN on Mushroom Data\n  <p>In this tutorial we use a purely categorical dataset to predict mushroom odour.</p>\n  </div>\n  </a>\n</div>\n  <div class=\"grid-item\">\n  <a href=\"https://colab.research.google.com/github/JuliaAI/Imbalance.jl/blob/Doc-Examples/examples/smotenc_churn_dataset.ipynb\"><img id=\"colab\" src=\"./assets/colab.png\"/></a>\n  <a href=\"./smotenc_churn_dataset/smotenc_churn_dataset\">\n  <img src=\"./assets/churn smoten.jpeg\" alt=\"Image\">\n  <div class=\"item-title\">SMOTENC on Customer Churn Data\n  <p>In this tutorial we extend the SMOTE tutorial to include both categorical and continuous\n                        data for churn prediction</p>\n  </div>\n  </a>\n</div>\n\n  </div>\n\n","category":"page"},{"location":"#Imbalance.jl","page":"Introduction","title":"Imbalance.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: Imbalance)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"A Julia package with resampling methods to correct for class imbalance in a wide variety of classification settings.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"import Pkg;\nPkg.add(\"Imbalance\")","category":"page"},{"location":"#Quick-Start","page":"Introduction","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"We will illustrate using the package to oversample withSMOTE; however, all other implemented oversampling methods follow the same pattern.","category":"page"},{"location":"#Standard-API","page":"Introduction","title":"Standard API","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"All methods by default support a pure functional interface.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Imbalance\n\n# Set dataset properties then generate imbalanced data\nprobs = [0.5, 0.2, 0.3]                  # probability of each class      \nnum_rows, num_continuous_feats = 100, 5\nX, y = generate_imbalanced_data(num_rows, num_continuous_feats; probs, rng=42)      \n\n# Apply SMOTE to oversample the classes\nXover, yover = smote(X, y; k=5, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\n","category":"page"},{"location":"#MLJ-Interface","page":"Introduction","title":"MLJ Interface","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"All methods support the MLJ interface where instead of directly calling the method, one instantiates a model for the method while optionally passing the keyword parameters found in the functional interface then wraps the model in a machine and follows by calling transform on the machine and data.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using MLJ\n\n# Load the model\nSMOTE = @load SMOTE pkg=Imbalance\n\n# Create an instance of the model \noversampler = SMOTE(k=5, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\n\n# Wrap it in a machine\nmach = machine(oversampler)\n\n# Provide the data to transform \nXover, yover = transform(mach, X, y)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"All implemented oversampling methods are considered static transforms and hence, no fit is required. ","category":"page"},{"location":"#Table-Transforms-Interface","page":"Introduction","title":"Table Transforms Interface","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The TableTransforms interface operates on single tables; it assumes that y is one of the columns of the given table. Thus, it follows a similar pattern to the MLJ interface except that the index of y is a required argument while instantiating the model and the data to be transformed via apply is only one table Xy.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Imbalance\nusing TableTransforms\n\n# Generate imbalanced data\nnum_rows = 200\nnum_features = 5\ny_ind = 3\nXy, _ = generate_imbalanced_data(num_rows, num_features; \n                                 probs=[0.5, 0.2, 0.3], insert_y=y_ind, rng=42)\n\n# Initiate SMOTE model\noversampler = SMOTE_t(y_ind; k=5, ratios=Dict(0=>1.0, 1=> 0.9, 2=>0.8), rng=42)\nXyover = Xy |> oversampler       # can chain with other table transforms                  \nXyover, cache = TableTransforms.apply(oversampler, Xy)    # equivalently","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The reapply(oversampler, Xy, cache) method from TableTransforms simply falls back to apply(oversample, Xy) and the revert(oversampler, Xy, cache) reverts the transform by removing the oversampled observations from the table.","category":"page"},{"location":"#Features","page":"Introduction","title":"Features","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Provides some of the most sought oversampling algorithms in machine learning\nSupports multi-class classification and both nominal and continuous features\nGeneric by supporting table input/output formats as well as matrices\nProvides MLJ and TableTransforms interfaces aside from the default pure functional interface\nSupports tables regardless to whether the target is a separate column or one of the columns\nSupports automatic encoding and decoding of nominal features","category":"page"},{"location":"#Methods","page":"Introduction","title":"Methods","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The package provides five oversampling algorithms that all work in multi-class settings and with options for handling continuous and nominal features. In particular, it implements:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Basic Random Oversampling \nRandom Oversampling Examples (ROSE)\nSynthetic Minority Oversampling Technique (SMOTE)\nSMOTE-Nominal (SMOTE-N)\nSMOTE-Nominal Categorical (SMOTE-NC)","category":"page"},{"location":"#Rationale","page":"Introduction","title":"Rationale","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Most if not all machine learning algorithms can be viewed as a form of empirical risk minimization where the object is to find the parameters theta that for some loss function L minimize ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"hattheta = argmin_theta frac1N sum_i=1^N L(f_theta(x_i) y_i)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The underlying assumption is that minimizing this empirical risk corresponds to approximately minimizing the true risk which considers all examples in the populations which would imply that f_theta is approximately the true target function f that we seek to model.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"In a multi-class setting with K classes, one can write","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"hattheta = argmin_theta left( frac1N_1 sum_i in C_1 L(f_theta(x_i) y_i) + frac1N_2 sum_i in C_2 L(f_theta(x_i) y_i) + ldots + frac1N_K sum_i in C_K L(f_theta(x_i) y_i) right)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Class imbalance occurs when some classes have much fewer examples than other classes. In this case, the corresponding terms contribute minimally to the sum which makes it easier for any learning algorithm to find an approximate solution to the empirical risk that mostly only minimizes the over the significant sums. This yields a hypothesis f_theta that may be very different from the true target f with respect to the minority classes which may be the most important for the application in question.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"One obvious possible remedy is to weight the smaller sums so that a learning algorithm more easily avoids approximate solutions that exploit their insignificance which can be seen to be equivalent to repeating examples of the observations in minority classes. This can be achieved by naive random oversampling which is offered by this package along with other more advanced oversampling methods.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"To our knowledge, there are no existing maintained Julia packages that implement oversampling algorithms for multi-class classification problems or that handle both nominal and continuous features. This has served as a primary motivation for the creation of this package.","category":"page"}]
}
