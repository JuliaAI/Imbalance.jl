{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868ff3bb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069654fa",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "using Random\n",
    "using CSV\n",
    "using DataFrames\n",
    "using MLJ\n",
    "using ScientificTypes\n",
    "using Imbalance\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef62430",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Let's load the Iris dataset, the objective of this dataset is to predict the type of flower as one of \"virginica\", \"versicolor\" and \"setosa\" using its sepal and petal length and width. \n",
    "\n",
    "We don't need to so from a CSV file this time because `MLJ` has a macro for loading it already! The only difference is that we will need to explictly convert it to a dataframe as `MLJ` loads it as a named tuple of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e82aef7",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬─────────────┬──────────────┬─────────────┐\n",
      "│\u001b[1m sepal_length \u001b[0m│\u001b[1m sepal_width \u001b[0m│\u001b[1m petal_length \u001b[0m│\u001b[1m petal_width \u001b[0m│\n",
      "│\u001b[90m Float64      \u001b[0m│\u001b[90m Float64     \u001b[0m│\u001b[90m Float64      \u001b[0m│\u001b[90m Float64     \u001b[0m│\n",
      "│\u001b[90m Continuous   \u001b[0m│\u001b[90m Continuous  \u001b[0m│\u001b[90m Continuous   \u001b[0m│\u001b[90m Continuous  \u001b[0m│\n",
      "├──────────────┼─────────────┼──────────────┼─────────────┤\n",
      "│ 5.1          │ 3.5         │ 1.4          │ 0.2         │\n",
      "│ 4.9          │ 3.0         │ 1.4          │ 0.2         │\n",
      "│ 4.7          │ 3.2         │ 1.3          │ 0.2         │\n",
      "│ 4.6          │ 3.1         │ 1.5          │ 0.2         │\n",
      "│ 5.0          │ 3.6         │ 1.4          │ 0.2         │\n",
      "└──────────────┴─────────────┴──────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "X, y = @load_iris\n",
    "X = DataFrame(X)\n",
    "first(X, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1903cc",
   "metadata": {},
   "source": [
    "Our purpose for this tutorial is primarily visuallization. Thus, let's select two of the continuous features only to work with. It's known that the sepal length and width play a much bigger role in classifying the type of flower so let's keep those only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba07434",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────┬──────────────┐\n",
      "│\u001b[1m petal_width \u001b[0m│\u001b[1m petal_length \u001b[0m│\n",
      "│\u001b[90m Float64     \u001b[0m│\u001b[90m Float64      \u001b[0m│\n",
      "│\u001b[90m Continuous  \u001b[0m│\u001b[90m Continuous   \u001b[0m│\n",
      "├─────────────┼──────────────┤\n",
      "│ 0.2         │ 1.4          │\n",
      "│ 0.2         │ 1.4          │\n",
      "│ 0.2         │ 1.3          │\n",
      "│ 0.2         │ 1.5          │\n",
      "│ 0.2         │ 1.4          │\n",
      "└─────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "X = select(X, :petal_width, :petal_length)\n",
    "first(X, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942b555",
   "metadata": {},
   "source": [
    "## Coercing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375d2db8",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────┬────────────┬─────────┐\n",
       "│\u001b[22m names        \u001b[0m│\u001b[22m scitypes   \u001b[0m│\u001b[22m types   \u001b[0m│\n",
       "├──────────────┼────────────┼─────────┤\n",
       "│ petal_width  │ Continuous │ Float64 │\n",
       "│ petal_length │ Continuous │ Float64 │\n",
       "└──────────────┴────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ScientificTypes.schema(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc6fa3",
   "metadata": {},
   "source": [
    "Things look good, no coercion is needed.\n",
    "\n",
    "## Oversampling\n",
    "\n",
    "Iris, by default has no imbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "379234ea",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%) \n",
      "setosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%) \n",
      "versicolor: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 50 (100.0%) \n"
     ]
    }
   ],
   "source": [
    "checkbalance(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2798a22",
   "metadata": {},
   "source": [
    "To simulate that there is a balance problem, we will consider a random sample of 100 observations. A random sample does not guarantee perserving the proportion of classes; in this, we actually set the seed to get a very unlikely random sample that suffers from strong imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08452d66",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor: ▇▇▇▇▇▇▇▇▇▇▇ 12 (22.6%) \n",
      "setosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 35 (66.0%) \n",
      "virginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%) \n"
     ]
    }
   ],
   "source": [
    "Random.seed!(803429)\n",
    "subset_indices = rand(1:size(X, 1), 100)\n",
    "X, y = X[subset_indices, :], y[subset_indices]\n",
    "checkbalance(y)         # comes from Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa89dd5",
   "metadata": {},
   "source": [
    "We will treat this as our training set going forward so we don't need to partition. Now let's oversample it with ROSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b09a9951",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mProgress:  67%|███████████████████████████▍             |  ETA: 0:00:00\u001b[39m\u001b[K\r\n",
      "\u001b[34m  class:  versicolor\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%) \n",
      "setosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%) \n",
      "versicolor: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 53 (100.0%) \n"
     ]
    }
   ],
   "source": [
    "Xover, yover = rose(X, y; s=0.3, ratios=Dict(\"versicolor\" => 1.0, \"setosa\"=>1.0))\n",
    "checkbalance(yover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5dfb2",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a01f3d",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n",
       " (name = AdaBoostClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianLDA, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianQDA, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = CatBoostClassifier, package_name = CatBoost, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = BetaML, ... )\n",
       " ⋮\n",
       " (name = SGDClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVMLinearClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVMNuClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = StableForestClassifier, package_name = SIRUS, ... )\n",
       " (name = StableRulesClassifier, package_name = SIRUS, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models(matching(Xover, yover))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edce49b",
   "metadata": {},
   "source": [
    "Let's go for a [Decision Tree](https://alan-turing-institute.github.io/MLJ.jl/dev/models/DecisionTreeClassifier_DecisionTree/#DecisionTreeClassifier_DecisionTree). This is just like the normal perceptron but it learns the separating hyperplane in a higher dimensional space using the kernel trick so that it corresponds to a nonlinear separating hypersurface in the original space. This isn't necessarily helpful in our case, but just to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d708ca0c",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Documents/GitHub/Imbalance.jl/Project.toml`\n",
      " \u001b[90m [6f286f6a] \u001b[39m\u001b[92m+ MultivariateStats v0.10.2\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Documents/GitHub/Imbalance.jl/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \u001b[90m [7d9fca2a] \u001b[39m\u001b[92m+ Arpack v0.5.4\u001b[39m\n",
      " \u001b[90m [6f286f6a] \u001b[39m\u001b[92m+ MultivariateStats v0.10.2\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m\u001b[90m [68821587] \u001b[39m\u001b[92m+ Arpack_jll v3.5.1+1\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"MultivariateStats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2f0e0",
   "metadata": {},
   "source": [
    "### Before Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2601606",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJMultivariateStatsInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/essam/.julia/packages/MLJModels/7apZ3/src/loading.jl:159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: BayesianLDA(method = gevd, …)\n",
       "  args: \n",
       "    1:\tSource @008 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @604 ⏎ AbstractVector{Multiclass{3}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load the model\n",
    "BayesianLDA = @load BayesianLDA pkg=MultivariateStats\n",
    "\n",
    "# 2. Instantiate it \n",
    "model = BayesianLDA()\n",
    "\n",
    "# 3. Wrap it with the data in a machine\n",
    "mach = machine(model, X, y)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach, verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24400b61",
   "metadata": {},
   "source": [
    "### After Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3997117b",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: BayesianLDA(method = gevd, …)\n",
       "  args: \n",
       "    1:\tSource @447 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @477 ⏎ AbstractVector{Multiclass{3}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Wrap it with the data in a machine\n",
    "mach_over = machine(model, Xover, yover)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach_over, verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784ac0e",
   "metadata": {},
   "source": [
    "## Plot Decision Boundaries\n",
    "\n",
    "Construct ranges for each feature and consecutively a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76ddfe71",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200×200 Matrix{Tuple{Float64, Float64}}:\n",
       " (-0.9, 0.2)       (-0.9, 0.238693)       …  (-0.9, 7.9)\n",
       " (-0.878894, 0.2)  (-0.878894, 0.238693)     (-0.878894, 7.9)\n",
       " (-0.857789, 0.2)  (-0.857789, 0.238693)     (-0.857789, 7.9)\n",
       " (-0.836683, 0.2)  (-0.836683, 0.238693)     (-0.836683, 7.9)\n",
       " (-0.815578, 0.2)  (-0.815578, 0.238693)     (-0.815578, 7.9)\n",
       " (-0.794472, 0.2)  (-0.794472, 0.238693)  …  (-0.794472, 7.9)\n",
       " (-0.773367, 0.2)  (-0.773367, 0.238693)     (-0.773367, 7.9)\n",
       " (-0.752261, 0.2)  (-0.752261, 0.238693)     (-0.752261, 7.9)\n",
       " (-0.731156, 0.2)  (-0.731156, 0.238693)     (-0.731156, 7.9)\n",
       " (-0.71005, 0.2)   (-0.71005, 0.238693)      (-0.71005, 7.9)\n",
       " ⋮                                        ⋱  \n",
       " (3.13116, 0.2)    (3.13116, 0.238693)       (3.13116, 7.9)\n",
       " (3.15226, 0.2)    (3.15226, 0.238693)       (3.15226, 7.9)\n",
       " (3.17337, 0.2)    (3.17337, 0.238693)       (3.17337, 7.9)\n",
       " (3.19447, 0.2)    (3.19447, 0.238693)       (3.19447, 7.9)\n",
       " (3.21558, 0.2)    (3.21558, 0.238693)    …  (3.21558, 7.9)\n",
       " (3.23668, 0.2)    (3.23668, 0.238693)       (3.23668, 7.9)\n",
       " (3.25779, 0.2)    (3.25779, 0.238693)       (3.25779, 7.9)\n",
       " (3.27889, 0.2)    (3.27889, 0.238693)       (3.27889, 7.9)\n",
       " (3.3, 0.2)        (3.3, 0.238693)           (3.3, 7.9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "petal_width_range =\n",
    "\trange(minimum(X.petal_width) - 1, maximum(X.petal_width) + 1, length = 200)\n",
    "petal_length_range =\n",
    "\trange(minimum(X.petal_length) - 1, maximum(X.petal_length) + 1, length = 200)\n",
    "grid_points = [(pw, pl) for pw in petal_width_range, pl in petal_length_range]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7e7f0",
   "metadata": {},
   "source": [
    "Evaluate the grid with the machine before and after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39231d34",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200×200 CategoricalArrays.CategoricalArray{String,2,UInt32}:\n",
       " \"setosa\"     \"setosa\"     \"setosa\"     …  \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"     …  \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n",
       " \"setosa\"     \"setosa\"     \"setosa\"        \"versicolor\"  \"versicolor\"\n",
       " ⋮                                      ⋱                \n",
       " \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n",
       " \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n",
       " \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n",
       " \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n",
       " \"virginica\"  \"virginica\"  \"virginica\"  …  \"virginica\"   \"virginica\"\n",
       " \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n",
       " \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n",
       " \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\"\n",
       " \"virginica\"  \"virginica\"  \"virginica\"     \"virginica\"   \"virginica\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_predictions = [\n",
    "\tpredict_mode(mach, Tables.table(reshape(collect(point), 1, 2)))[1] for\n",
    "\tpoint in grid_points\n",
    "]\n",
    "grid_predictions_over = [\n",
    "\tpredict_mode(mach_over, Tables.table(reshape(collect(point), 1, 2)))[1] for\n",
    "\tpoint in grid_points\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adb8882",
   "metadata": {},
   "source": [
    "Make two contour plots using the grid predictions before and after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a52db10c",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p = contourf(petal_length_range, petal_width_range, grid_predictions,\n",
    "\tlevels = 3, color = :Set3_3, colorbar = false)\n",
    "p_over = contourf(petal_length_range, petal_width_range, grid_predictions_over,\n",
    "\tlevels = 3, color = :Set3_3, colorbar = false)\n",
    "println()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4429c8",
   "metadata": {},
   "source": [
    "Scatter plot the data before and after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cc40d",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "labels = unique(y)\n",
    "colors = Dict(\"setosa\" => \"green\", \"versicolor\" => \"yellow\",\n",
    "\t\"virginica\" => \"purple\")\n",
    "\n",
    "for label in labels\n",
    "\tscatter!(p, X.petal_length[y.==label], X.petal_width[y.==label],\n",
    "\t\tcolor = colors[label], label = label,\n",
    "\t\ttitle = \"Before Oversampling\")\n",
    "\tscatter!(p_over, Xover.petal_length[yover.==label], Xover.petal_width[yover.==label],\n",
    "\t\tcolor = colors[label], label = label,\n",
    "\t\ttitle = \"After Oversampling\")\n",
    "end\n",
    "\n",
    "plot_res = plot(\n",
    "\tp,\n",
    "\tp_over,\n",
    "\tlayout = (1, 2),\n",
    "\txlabel = \"petal length\",\n",
    "\tylabel = \"petal width\",\n",
    "\tsize = (900, 300),\n",
    ")\n",
    "savefig(plot_res, \"./ROSE-before-after.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0344bc1",
   "metadata": {},
   "source": [
    "![Before After ROSE](https://i.imgur.com/85leARg.png)\n",
    "\n",
    "## Effect of Increasing `s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d621cb4",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "anim = @animate for s ∈ 0:0.03:6.0\n",
    "\t# oversample\n",
    "\tXover, yover =\n",
    "\t\trose(X, y; s = s, ratios = Dict(\"setosa\" => 1.0, \"versicolor\" => 1.0), rng = 42)\n",
    "\n",
    "\tmodel = BayesianLDA()\t\n",
    "\tmach_over = machine(model, Xover, yover)\n",
    "\tfit!(mach_over, verbosity = 0)\n",
    "\n",
    "\t# grid predictions\n",
    "\tgrid_predictions_over = [\n",
    "\t\tpredict_mode(mach_over, Tables.table(reshape(collect(point), 1, 2)))[1] for\n",
    "\t\tpoint in grid_points\n",
    "\t]\n",
    "\n",
    "\tp_over = contourf(petal_length_range, petal_width_range, grid_predictions_over,\n",
    "\t\tlevels = 3, color = :Set3_3, colorbar = false)\n",
    "\n",
    "\tfor label in labels\n",
    "\t\tscatter!(p_over, Xover.petal_length[yover.==label],\n",
    "\t\t\tXover.petal_width[yover.==label],\n",
    "\t\t\tcolor = colors[label], label = label,\n",
    "\t\t\ttitle = \"Oversampling with s=$s\")\n",
    "\tend\n",
    "\tplot!(dpi = 150)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbfa966f",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved animation to /Users/essam/Documents/GitHub/Imbalance.jl/docs/src/examples/effect_of_s/rose-animation.gif\n",
      "└ @ Plots /Users/essam/.julia/packages/Plots/3BCH5/src/animation.jl:156\n"
     ]
    }
   ],
   "source": [
    "gif(anim, \"./rose-animation.gif\", fps=6)\n",
    "println()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5510b9d",
   "metadata": {},
   "source": [
    "![ROSE Effect of S](https://gcdnb.pbrd.co/images/RFbcAmPKNvKu.gif?o=1)\n",
    "\n",
    "As we can see, the larger `s` is the more spread out are the oversampled points. This is expected because what ROSE does is oversample by sampling from the distribution that corresponds to placing Gaussians on the existing points and `s` is a hyperparameter proportional to the bandwidth of the Gaussians. When `s=0` the only points that can be generated lie on top of others; i.e., ROSE becomes equivalent to random oversampling\n",
    "\n",
    "The decision boundary is mainly unstable because we used a small number of epochs with the perceptron to generate this animation. It still took plenty of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8305a808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook effect_of_s.ipynb to markdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Writing 14952 bytes to effect_of_s.md\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append(\"..\");\n",
    "from convert import convert_to_md;\n",
    "convert_to_md('effect_of_s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
