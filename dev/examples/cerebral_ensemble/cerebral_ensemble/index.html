<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Balanced Bagging for Cerebral Stroke Prediction · Imbalance.jl</title><meta name="title" content="Balanced Bagging for Cerebral Stroke Prediction · Imbalance.jl"/><meta property="og:title" content="Balanced Bagging for Cerebral Stroke Prediction · Imbalance.jl"/><meta property="twitter:title" content="Balanced Bagging for Cerebral Stroke Prediction · Imbalance.jl"/><meta name="description" content="Documentation for Imbalance.jl."/><meta property="og:description" content="Documentation for Imbalance.jl."/><meta property="twitter:description" content="Documentation for Imbalance.jl."/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css?family=Montserratwght@100;200;300;400;500;600;700;800;900|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.gif" alt="Imbalance.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">Imbalance.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Introduction</a></li><li><span class="tocitem">Algorithms</span><ul><li><a class="tocitem" href="../../../algorithms/oversampling_algorithms/">Oversampling</a></li><li><a class="tocitem" href="../../../algorithms/undersampling_algorithms/">Undersampling</a></li><li><a class="tocitem" href="../../../algorithms/mlj_balancing/">Combination</a></li><li><a class="tocitem" href="../../../algorithms/implementation_notes/">Implementation Notes</a></li><li><a class="tocitem" href="../../../algorithms/extra_algorithms/">Extras</a></li></ul></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../../walkthrough/">Introduction</a></li><li><a class="tocitem" href="../../">More Examples</a></li><li><a class="tocitem" href="../../Colab/">Google Colab</a></li></ul></li><li><a class="tocitem" href="../../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../../about/">About</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Balanced Bagging for Cerebral Stroke Prediction</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Balanced Bagging for Cerebral Stroke Prediction</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaAI/Imbalance.jl/" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Balanced-Bagging-for-Cerebral-Stroke-Prediction"><a class="docs-heading-anchor" href="#Balanced-Bagging-for-Cerebral-Stroke-Prediction">Balanced Bagging for Cerebral Stroke Prediction</a><a id="Balanced-Bagging-for-Cerebral-Stroke-Prediction-1"></a><a class="docs-heading-anchor-permalink" href="#Balanced-Bagging-for-Cerebral-Stroke-Prediction" title="Permalink"></a></h1><pre><code class="language-julia hljs">import Pkg;
Pkg.add([&quot;Random&quot;, &quot;CSV&quot;, &quot;DataFrames&quot;, &quot;MLJ&quot;, &quot;Imbalance&quot;, &quot;MLJBalancing&quot;, 
         &quot;ScientificTypes&quot;,&quot;Impute&quot;, &quot;StatsBase&quot;,  &quot;Plots&quot;, &quot;Measures&quot;, &quot;HTTP&quot;])

using Random
using CSV
using DataFrames
using MLJ
using Imbalance
using MLJBalancing
using StatsBase
using ScientificTypes
using Plots, Measures
using Impute
using HTTP: download</code></pre><h2 id="Loading-Data"><a class="docs-heading-anchor" href="#Loading-Data">Loading Data</a><a id="Loading-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Loading-Data" title="Permalink"></a></h2><p>In this example, we will consider the <a href="https://www.kaggle.com/datasets/shashwatwork/cerebral-stroke-predictionimbalaced-dataset">Cerebral Stroke Prediction Dataset</a> found on Kaggle for the objective of predicting where a stroke has occurred given medical features about patients.</p><p><code>CSV</code> gives us the ability to easily read the dataset after it&#39;s downloaded as follows</p><pre><code class="language-julia hljs">download(&quot;https://raw.githubusercontent.com/JuliaAI/Imbalance.jl/dev/docs/src/examples/cerebral_ensemble/cerebral.csv&quot;)
df = CSV.read(&quot;./cerebral.csv&quot;, DataFrame)

# Display the first 5 rows with DataFrames
first(df, 5) |&gt; pretty</code></pre><pre><code class="nohighlight hljs">┌───────┬─────────┬────────────┬──────────────┬───────────────┬──────────────┬──────────────┬────────────────┬───────────────────┬────────────────────────────┬──────────────────────────┬────────┐
│ id    │ gender  │ age        │ hypertension │ heart_disease │ ever_married │ work_type    │ Residence_type │ avg_glucose_level │ bmi                        │ smoking_status           │ stroke │
│ Int64 │ String7 │ Float64    │ Int64        │ Int64         │ String3      │ String15     │ String7        │ Float64           │ Union{Missing, Float64}    │ Union{Missing, String15} │ Int64  │
│ Count │ Textual │ Continuous │ Count        │ Count         │ Textual      │ Textual      │ Textual        │ Continuous        │ Union{Missing, Continuous} │ Union{Missing, Textual}  │ Count  │
├───────┼─────────┼────────────┼──────────────┼───────────────┼──────────────┼──────────────┼────────────────┼───────────────────┼────────────────────────────┼──────────────────────────┼────────┤
│ 30669 │ Male    │ 3.0        │ 0            │ 0             │ No           │ children     │ Rural          │ 95.12             │ 18.0                       │ missing                  │ 0      │
│ 30468 │ Male    │ 58.0       │ 1            │ 0             │ Yes          │ Private      │ Urban          │ 87.96             │ 39.2                       │ never smoked             │ 0      │
│ 16523 │ Female  │ 8.0        │ 0            │ 0             │ No           │ Private      │ Urban          │ 110.89            │ 17.6                       │ missing                  │ 0      │
│ 56543 │ Female  │ 70.0       │ 0            │ 0             │ Yes          │ Private      │ Rural          │ 69.04             │ 35.9                       │ formerly smoked          │ 0      │
│ 46136 │ Male    │ 14.0       │ 0            │ 0             │ No           │ Never_worked │ Rural          │ 161.28            │ 19.1                       │ missing                  │ 0      │
└───────┴─────────┴────────────┴──────────────┴───────────────┴──────────────┴──────────────┴────────────────┴───────────────────┴────────────────────────────┴──────────────────────────┴────────┘</code></pre><p>It&#39;s obvious that the <code>id</code> column is useless for predictions so we may as well drop it.</p><pre><code class="language-julia hljs">df = df[:, Not(:id)]
first(df, 5) |&gt; pretty</code></pre><pre><code class="nohighlight hljs">┌─────────┬────────────┬──────────────┬───────────────┬──────────────┬──────────────┬────────────────┬───────────────────┬────────────────────────────┬──────────────────────────┬────────┐
│ gender  │ age        │ hypertension │ heart_disease │ ever_married │ work_type    │ Residence_type │ avg_glucose_level │ bmi                        │ smoking_status           │ stroke │
│ String7 │ Float64    │ Int64        │ Int64         │ String3      │ String15     │ String7        │ Float64           │ Union{Missing, Float64}    │ Union{Missing, String15} │ Int64  │
│ Textual │ Continuous │ Count        │ Count         │ Textual      │ Textual      │ Textual        │ Continuous        │ Union{Missing, Continuous} │ Union{Missing, Textual}  │ Count  │
├─────────┼────────────┼──────────────┼───────────────┼──────────────┼──────────────┼────────────────┼───────────────────┼────────────────────────────┼──────────────────────────┼────────┤
│ Male    │ 3.0        │ 0            │ 0             │ No           │ children     │ Rural          │ 95.12             │ 18.0                       │ missing                  │ 0      │
│ Male    │ 58.0       │ 1            │ 0             │ Yes          │ Private      │ Urban          │ 87.96             │ 39.2                       │ never smoked             │ 0      │
│ Female  │ 8.0        │ 0            │ 0             │ No           │ Private      │ Urban          │ 110.89            │ 17.6                       │ missing                  │ 0      │
│ Female  │ 70.0       │ 0            │ 0             │ Yes          │ Private      │ Rural          │ 69.04             │ 35.9                       │ formerly smoked          │ 0      │
│ Male    │ 14.0       │ 0            │ 0             │ No           │ Never_worked │ Rural          │ 161.28            │ 19.1                       │ missing                  │ 0      │
└─────────┴────────────┴──────────────┴───────────────┴──────────────┴──────────────┴────────────────┴───────────────────┴────────────────────────────┴──────────────────────────┴────────┘</code></pre><h2 id="Visualize-the-Data"><a class="docs-heading-anchor" href="#Visualize-the-Data">Visualize the Data</a><a id="Visualize-the-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Visualize-the-Data" title="Permalink"></a></h2><p>Since this dataset is composed mostly of categorical features, a bar chart for each categorical column is a good way to visualize the data.</p><pre><code class="language-julia hljs"># Create a bar chart for each column
bar_charts = []
for col in names(df)
 counts = countmap(df[!, col])
  k, v = collect(keys(counts)), collect(values(counts))
   if length(k) &lt; 20
     push!(bar_charts, bar(k, v, legend=false, title=col, color=&quot;turquoise3&quot;, xrotation=90, margin=6mm))
    end
end

# Combine bar charts into a grid layout with specified plot size
plot_res = plot(bar_charts..., layout=(3, 4),
                size=(1300, 500),
                dpi=200
                )
savefig(plot_res, &quot;./assets/cerebral-charts.png&quot;)
</code></pre><p><img src="../assets/cerebral-charts.png" alt="Mushroom Features Plots"/></p><p>Our target her is the <code>Stroke</code> variable; notice how imbalanced it is.</p><h2 id="Coercing-Data"><a class="docs-heading-anchor" href="#Coercing-Data">Coercing Data</a><a id="Coercing-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Coercing-Data" title="Permalink"></a></h2><p>Typical models from <code>MLJ</code> assume that elements in each column of a table have some <code>scientific type</code> as defined by the <a href="https://juliaai.github.io/ScientificTypes.jl/dev/">ScientificTypes.jl</a> package. It&#39;s often necessary to coerce the types found by default to the appropriate type.</p><pre><code class="language-julia hljs">ScientificTypes.schema(df)</code></pre><pre><code class="nohighlight hljs">┌───────────────────┬────────────────────────────┬──────────────────────────┐
│ names             │ scitypes                   │ types                    │
├───────────────────┼────────────────────────────┼──────────────────────────┤
│ gender            │ Textual                    │ String7                  │
│ age               │ Continuous                 │ Float64                  │
│ hypertension      │ Count                      │ Int64                    │
│ heart_disease     │ Count                      │ Int64                    │
│ ever_married      │ Textual                    │ String3                  │
│ work_type         │ Textual                    │ String15                 │
│ Residence_type    │ Textual                    │ String7                  │
│ avg_glucose_level │ Continuous                 │ Float64                  │
│ bmi               │ Union{Missing, Continuous} │ Union{Missing, Float64}  │
│ smoking_status    │ Union{Missing, Textual}    │ Union{Missing, String15} │
│ stroke            │ Count                      │ Int64                    │
└───────────────────┴────────────────────────────┴──────────────────────────┘</code></pre><p>For instance, here we need to coerce all the data to <code>Multiclass</code> as they are all nominal variables except for <code>Age</code>, <code>avg_glucose_level</code> and <code>bmi</code> which we can treat as continuous</p><pre><code class="language-julia hljs">df = coerce(df, :gender =&gt; Multiclass, :age =&gt; Continuous, :hypertension =&gt; Multiclass,
	:heart_disease =&gt; Multiclass, :ever_married =&gt; Multiclass, :work_type =&gt; Multiclass,
	:Residence_type =&gt; Multiclass, :avg_glucose_level =&gt; Continuous,
	:bmi =&gt; Continuous, :smoking_status =&gt; Multiclass, :stroke =&gt; Multiclass,
)
ScientificTypes.schema(df)</code></pre><pre><code class="nohighlight hljs">┌───────────────────┬───────────────┬────────────────────────────────────┐
│ names             │ scitypes      │ types                              │
├───────────────────┼───────────────┼────────────────────────────────────┤
│ gender            │ Multiclass{3} │ CategoricalValue{String7, UInt32}  │
│ age               │ Continuous    │ Float64                            │
│ hypertension      │ Multiclass{2} │ CategoricalValue{Int64, UInt32}    │
│ heart_disease     │ Multiclass{2} │ CategoricalValue{Int64, UInt32}    │
│ ever_married      │ Multiclass{2} │ CategoricalValue{String3, UInt32}  │
│ work_type         │ Multiclass{5} │ CategoricalValue{String15, UInt32} │
│ Residence_type    │ Multiclass{2} │ CategoricalValue{String7, UInt32}  │
│ avg_glucose_level │ Continuous    │ Float64                            │
│ bmi               │ Continuous    │ Float64                            │
│ smoking_status    │ Multiclass{3} │ CategoricalValue{String15, UInt32} │
│ stroke            │ Multiclass{2} │ CategoricalValue{Int64, UInt32}    │
└───────────────────┴───────────────┴────────────────────────────────────┘</code></pre><p>As shown in the types, some columns have missing values we will impute them using simple random sampling as dropping their rows would mean that we lose a big chunk of the dataset.</p><pre><code class="language-julia hljs">df = Impute.srs(df); disallowmissing!(df)
first(df, 5) |&gt; pretty</code></pre><pre><code class="nohighlight hljs">┌───────────────────────────────────┬────────────┬─────────────────────────────────┬─────────────────────────────────┬───────────────────────────────────┬────────────────────────────────────┬───────────────────────────────────┬───────────────────┬────────────┬────────────────────────────────────┬─────────────────────────────────┐
│ gender                            │ age        │ hypertension                    │ heart_disease                   │ ever_married                      │ work_type                          │ Residence_type                    │ avg_glucose_level │ bmi        │ smoking_status                     │ stroke                          │
│ CategoricalValue{String7, UInt32} │ Float64    │ CategoricalValue{Int64, UInt32} │ CategoricalValue{Int64, UInt32} │ CategoricalValue{String3, UInt32} │ CategoricalValue{String15, UInt32} │ CategoricalValue{String7, UInt32} │ Float64           │ Float64    │ CategoricalValue{String15, UInt32} │ CategoricalValue{Int64, UInt32} │
│ Multiclass{3}                     │ Continuous │ Multiclass{2}                   │ Multiclass{2}                   │ Multiclass{2}                     │ Multiclass{5}                      │ Multiclass{2}                     │ Continuous        │ Continuous │ Multiclass{3}                      │ Multiclass{2}                   │
├───────────────────────────────────┼────────────┼─────────────────────────────────┼─────────────────────────────────┼───────────────────────────────────┼────────────────────────────────────┼───────────────────────────────────┼───────────────────┼────────────┼────────────────────────────────────┼─────────────────────────────────┤
│ Male                              │ 3.0        │ 0                               │ 0                               │ No                                │ children                           │ Rural                             │ 95.12             │ 18.0       │ formerly smoked                    │ 0                               │
│ Male                              │ 58.0       │ 1                               │ 0                               │ Yes                               │ Private                            │ Urban                             │ 87.96             │ 39.2       │ never smoked                       │ 0                               │
│ Female                            │ 8.0        │ 0                               │ 0                               │ No                                │ Private                            │ Urban                             │ 110.89            │ 17.6       │ never smoked                       │ 0                               │
│ Female                            │ 70.0       │ 0                               │ 0                               │ Yes                               │ Private                            │ Rural                             │ 69.04             │ 35.9       │ formerly smoked                    │ 0                               │
│ Male                              │ 14.0       │ 0                               │ 0                               │ No                                │ Never_worked                       │ Rural                             │ 161.28            │ 19.1       │ formerly smoked                    │ 0                               │
└───────────────────────────────────┴────────────┴─────────────────────────────────┴─────────────────────────────────┴───────────────────────────────────┴────────────────────────────────────┴───────────────────────────────────┴───────────────────┴────────────┴────────────────────────────────────┴─────────────────────────────────┘</code></pre><h2 id="Unpacking-and-Splitting-Data"><a class="docs-heading-anchor" href="#Unpacking-and-Splitting-Data">Unpacking and Splitting Data</a><a id="Unpacking-and-Splitting-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Unpacking-and-Splitting-Data" title="Permalink"></a></h2><p>Both <code>MLJ</code> and the pure functional interface of <code>Imbalance</code> assume that the observations table <code>X</code> and target vector <code>y</code> are separate. We can accomplish that by using <code>unpack</code> from <code>MLJ</code></p><pre><code class="language-julia hljs">y, X = unpack(df, ==(:stroke); rng=123);
first(X, 5) |&gt; pretty</code></pre><pre><code class="nohighlight hljs">┌───────────────────────────────────┬────────────┬─────────────────────────────────┬─────────────────────────────────┬───────────────────────────────────┬────────────────────────────────────┬───────────────────────────────────┬───────────────────┬────────────┬────────────────────────────────────┐
│ gender                            │ age        │ hypertension                    │ heart_disease                   │ ever_married                      │ work_type                          │ Residence_type                    │ avg_glucose_level │ bmi        │ smoking_status                     │
│ CategoricalValue{String7, UInt32} │ Float64    │ CategoricalValue{Int64, UInt32} │ CategoricalValue{Int64, UInt32} │ CategoricalValue{String3, UInt32} │ CategoricalValue{String15, UInt32} │ CategoricalValue{String7, UInt32} │ Float64           │ Float64    │ CategoricalValue{String15, UInt32} │
│ Multiclass{3}                     │ Continuous │ Multiclass{2}                   │ Multiclass{2}                   │ Multiclass{2}                     │ Multiclass{5}                      │ Multiclass{2}                     │ Continuous        │ Continuous │ Multiclass{3}                      │
├───────────────────────────────────┼────────────┼─────────────────────────────────┼─────────────────────────────────┼───────────────────────────────────┼────────────────────────────────────┼───────────────────────────────────┼───────────────────┼────────────┼────────────────────────────────────┤
│ Female                            │ 37.0       │ 0                               │ 0                               │ Yes                               │ Private                            │ Urban                             │ 103.66            │ 36.1       │ smokes                             │
│ Female                            │ 78.0       │ 0                               │ 0                               │ No                                │ Private                            │ Rural                             │ 83.97             │ 39.6       │ formerly smoked                    │
│ Female                            │ 2.0        │ 0                               │ 0                               │ No                                │ children                           │ Urban                             │ 98.66             │ 17.0       │ smokes                             │
│ Female                            │ 62.0       │ 0                               │ 0                               │ No                                │ Private                            │ Rural                             │ 205.41            │ 27.8       │ smokes                             │
│ Male                              │ 14.0       │ 0                               │ 0                               │ No                                │ Private                            │ Rural                             │ 118.18            │ 24.5       │ never smoked                       │
└───────────────────────────────────┴────────────┴─────────────────────────────────┴─────────────────────────────────┴───────────────────────────────────┴────────────────────────────────────┴───────────────────────────────────┴───────────────────┴────────────┴────────────────────────────────────┘</code></pre><p>Splitting the data into train and test portions is also easy using <code>MLJ</code>&#39;s <code>partition</code> function. <code>stratify=y</code> guarantees that the data is distributed in the same proportions as the original dataset in both splits which is more representative of the real world.</p><pre><code class="language-julia hljs">(X_train, X_test), (y_train, y_test) = partition(
	(X, y),
	0.8,
	multi = true,
	shuffle = true,
	stratify = y,
	rng = Random.Xoshiro(42)
)</code></pre><p>⚠️ Always split the data before oversampling. If your test data has oversampled observations then train-test contamination has occurred; novel observations will not come from the oversampling function.</p><h2 id="Oversampling"><a class="docs-heading-anchor" href="#Oversampling">Oversampling</a><a id="Oversampling-1"></a><a class="docs-heading-anchor-permalink" href="#Oversampling" title="Permalink"></a></h2><p>It was obvious from the bar charts that there is a severe imbalance problem. Let&#39;s look at that again.</p><pre><code class="language-julia hljs">checkbalance(y)         # comes from Imbalance</code></pre><pre><code class="nohighlight hljs">1: ▇ 783 (1.8%) 
0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 42617 (100.0%)</code></pre><p>Indeed, may be too severe for most models.</p><h2 id="Training-the-Model"><a class="docs-heading-anchor" href="#Training-the-Model">Training the Model</a><a id="Training-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Training-the-Model" title="Permalink"></a></h2><p>Because we have scientific types setup, we can easily check what models will be able to train on our data. This should guarantee that the model we choose won&#39;t throw an error due to types after feeding it the data.</p><pre><code class="language-julia hljs">ms = models(matching(Xover, yover))</code></pre><pre><code class="nohighlight hljs">6-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:
 (name = CatBoostClassifier, package_name = CatBoost, ... )
 (name = ConstantClassifier, package_name = MLJModels, ... )
 (name = DecisionTreeClassifier, package_name = BetaML, ... )
 (name = DeterministicConstantClassifier, package_name = MLJModels, ... )
 (name = OneRuleClassifier, package_name = OneRule, ... )
 (name = RandomForestClassifier, package_name = BetaML, ... )</code></pre><p>Let&#39;s go for a <code>DecisionTreeClassifier</code></p><pre><code class="language-julia hljs">import Pkg; Pkg.add(&quot;BetaML&quot;)</code></pre><pre><code class="nohighlight hljs">   Resolving package versions...
   Installed MLJBalancing ─ v0.1.0
    Updating `~/Documents/GitHub/Imbalance.jl/docs/Project.toml`
  [45f359ea] + MLJBalancing v0.1.0
    Updating `~/Documents/GitHub/Imbalance.jl/docs/Manifest.toml`
  [45f359ea] + MLJBalancing v0.1.0
Precompiling project...
  ✓ MLJBalancing
  1 dependency successfully precompiled in 25 seconds. 262 already precompiled.</code></pre><h4 id="Load-and-Construct"><a class="docs-heading-anchor" href="#Load-and-Construct">Load and Construct</a><a id="Load-and-Construct-1"></a><a class="docs-heading-anchor-permalink" href="#Load-and-Construct" title="Permalink"></a></h4><pre><code class="language-julia hljs"># 1. Load the model
DecisionTreeClassifier = @load DecisionTreeClassifier pkg=BetaML

# 2. Instantiate it
model = DecisionTreeClassifier(max_depth=4)</code></pre><pre><code class="nohighlight hljs">import BetaML ✔


┌ Info: For silent loading, specify `verbosity=0`. 
└ @ Main /Users/essam/.julia/packages/MLJModels/EkXIe/src/loading.jl:159



DecisionTreeClassifier(
  max_depth = 4, 
  min_gain = 0.0, 
  min_records = 2, 
  max_features = 0, 
  splitting_criterion = BetaML.Utils.gini, 
  rng = Random._GLOBAL_RNG())</code></pre><h4 id="Wrap-in-a-machine-and-fit!"><a class="docs-heading-anchor" href="#Wrap-in-a-machine-and-fit!">Wrap in a machine and fit!</a><a id="Wrap-in-a-machine-and-fit!-1"></a><a class="docs-heading-anchor-permalink" href="#Wrap-in-a-machine-and-fit!" title="Permalink"></a></h4><pre><code class="language-julia hljs"># 3. Wrap it with the data in a machine
mach = machine(model, X_train, y_train)

# 4. fit the machine learning model
fit!(mach, verbosity=0)</code></pre><pre><code class="nohighlight hljs">trained Machine; caches model-specific representations of data
  model: DecisionTreeClassifier(max_depth = 4, …)
  args: 
    1:	Source @245 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{5}}, AbstractVector{Multiclass{2}}, AbstractVector{Multiclass{3}}}}
    2:	Source @251 ⏎ AbstractVector{Multiclass{2}}</code></pre><h4 id="Evaluate-the-Model"><a class="docs-heading-anchor" href="#Evaluate-the-Model">Evaluate the Model</a><a id="Evaluate-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluate-the-Model" title="Permalink"></a></h4><pre><code class="language-julia hljs">y_pred = MLJ.predict_mode(mach, X_test)                         

score = round(balanced_accuracy(y_pred, y_test), digits=2)</code></pre><pre><code class="nohighlight hljs">0.5</code></pre><h2 id="Training-BalancedBagging-Model"><a class="docs-heading-anchor" href="#Training-BalancedBagging-Model">Training BalancedBagging Model</a><a id="Training-BalancedBagging-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Training-BalancedBagging-Model" title="Permalink"></a></h2><p>The results suggest that the model is just as good as random guessing. Let&#39;s see if this gets better by using a <code>BalancedBaggingClassifier</code>. This classifier trains <code>T</code> of the given <code>model</code> on <code>T</code> undersampled versions of the dataset where in each undersampled version there are as much majority examples as there are minority examples.</p><p>This approach can allow us to workaround the imbalance issue without losing any data. For instance, if we set <code>T=Int(100/1.8)</code> (which is the default) then on average all majority examples will be used in one of the <code>T</code> bags.</p><h4 id="Load-and-Construct-2"><a class="docs-heading-anchor" href="#Load-and-Construct-2">Load and Construct</a><a class="docs-heading-anchor-permalink" href="#Load-and-Construct-2" title="Permalink"></a></h4><pre><code class="language-julia hljs">bagging_model = BalancedBaggingClassifier(model=model, T=30, rng=Random.Xoshiro(42))</code></pre><pre><code class="nohighlight hljs">BalancedBaggingClassifier(
  model = DecisionTreeClassifier(
        max_depth = 4, 
        min_gain = 0.0, 
        min_records = 2, 
        max_features = 0, 
        splitting_criterion = BetaML.Utils.gini, 
        rng = Random._GLOBAL_RNG()), 
  T = 30, 
  rng = Xoshiro(0xa379de7eeeb2a4e8, 0x953dccb6b532b3af, 0xf597b8ff8cfd652a, 0xccd7337c571680d1))</code></pre><h4 id="Wrap-in-a-machine-and-fit!-2"><a class="docs-heading-anchor" href="#Wrap-in-a-machine-and-fit!-2">Wrap in a machine and fit!</a><a class="docs-heading-anchor-permalink" href="#Wrap-in-a-machine-and-fit!-2" title="Permalink"></a></h4><pre><code class="language-julia hljs"># 3. Wrap it with the data in a machine
mach_over = machine(bagging_model, X_train, y_train)

# 4. fit the machine learning model
fit!(mach_over, verbosity=0)</code></pre><pre><code class="nohighlight hljs">trained Machine; does not cache data
  model: BalancedBaggingClassifier(model = DecisionTreeClassifier(max_depth = 4, …), …)
  args: 
    1:	Source @005 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{5}}, AbstractVector{Multiclass{2}}, AbstractVector{Multiclass{3}}}}
    2:	Source @531 ⏎ AbstractVector{Multiclass{2}}</code></pre><h4 id="Evaluate-the-Model-2"><a class="docs-heading-anchor" href="#Evaluate-the-Model-2">Evaluate the Model</a><a class="docs-heading-anchor-permalink" href="#Evaluate-the-Model-2" title="Permalink"></a></h4><pre><code class="language-julia hljs">y_pred = MLJ.predict_mode(mach_over, X_test)                         

score = round(balanced_accuracy(y_pred, y_test), digits=2)</code></pre><pre><code class="nohighlight hljs">0.77</code></pre><p>This is a dramatic improvement over what we had before. Let&#39;s confirm with cross-validation.</p><pre><code class="language-julia hljs">cv=CV(nfolds=10)
evaluate!(mach_over, resampling=cv, measure=balanced_accuracy, operation=predict_mode) </code></pre><pre><code class="nohighlight hljs">Evaluating over 10 folds: 100%[=========================] Time: 0:01:40[K



PerformanceEvaluation object with these fields:
  model, measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows, resampling, repeats
Extract:
┌─────────────────────┬──────────────┬─────────────┬─────────┬──────────────────
│ measure             │ operation    │ measurement │ 1.96*SE │ per_fold        ⋯
├─────────────────────┼──────────────┼─────────────┼─────────┼──────────────────
│ BalancedAccuracy(   │ predict_mode │ 0.772       │ 0.0146  │ [0.738, 0.769,  ⋯
│   adjusted = false) │              │             │         │                 ⋯
└─────────────────────┴──────────────┴─────────────┴─────────┴──────────────────
                                                                1 column omitted</code></pre><p>Under the normality of scores, the <code>95%</code> confidence interval is <code>77.2±1.4%</code> for the balanced accuracy.</p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.0 on <span class="colophon-date" title="Wednesday 11 October 2023 00:44">Wednesday 11 October 2023</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
