<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Walkthrough · Imbalance.jl</title><meta name="title" content="Walkthrough · Imbalance.jl"/><meta property="og:title" content="Walkthrough · Imbalance.jl"/><meta property="twitter:title" content="Walkthrough · Imbalance.jl"/><meta name="description" content="Documentation for Imbalance.jl."/><meta property="og:description" content="Documentation for Imbalance.jl."/><meta property="twitter:description" content="Documentation for Imbalance.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css?family=Montserratwght@100;200;300;400;500;600;700;800;900|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.gif" alt="Imbalance.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Imbalance.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><span class="tocitem">Algorithms</span><ul><li><a class="tocitem" href="../../oversampling_algorithms/">Oversampling</a></li><li><a class="tocitem" href="../../undersampling_algorithms/">Undersampling</a></li><li><a class="tocitem" href="../../extra_algorithms/">Extras</a></li></ul></li><li class="is-active"><a class="tocitem" href>Walkthrough</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Prerequisites"><span>Prerequisites</span></a></li><li><a class="tocitem" href="#Loading-Data"><span>Loading Data</span></a></li><li><a class="tocitem" href="#Coercing-Data"><span>Coercing Data</span></a></li><li><a class="tocitem" href="#Unpacking-and-Splitting-Data"><span>Unpacking and Splitting Data</span></a></li><li><a class="tocitem" href="#Oversampling"><span>Oversampling</span></a></li><li><a class="tocitem" href="#Training-the-Model"><span>Training the Model</span></a></li><li><a class="tocitem" href="#Evaluating-the-Model"><span>Evaluating the Model</span></a></li><li class="toplevel"><a class="tocitem" href="#Google-Colab"><span>Google Colab</span></a></li></ul></li><li><a class="tocitem" href="../">Examples</a></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../about/">About</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Walkthrough</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Walkthrough</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaAI/Imbalance.jl/" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h1><p>In this section of the docs, we will walk you through some examples to demonstrate how you can use <code>Imbalance.jl</code> in your machine learning project. Although we focus on examples, you can learn more about how specific algorithms work by reading this series of blogposts on  <a href="https://medium.com/towards-data-science/class-imbalance-from-random-oversampling-to-rose-517e06d7a9b">Medium</a>.</p><h1 id="Prerequisites"><a class="docs-heading-anchor" href="#Prerequisites">Prerequisites</a><a id="Prerequisites-1"></a><a class="docs-heading-anchor-permalink" href="#Prerequisites" title="Permalink"></a></h1><p>In further examples, we will assume familiarity with the <a href="https://csv.juliadata.org/stable/index.html">CSV</a>, <a href="https://dataframes.juliadata.org/stable/">DataFrames</a>, <a href="https://juliaai.github.io/ScientificTypes.jl/dev/">ScientificTypes</a> and <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a> packages, all of which come with excellent documentation. This example is devoted to assuring and enforcing your familiarity with such packages. You can try this all examples in the docs on your browser using <a href="https://githubtocolab.com/JuliaAI/Imbalance.jl/blob/dev/docs/src/examples/walkthrough.ipynb">Google Colab</a> and you can read more about that in the last section.</p><pre><code class="language-julia hljs">using Random
using CSV
using DataFrames
using MLJ
using Imbalance
using ScientificTypes</code></pre><h2 id="Loading-Data"><a class="docs-heading-anchor" href="#Loading-Data">Loading Data</a><a id="Loading-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Loading-Data" title="Permalink"></a></h2><p>In this example, we will consider the <a href="https://www.kaggle.com/datasets/yasserh/bmidataset">BMI dataset</a> found on Kaggle where the objective is to predict the BMI index of individuals given their gender, weight and height. </p><p><code>CSV</code> gives us the ability to easily read the dataset after it&#39;s downloaded as follows</p><pre><code class="language-julia hljs">df = CSV.read(&quot;datasets/bmi.csv&quot;, DataFrame)

# Display the first 5 rows with DataFrames
first(df, 5) |&gt; pretty</code></pre><pre><code class="nohighlight hljs">┌─────────┬────────┬────────┬───────┐
│ Gender  │ Height │ Weight │ Index │
│ String7 │ Int64  │ Int64  │ Int64 │
│ Textual │ Count  │ Count  │ Count │
├─────────┼────────┼────────┼───────┤
│ Male    │ 174    │ 96     │ 4     │
│ Male    │ 189    │ 87     │ 2     │
│ Female  │ 185    │ 110    │ 4     │
│ Female  │ 195    │ 104    │ 3     │
│ Male    │ 149    │ 61     │ 3     │
└─────────┴────────┴────────┴───────┘</code></pre><h2 id="Coercing-Data"><a class="docs-heading-anchor" href="#Coercing-Data">Coercing Data</a><a id="Coercing-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Coercing-Data" title="Permalink"></a></h2><p>Typical models from <code>MLJ</code> assume that elements in each column of a table have some <em>scientific type</em> as defined by the <a href="https://juliaai.github.io/ScientificTypes.jl/dev/">ScientificTypes.jl</a> package. Among the many types defined by the package, we are interested in <code>Multiclass</code>, <code>OrderedFactor</code> which fall under the <code>Finite</code> abstract type and <code>Continuous</code> and <code>Count</code> which fall under the <code>Infinite</code> abstract type.</p><p>One motivation for this package is that it&#39;s not generally obvious whether numerical data in an input table is of continuous type or categorical type given that numbers can describe both. Meanwhile, it&#39;s problematic if a model treats numerical data as say <code>Continuous</code> or <code>Count</code> when it&#39;s in reality nominal (i.e., <code>Multiclass</code>) or ordinal (i.e., <code>OrderedFactor</code>).</p><p>We can use <code>schema(df)</code> to see how each features is currently going to be interpreted by the resampling algorithms: </p><pre><code class="language-julia hljs">ScientificTypes.schema(df)</code></pre><pre><code class="nohighlight hljs">┌────────┬──────────┬─────────┐
│ names  │ scitypes │ types   │
├────────┼──────────┼─────────┤
│ Gender │ Textual  │ String7 │
│ Height │ Count    │ Int64   │
│ Weight │ Count    │ Int64   │
│ Index  │ Count    │ Int64   │
└────────┴──────────┴─────────┘</code></pre><p>To change encodings that are leading to incorrect interpretations (true for all variable in this example), we use the coerce method, as follows:</p><pre><code class="language-julia hljs">df = coerce(df,
            :Gender =&gt; Multiclass,
            :Height =&gt; Continuous,
            :Weight =&gt; Continuous,
            :Index =&gt; OrderedFactor)
ScientificTypes.schema(df)</code></pre><pre><code class="nohighlight hljs">┌────────┬──────────────────┬───────────────────────────────────┐
│ names  │ scitypes         │ types                             │
├────────┼──────────────────┼───────────────────────────────────┤
│ Gender │ Multiclass{2}    │ CategoricalValue{String7, UInt32} │
│ Height │ Continuous       │ Float64                           │
│ Weight │ Continuous       │ Float64                           │
│ Index  │ OrderedFactor{6} │ CategoricalValue{Int64, UInt32}   │
└────────┴──────────────────┴───────────────────────────────────┘</code></pre><h2 id="Unpacking-and-Splitting-Data"><a class="docs-heading-anchor" href="#Unpacking-and-Splitting-Data">Unpacking and Splitting Data</a><a id="Unpacking-and-Splitting-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Unpacking-and-Splitting-Data" title="Permalink"></a></h2><p>Both <code>MLJ</code> and the pure functional interface of <code>Imbalance</code> assume that the observations table <code>X</code> and target vector <code>y</code> are separate. We can accomplish that by using <code>unpack</code> from <code>MLJ</code></p><pre><code class="language-julia hljs">y, X = unpack(df, ==(:Index); rng=123);
first(X, 5) |&gt; pretty</code></pre><pre><code class="nohighlight hljs">┌───────────────────────────────────┬────────────┬────────────┐
│ Gender                            │ Height     │ Weight     │
│ CategoricalValue{String7, UInt32} │ Float64    │ Float64    │
│ Multiclass{2}                     │ Continuous │ Continuous │
├───────────────────────────────────┼────────────┼────────────┤
│ Female                            │ 173.0      │ 82.0       │
│ Female                            │ 187.0      │ 121.0      │
│ Male                              │ 144.0      │ 145.0      │
│ Male                              │ 156.0      │ 74.0       │
│ Male                              │ 167.0      │ 151.0      │
└───────────────────────────────────┴────────────┴────────────┘</code></pre><p>Splitting the data into train and test portions is also easy using <code>MLJ</code>&#39;s <code>partition</code> function. <code>stratify=y</code> guarantees that the data is distributed in the same proportions as the original dataset in both splits which is more representative of the real world.</p><pre><code class="language-julia hljs">train_inds, test_inds = partition(
    eachindex(y), 0.8, shuffle=true, stratify=y, rng=Random.Xoshiro(42))
X_train, X_test = X[train_inds, :], X[test_inds, :]
y_train, y_test = y[train_inds], y[test_inds]</code></pre><pre><code class="nohighlight hljs">(CategoricalArrays.CategoricalValue{Int64, UInt32}[5, 5, 5, 4, 5, 3, 4, 5, 5, 5  …  5, 4, 4, 5, 4, 5, 5, 3, 5, 2], CategoricalArrays.CategoricalValue{Int64, UInt32}[2, 2, 5, 5, 4, 2, 2, 4, 3, 3  …  2, 0, 0, 5, 3, 5, 2, 4, 5, 5])</code></pre><p>⚠️ Always split the data before oversampling. If your test data has oversampled observations then train-test contamination has occurred; novel observations will not come from the oversampling function.</p><h2 id="Oversampling"><a class="docs-heading-anchor" href="#Oversampling">Oversampling</a><a id="Oversampling-1"></a><a class="docs-heading-anchor-permalink" href="#Oversampling" title="Permalink"></a></h2><p>Before deciding to oversample, let&#39;s see how adverse is the imbalance problem, if it exists. Ideally, you may as well check if the classification model is robust to this problem.</p><pre><code class="language-julia hljs">checkbalance(y)             # comes from Imbalance</code></pre><pre><code class="nohighlight hljs">0: ▇▇▇ 13 (6.6%) 
1: ▇▇▇▇▇▇ 22 (11.1%) 
3: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 68 (34.3%) 
2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 69 (34.8%) 
4: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 130 (65.7%) 
5: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 198 (100.0%)</code></pre><p>Looks like we have a class imbalance problem. Let&#39;s set the desired ratios so that the first two classes are 30%     of the majority class, the second two are 50% of the majority class and the rest as is (ignore in the dictionary)</p><pre><code class="language-julia hljs">ratios = Dict(0=&gt;0.3, 1=&gt;0.3, 2=&gt;0.5, 3=&gt;0.5)              </code></pre><pre><code class="nohighlight hljs">Dict{Int64, Float64} with 4 entries:
  0 =&gt; 0.3
  2 =&gt; 0.5
  3 =&gt; 0.5
  1 =&gt; 0.3</code></pre><p>Let&#39;s use random oversampling to oversample the data. This particular model does not care about the scientific types of the data. It takes <code>X</code> and <code>y</code> as positional arguments and <code>ratios</code> and <code>rng</code> are the main keyword arguments</p><pre><code class="language-julia hljs">Xover, yover = random_oversample(X, y; ratios, rng=42)        </code></pre><pre><code class="nohighlight hljs">Progress:  33%|█████████████▋                           |  ETA: 0:00:01[K
[A


(644×3 DataFrame
 Row │ Gender  Height   Weight  
     │ Cat…    Float64  Float64 
─────┼──────────────────────────
   1 │ Female    173.0     82.0
   2 │ Female    187.0    121.0
   3 │ Male      144.0    145.0
   4 │ Male      156.0     74.0
   5 │ Male      167.0    151.0
   6 │ Female    146.0    147.0
   7 │ Female    157.0    153.0
   8 │ Male      187.0    140.0
  ⋮  │   ⋮        ⋮        ⋮
 638 │ Female    183.0     50.0
 639 │ Female    163.0     57.0
 640 │ Female    190.0     50.0
 641 │ Male      181.0     51.0
 642 │ Male      188.0     54.0
 643 │ Female    191.0     54.0
 644 │ Male      198.0     50.0
                629 rows omitted, CategoricalArrays.CategoricalValue{Int64, UInt32}[2, 4, 5, 4, 5, 5, 5, 5, 5, 2  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</code></pre><pre><code class="language-julia hljs">checkbalance(yover)</code></pre><pre><code class="nohighlight hljs">0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 59 (29.8%) 
1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 59 (29.8%) 
2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 99 (50.0%) 
3: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 99 (50.0%) 
4: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 130 (65.7%) 
5: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 198 (100.0%)</code></pre><p>This indeeds aligns with the desired ratios we have set earlier.</p><h2 id="Training-the-Model"><a class="docs-heading-anchor" href="#Training-the-Model">Training the Model</a><a id="Training-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Training-the-Model" title="Permalink"></a></h2><p>Because we have scientific types setup, we can easily check what models will be able to train on our data. This should guarantee that the model we choose won&#39;t throw an error due to types after feeding it the data.</p><pre><code class="language-julia hljs">models(matching(Xover, yover))</code></pre><pre><code class="nohighlight hljs">5-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:
 (name = CatBoostClassifier, package_name = CatBoost, ... )
 (name = ConstantClassifier, package_name = MLJModels, ... )
 (name = DecisionTreeClassifier, package_name = BetaML, ... )
 (name = DeterministicConstantClassifier, package_name = MLJModels, ... )
 (name = RandomForestClassifier, package_name = BetaML, ... )</code></pre><p>Let&#39;s go for a decision tree form BetaML</p><pre><code class="language-julia hljs">import Pkg; Pkg.add(&quot;BetaML&quot;)</code></pre><h3 id="Before-Oversampling"><a class="docs-heading-anchor" href="#Before-Oversampling">Before Oversampling</a><a id="Before-Oversampling-1"></a><a class="docs-heading-anchor-permalink" href="#Before-Oversampling" title="Permalink"></a></h3><pre><code class="language-julia hljs"># 1. Load the model
DecisionTreeClassifier = @load DecisionTreeClassifier pkg=BetaML verbosity=0

# 2. Instantiate it
model = DecisionTreeClassifier(max_depth=5, rng=Random.Xoshiro(42))

# 3. Wrap it with the data in a machine
mach = machine(model, X_train, y_train)

# 4. fit the machine learning model
fit!(mach)</code></pre><pre><code class="nohighlight hljs">┌ Info: Training machine(DecisionTreeClassifier(max_depth = 5, …), …).
└ @ MLJBase /Users/essam/.julia/packages/MLJBase/ByFwA/src/machines.jl:492



trained Machine; caches model-specific representations of data
  model: DecisionTreeClassifier(max_depth = 5, …)
  args: 
    1:	Source @505 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{2}}}}
    2:	Source @092 ⏎ AbstractVector{OrderedFactor{6}}</code></pre><h3 id="After-Oversampling"><a class="docs-heading-anchor" href="#After-Oversampling">After Oversampling</a><a id="After-Oversampling-1"></a><a class="docs-heading-anchor-permalink" href="#After-Oversampling" title="Permalink"></a></h3><pre><code class="language-julia hljs"># 3. Wrap it with the data in a machine
mach_over = machine(model, Xover, yover)

# 4. fit the machine learning model
fit!(mach_over)</code></pre><pre><code class="nohighlight hljs">┌ Info: Training machine(DecisionTreeClassifier(max_depth = 5, …), …).
└ @ MLJBase /Users/essam/.julia/packages/MLJBase/ByFwA/src/machines.jl:492



trained Machine; caches model-specific representations of data
  model: DecisionTreeClassifier(max_depth = 5, …)
  args: 
    1:	Source @447 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{2}}}}
    2:	Source @581 ⏎ AbstractVector{OrderedFactor{6}}</code></pre><h2 id="Evaluating-the-Model"><a class="docs-heading-anchor" href="#Evaluating-the-Model">Evaluating the Model</a><a id="Evaluating-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluating-the-Model" title="Permalink"></a></h2><p>To evaluate the model, we will use the balanced accuracy metric which equally account for all classes. For instance, if we have two classes and we correctly classify 100% of the examples in the first and 50% of the examples in the second then the balanced accuracy is <span>$(100+50)/2=75%$</span>. This holds regardless to how big or small each class is.</p><p>The <code>predict_mode</code> will return a vector of predictions given <code>X_test</code> and the fitted machine. It&#39;s different in that <code>predict</code> in not returning probablities the model assigns to each class; instead, it returns the classes with the maximum probabilities; i.e., the modes.</p><h3 id="Before-Oversampling-2"><a class="docs-heading-anchor" href="#Before-Oversampling-2">Before Oversampling</a><a class="docs-heading-anchor-permalink" href="#Before-Oversampling-2" title="Permalink"></a></h3><pre><code class="language-julia hljs">y_pred = predict_mode(mach, X_test)                         

score = round(balanced_accuracy(y_pred, y_test), digits=2)</code></pre><pre><code class="nohighlight hljs">0.62</code></pre><h3 id="After-Oversampling-2"><a class="docs-heading-anchor" href="#After-Oversampling-2">After Oversampling</a><a class="docs-heading-anchor-permalink" href="#After-Oversampling-2" title="Permalink"></a></h3><pre><code class="language-julia hljs">y_pred_over = predict_mode(mach_over, X_test)

score = round(balanced_accuracy(y_pred_over, y_test), digits=2)</code></pre><pre><code class="nohighlight hljs">0.77</code></pre><h1 id="Google-Colab"><a class="docs-heading-anchor" href="#Google-Colab">Google Colab</a><a id="Google-Colab-1"></a><a class="docs-heading-anchor-permalink" href="#Google-Colab" title="Permalink"></a></h1><p>It is possible to run this tutorial and others in the examples section on Google Colab.</p><ul><li>Click the Colab icon link as your hover on the example</li><li>Paste and run the following in the first cell</li></ul><pre><code class="language-julia hljs">%%capture
%%shell
if ! command -v julia 3&gt;&amp;1 &gt; /dev/null
then
    wget -q &#39;https://julialang-s3.julialang.org/bin/linux/x64/1.7/julia-1.7.2-linux-x86_64.tar.gz&#39; \
        -O /tmp/julia.tar.gz
    tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1
    rm /tmp/julia.tar.gz
fi
julia -e &#39;using Pkg; pkg&quot;add IJulia; precompile;&quot;&#39;
echo &#39;Done&#39;
</code></pre><ul><li>Change the runtime to Julia from the toolbar</li><li><code>Pkg.add</code> Imbalance and any needed packages (those being used)</li></ul><pre><code class="language-julia hljs">Pkg.add([&quot;Random&quot;, &quot;CSV&quot;, &quot;DataFrames&quot;, &quot;MLJ&quot;, &quot;Imbalance&quot;, &quot;ScientificTypes&quot;])</code></pre><ul><li>Click the folder icon on the left, make a <code>datasets</code> folder and drag and drop it in there</li><li>Run the notebook</li></ul><p>Sincere thanks to <a href="https://github.com/Dsantra92/Julia-on-Colab">Julia-on-Colab</a> for making this possible</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../extra_algorithms/">« Extras</a><a class="docs-footer-nextpage" href="../">Examples »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.0 on <span class="colophon-date" title="Monday 2 October 2023 19:24">Monday 2 October 2023</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
