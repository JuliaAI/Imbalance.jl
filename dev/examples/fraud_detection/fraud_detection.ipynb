{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b34e65",
   "metadata": {},
   "source": [
    "# SMOTE-Tomek for Ethereum Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287bfd79",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "using Imbalance\n",
    "using MLJBalancing\n",
    "using CSV\n",
    "using DataFrames\n",
    "using ScientificTypes\n",
    "using CategoricalArrays\n",
    "using MLJ\n",
    "using Plots\n",
    "using Random\n",
    "using Impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430997fb",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "In this example, we will consider the [Ethereum Fraud Detection Dataset](https://www.kaggle.com/datasets/vagifa/ethereum-frauddetection-dataset) found on Kaggle where the objective is to predict whether an Ethereum transaction is fraud or not (called `FLAG`) given some features about the transaction.\n",
    "\n",
    "`CSV` gives us the ability to easily read the dataset after it's downloaded as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b09a517",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "df = CSV.read(\"../datasets/transactions.csv\", DataFrame)\n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f9119",
   "metadata": {},
   "source": [
    "There are plenty of useless columns that we can get rid of such as `Column1`, `Index` and probably, `Address`. We also have to get rid of the categorical features because SMOTE won't be able to deal with those and it leaves us with more options for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a995bf8",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df[:,\n",
    "\tNot([\n",
    "\t\t:Column1,\n",
    "\t\t:Index,\n",
    "\t\t:Address,\n",
    "\t\tSymbol(\" ERC20 most sent token type\"),\n",
    "\t\tSymbol(\" ERC20_most_rec_token_type\"),\n",
    "\t]),\n",
    "] \n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d9466",
   "metadata": {},
   "source": [
    "If you scroll through the printed data frame, you find that some columns also have `Missing` for their element type, meaning that they may be containing missing values. We will use *linear interpolation*, *last-observation carried forward* and *next observation carried backward* techniques to fill up the missing values. This will allow us to call `disallowmissing!(df)` to return a dataframe where `Missing` is not an element type for any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82ca7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Impute.interp(df) |> Impute.locf() |> Impute.nocb(); disallowmissing!(df)\n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb3cac",
   "metadata": {},
   "source": [
    "## Coercing Data\n",
    "\n",
    "Let's look at the schema first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6411f368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────────────────────────────────────┬────────────┬─────────┐\n",
       "│\u001b[22m names                                                \u001b[0m│\u001b[22m scitypes   \u001b[0m│\u001b[22m types   \u001b[0m│\n",
       "├──────────────────────────────────────────────────────┼────────────┼─────────┤\n",
       "│ FLAG                                                 │ Count      │ Int64   │\n",
       "│ Avg min between sent tnx                             │ Continuous │ Float64 │\n",
       "│ Avg min between received tnx                         │ Continuous │ Float64 │\n",
       "│ Time Diff between first and last (Mins)              │ Continuous │ Float64 │\n",
       "│ Sent tnx                                             │ Count      │ Int64   │\n",
       "│ Received Tnx                                         │ Count      │ Int64   │\n",
       "│ Number of Created Contracts                          │ Count      │ Int64   │\n",
       "│ Unique Received From Addresses                       │ Count      │ Int64   │\n",
       "│ Unique Sent To Addresses                             │ Count      │ Int64   │\n",
       "│ min value received                                   │ Continuous │ Float64 │\n",
       "│ max value received                                   │ Continuous │ Float64 │\n",
       "│ avg val received                                     │ Continuous │ Float64 │\n",
       "│ min val sent                                         │ Continuous │ Float64 │\n",
       "│ max val sent                                         │ Continuous │ Float64 │\n",
       "│ avg val sent                                         │ Continuous │ Float64 │\n",
       "│ min value sent to contract                           │ Continuous │ Float64 │\n",
       "│                          ⋮                           │     ⋮      │    ⋮    │\n",
       "└──────────────────────────────────────────────────────┴────────────┴─────────┘\n",
       "\u001b[36m                                                                30 rows omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ScientificTypes.schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889c2bd",
   "metadata": {},
   "source": [
    "The `FLAG` target should definitely be Multiclass, the rest seems fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52abb9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────────────────────────────────────┬───────────────┬────────\n",
       "│\u001b[22m names                                                \u001b[0m│\u001b[22m scitypes      \u001b[0m│\u001b[22m types\u001b[0m ⋯\n",
       "├──────────────────────────────────────────────────────┼───────────────┼────────\n",
       "│ FLAG                                                 │ Multiclass{2} │ Categ ⋯\n",
       "│ Avg min between sent tnx                             │ Continuous    │ Float ⋯\n",
       "│ Avg min between received tnx                         │ Continuous    │ Float ⋯\n",
       "│ Time Diff between first and last (Mins)              │ Continuous    │ Float ⋯\n",
       "│ Sent tnx                                             │ Count         │ Int64 ⋯\n",
       "│ Received Tnx                                         │ Count         │ Int64 ⋯\n",
       "│ Number of Created Contracts                          │ Count         │ Int64 ⋯\n",
       "│ Unique Received From Addresses                       │ Count         │ Int64 ⋯\n",
       "│ Unique Sent To Addresses                             │ Count         │ Int64 ⋯\n",
       "│ min value received                                   │ Continuous    │ Float ⋯\n",
       "│ max value received                                   │ Continuous    │ Float ⋯\n",
       "│ avg val received                                     │ Continuous    │ Float ⋯\n",
       "│ min val sent                                         │ Continuous    │ Float ⋯\n",
       "│ max val sent                                         │ Continuous    │ Float ⋯\n",
       "│ avg val sent                                         │ Continuous    │ Float ⋯\n",
       "│ min value sent to contract                           │ Continuous    │ Float ⋯\n",
       "│                          ⋮                           │       ⋮       │       ⋱\n",
       "└──────────────────────────────────────────────────────┴───────────────┴────────\n",
       "\u001b[36m                                                    1 column and 30 rows omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = coerce(df, :FLAG =>Multiclass)\n",
    "ScientificTypes.schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ea706",
   "metadata": {},
   "source": [
    "## Unpacking and Splitting Data\n",
    "\n",
    "Both `MLJ` and the pure functional interface of `Imbalance` assume that the observations table `X` and target vector `y` are separate. We can accomplish that by using `unpack` from `MLJ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "784ec902",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "y, X = unpack(df, ==(:FLAG); rng=123);\n",
    "first(X, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95081762",
   "metadata": {},
   "source": [
    "Splitting the data into train and test portions is also easy using `MLJ`'s `partition` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e39afd",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "(X_train, X_test), (y_train, y_test) = partition(\n",
    "\t(X, y),\n",
    "\t0.8,\n",
    "\tmulti = true,\n",
    "\tshuffle = true,\n",
    "\tstratify = y,\n",
    "\trng = Random.Xoshiro(41)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad9aad",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "\n",
    "\n",
    "Before deciding to oversample, let's see how adverse is the imbalance problem, if it exists. Ideally, you may as well check if the classification model is robust to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54542119",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "checkbalance(y)         # comes from Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b452b9",
   "metadata": {},
   "source": [
    "This signals a potential class imbalance problem. Let's consider using `SMOTE-Tomek` to resample this data. The `SMOTE-Tomek` algorithm is nothing but `SMOTE` followed by `TomekUndersampler`. We can wrap these in a pipeline along with a classification model for predictions using `BalancedModel` from `MLJBalancing`. Let's go for a `RandomForestClassifier` from `DecisionTree.jl` for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add(\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccbd57",
   "metadata": {},
   "source": [
    "#### Construct the Resampling & Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2127765c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(\n",
       "  max_depth = -1, \n",
       "  min_samples_leaf = 1, \n",
       "  min_samples_split = 2, \n",
       "  min_purity_increase = 0.0, \n",
       "  n_subfeatures = -1, \n",
       "  n_trees = 2, \n",
       "  sampling_fraction = 0.7, \n",
       "  feature_importance = :impurity, \n",
       "  rng = Xoshiro(0xa379de7eeeb2a4e8, 0x953dccb6b532b3af, 0xf597b8ff8cfd652a, 0xccd7337c571680d1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oversampler = Imbalance.MLJ.SMOTE(ratios=Dict(1=>0.5), rng=Random.Xoshiro(42))\n",
    "undersampler = Imbalance.MLJ.TomekUndersampler(min_ratios=Dict(0=>1.3), force_min_ratios=true)\n",
    "RandomForestClassifier = @load RandomForestClassifier pkg=DecisionTree\n",
    "model = RandomForestClassifier(n_trees=2, rng=Random.Xoshiro(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d972c1",
   "metadata": {},
   "source": [
    "#### Form the Pipeline using `BalancedModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "877ba66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedModelProbabilistic(\n",
       "  model = RandomForestClassifier(\n",
       "        max_depth = -1, \n",
       "        min_samples_leaf = 1, \n",
       "        min_samples_split = 2, \n",
       "        min_purity_increase = 0.0, \n",
       "        n_subfeatures = -1, \n",
       "        n_trees = 2, \n",
       "        sampling_fraction = 0.7, \n",
       "        feature_importance = :impurity, \n",
       "        rng = Xoshiro(0xa379de7eeeb2a4e8, 0x953dccb6b532b3af, 0xf597b8ff8cfd652a, 0xccd7337c571680d1)), \n",
       "  balancer1 = SMOTE(\n",
       "        k = 5, \n",
       "        ratios = Dict(1 => 0.5), \n",
       "        rng = Xoshiro(0xa379de7eeeb2a4e8, 0x953dccb6b532b3af, 0xf597b8ff8cfd652a, 0xccd7337c571680d1), \n",
       "        try_preserve_type = true), \n",
       "  balancer2 = TomekUndersampler(\n",
       "        min_ratios = Dict(0 => 1.3), \n",
       "        force_min_ratios = true, \n",
       "        rng = TaskLocalRNG(), \n",
       "        try_preserve_type = true))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balanced_model = BalancedModel(model=model, balancer1=oversampler, balancer2=undersampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d04c94",
   "metadata": {},
   "source": [
    "Now we can treat `balanced_model` like any `MLJ` model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e862b0f",
   "metadata": {},
   "source": [
    "#### Fit the `BalancedModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c60a20ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trained Machine; does not cache data\n",
       "  model: BalancedModelProbabilistic(model = RandomForestClassifier(max_depth = -1, …), …)\n",
       "  args: \n",
       "    1:\tSource @967 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}\n",
       "    2:\tSource @913 ⏎ AbstractVector{Multiclass{2}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Wrap it with the data in a machine\n",
    "mach_over = machine(balanced_model, X_train, y_train)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach_over, verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51db92ce",
   "metadata": {},
   "source": [
    "#### Validate the `BalancedModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f04551aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  model, measure, operation, measurement, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_rows, resampling, repeats\n",
       "Extract:\n",
       "┌─────────────────────┬──────────────┬─────────────┬─────────┬──────────────────\n",
       "│\u001b[22m measure             \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\u001b[22m per_fold       \u001b[0m ⋯\n",
       "├─────────────────────┼──────────────┼─────────────┼─────────┼──────────────────\n",
       "│ BalancedAccuracy(   │ predict_mode │ 0.93        │ 0.00757 │ [0.927, 0.936,  ⋯\n",
       "│   adjusted = false) │              │             │         │                 ⋯\n",
       "└─────────────────────┴──────────────┴─────────────┴─────────┴──────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv=CV(nfolds=10)\n",
    "evaluate!(mach_over, resampling=cv, measure=balanced_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a773396",
   "metadata": {},
   "source": [
    "#### Compare with `RandomForestClassifier` only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bac39a",
   "metadata": {},
   "source": [
    "To see if this represents any form of improvement, fitting and validating the original model by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50d21963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  model, measure, operation, measurement, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_rows, resampling, repeats\n",
       "Extract:\n",
       "┌─────────────────────┬──────────────┬─────────────┬─────────┬──────────────────\n",
       "│\u001b[22m measure             \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\u001b[22m per_fold       \u001b[0m ⋯\n",
       "├─────────────────────┼──────────────┼─────────────┼─────────┼──────────────────\n",
       "│ BalancedAccuracy(   │ predict_mode │ 0.908       │ 0.00932 │ [0.903, 0.898,  ⋯\n",
       "│   adjusted = false) │              │             │         │                 ⋯\n",
       "└─────────────────────┴──────────────┴─────────────┴─────────┴──────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Wrap it with the data in a machine\n",
    "mach = machine(model, X_train, y_train, scitype_check_level=0)\n",
    "fit!(mach)\n",
    "\n",
    "evaluate!(mach, resampling=cv, measure=balanced_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203370aa",
   "metadata": {},
   "source": [
    "Assuming normal scores, the `95%` confidence interval was `90.8±0.9` and after resampling it has become `93±0.7` which corresponds to a small improvement in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a1aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook fraud_detection.ipynb to markdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno 2] No such file or directory: './assets'\n",
      "Conversion Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Writing 11899 bytes to fraud_detection.md\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "from convert import convert_to_md\n",
    "convert_to_md('fraud_detection')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
