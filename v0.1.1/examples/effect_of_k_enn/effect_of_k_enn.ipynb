{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of ENN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using CSV\n",
    "using DataFrames\n",
    "using MLJ\n",
    "using Imbalance\n",
    "using ScientificTypes\n",
    "using Plots, Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "In this example, we will consider the [BMI dataset](https://www.kaggle.com/datasets/yasserh/bmidataset) found on Kaggle where the objective is to predict the BMI index of individuals given their gender, weight and height. \n",
    "\n",
    "`CSV` gives us the ability to easily read the dataset after it's downloaded as follows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬────────┬────────┬───────┐\n",
      "│\u001b[1m Gender  \u001b[0m│\u001b[1m Height \u001b[0m│\u001b[1m Weight \u001b[0m│\u001b[1m Index \u001b[0m│\n",
      "│\u001b[90m String7 \u001b[0m│\u001b[90m Int64  \u001b[0m│\u001b[90m Int64  \u001b[0m│\u001b[90m Int64 \u001b[0m│\n",
      "│\u001b[90m Textual \u001b[0m│\u001b[90m Count  \u001b[0m│\u001b[90m Count  \u001b[0m│\u001b[90m Count \u001b[0m│\n",
      "├─────────┼────────┼────────┼───────┤\n",
      "│ Male    │ 174    │ 96     │ 4     │\n",
      "│ Male    │ 189    │ 87     │ 2     │\n",
      "│ Female  │ 185    │ 110    │ 4     │\n",
      "│ Female  │ 195    │ 104    │ 3     │\n",
      "│ Male    │ 149    │ 61     │ 3     │\n",
      "└─────────┴────────┴────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "df = CSV.read(\"../datasets/bmi.csv\", DataFrame)\n",
    "\n",
    "# Display the first 5 rows with DataFrames\n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the gender attribute for purposes of visualization and to have more options for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select!(df, Not(:Gender)) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coercing Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────┬──────────┬───────┐\n",
       "│\u001b[22m names  \u001b[0m│\u001b[22m scitypes \u001b[0m│\u001b[22m types \u001b[0m│\n",
       "├────────┼──────────┼───────┤\n",
       "│ Height │ Count    │ Int64 │\n",
       "│ Weight │ Count    │ Int64 │\n",
       "│ Index  │ Count    │ Int64 │\n",
       "└────────┴──────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ScientificTypes.schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight and Height should be `Continuous` and Index should be an `OrderedFactor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────┬──────────────────┬─────────────────────────────────┐\n",
       "│\u001b[22m names  \u001b[0m│\u001b[22m scitypes         \u001b[0m│\u001b[22m types                           \u001b[0m│\n",
       "├────────┼──────────────────┼─────────────────────────────────┤\n",
       "│ Height │ Continuous       │ Float64                         │\n",
       "│ Weight │ Continuous       │ Float64                         │\n",
       "│ Index  │ OrderedFactor{6} │ CategoricalValue{Int64, UInt32} │\n",
       "└────────┴──────────────────┴─────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = coerce(df,\n",
    "            :Height => Continuous,\n",
    "            :Weight => Continuous,\n",
    "            :Index => OrderedFactor)\n",
    "ScientificTypes.schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpacking Data\n",
    "\n",
    "Both `MLJ` and the pure functional interface of `Imbalance` assume that the observations table `X` and target vector `y` are separate. We can accomplish that by using `unpack` from `MLJ`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┬────────────┐\n",
      "│\u001b[1m Height     \u001b[0m│\u001b[1m Weight     \u001b[0m│\n",
      "│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64    \u001b[0m│\n",
      "│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous \u001b[0m│\n",
      "├────────────┼────────────┤\n",
      "│ 173.0      │ 82.0       │\n",
      "│ 187.0      │ 121.0      │\n",
      "│ 144.0      │ 145.0      │\n",
      "│ 156.0      │ 74.0       │\n",
      "│ 167.0      │ 151.0      │\n",
      "└────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "y, X = unpack(df, ==(:Index); rng=123);\n",
    "first(X, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will skip splitting the data since the main purpose of this tutorial is visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before undersampling, let's check the balance of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ▇▇▇ 13 (100.0%) \n",
      "1: ▇▇▇▇▇▇ 22 (169.2%) \n",
      "3: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 68 (523.1%) \n",
      "2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 69 (530.8%) \n",
      "4: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 130 (1000.0%) \n",
      "5: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 198 (1523.1%) \n"
     ]
    }
   ],
   "source": [
    "checkbalance(y; ref=\"minority\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use ENN undersampling to undersample the data. ENN undersamples the data by \"cleaning it out\" or in another words deleting any point that violates a certain condition. We can limit the number of points that are deleted by setting the `min_ratios` parameter. \n",
    "\n",
    "We will set `k=1` and `keep_condition=\"only mode\"` which means that any point with a label that is not the only most common one amongst its 1-nearest neighbors will be deleted (i.e., must have same label as its nearest neighbor). By setting `min_ratios=1.0` we constraint that points should never be deleted form any class if it's ratio relative to the minority class will be less than `1.0`. This also means that no points will be deleted from the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\u001b[1m448×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Height  \u001b[0m\u001b[1m Weight  \u001b[0m\n",
       "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼──────────────────\n",
       "   1 │   173.0     82.0\n",
       "   2 │   182.0     70.0\n",
       "   3 │   156.0     52.0\n",
       "   4 │   172.0     67.0\n",
       "   5 │   162.0     58.0\n",
       "   6 │   180.0     75.0\n",
       "   7 │   190.0     83.0\n",
       "   8 │   195.0     81.0\n",
       "  ⋮  │    ⋮        ⋮\n",
       " 442 │   196.0     50.0\n",
       " 443 │   191.0     54.0\n",
       " 444 │   185.0     52.0\n",
       " 445 │   182.0     50.0\n",
       " 446 │   198.0     50.0\n",
       " 447 │   198.0     50.0\n",
       " 448 │   181.0     51.0\n",
       "\u001b[36m        433 rows omitted\u001b[0m, CategoricalArrays.CategoricalValue{Int64, UInt32}[2, 2, 2, 2, 2, 2, 2, 2, 2, 2  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_under, y_under = enn_undersample(\n",
    "\tX,\n",
    "\ty;\n",
    "\tk = 1,\n",
    "\tkeep_condition = \"only mode\",\n",
    "\tmin_ratios=0.01,\n",
    "\trng = 42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ▇▇▇ 11 (100.0%) \n",
      "1: ▇▇▇▇▇ 19 (172.7%) \n",
      "2: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 56 (509.1%) \n",
      "3: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 58 (527.3%) \n",
      "4: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 115 (1045.5%) \n",
      "5: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 189 (1718.2%) \n"
     ]
    }
   ],
   "source": [
    "checkbalance(y_under; ref=\"minority\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indeeds aligns with the desired ratios we have set earlier.\n",
    "\n",
    "## Training the Model\n",
    "\n",
    "\n",
    "\n",
    "Because we have scientific types setup, we can easily check what models will be able to train on our data. This should guarantee that the model we choose won't throw an error due to types after feeding it the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n",
       " (name = AdaBoostClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianLDA, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianQDA, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = CatBoostClassifier, package_name = CatBoost, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = BetaML, ... )\n",
       " ⋮\n",
       " (name = SGDClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVMLinearClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVMNuClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = StableForestClassifier, package_name = SIRUS, ... )\n",
       " (name = StableRulesClassifier, package_name = SIRUS, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models(matching(X_under, y_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go for an `SVM` from `LIBSVM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Documents/GitHub/Imbalance.jl/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Documents/GitHub/Imbalance.jl/docs/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"LIBSVM\")\n",
    "import LIBSVM;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Undersampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLIBSVMInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/essam/.julia/packages/MLJModels/EkXIe/src/loading.jl:159\n",
      "┌ Info: Training machine(SVC(kernel = RadialBasis, …), …).\n",
      "└ @ MLJBase /Users/essam/.julia/packages/MLJBase/ByFwA/src/machines.jl:492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: SVC(kernel = RadialBasis, …)\n",
       "  args: \n",
       "    1:\tSource @987 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @104 ⏎ AbstractVector{OrderedFactor{6}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load the model\n",
    "SVC = @load SVC pkg=LIBSVM\n",
    "\n",
    "# 2. Instantiate it\n",
    "model = SVC(kernel=LIBSVM.Kernel.RadialBasis, gamma=0.01) ## instance\n",
    "\n",
    "# 3. Wrap it with the data in a machine\n",
    "mach = machine(model, X, y)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Undersampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(SVC(kernel = RadialBasis, …), …).\n",
      "└ @ MLJBase /Users/essam/.julia/packages/MLJBase/ByFwA/src/machines.jl:492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: SVC(kernel = RadialBasis, …)\n",
       "  args: \n",
       "    1:\tSource @123 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @423 ⏎ AbstractVector{OrderedFactor{6}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Wrap it with the data in a machine\n",
    "mach_under = machine(model, X_under, y_under)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Decision Boundaries\n",
    "\n",
    "Construct ranges for each feature and consecutively a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400×400 Matrix{Tuple{Float64, Float64}}:\n",
       " (139.0, 49.0)    (139.0, 49.2807)    (139.0, 49.5614)    …  (139.0, 161.0)\n",
       " (139.153, 49.0)  (139.153, 49.2807)  (139.153, 49.5614)     (139.153, 161.0)\n",
       " (139.306, 49.0)  (139.306, 49.2807)  (139.306, 49.5614)     (139.306, 161.0)\n",
       " (139.459, 49.0)  (139.459, 49.2807)  (139.459, 49.5614)     (139.459, 161.0)\n",
       " (139.612, 49.0)  (139.612, 49.2807)  (139.612, 49.5614)     (139.612, 161.0)\n",
       " (139.764, 49.0)  (139.764, 49.2807)  (139.764, 49.5614)  …  (139.764, 161.0)\n",
       " (139.917, 49.0)  (139.917, 49.2807)  (139.917, 49.5614)     (139.917, 161.0)\n",
       " (140.07, 49.0)   (140.07, 49.2807)   (140.07, 49.5614)      (140.07, 161.0)\n",
       " (140.223, 49.0)  (140.223, 49.2807)  (140.223, 49.5614)     (140.223, 161.0)\n",
       " (140.376, 49.0)  (140.376, 49.2807)  (140.376, 49.5614)     (140.376, 161.0)\n",
       " ⋮                                                        ⋱  \n",
       " (198.777, 49.0)  (198.777, 49.2807)  (198.777, 49.5614)     (198.777, 161.0)\n",
       " (198.93, 49.0)   (198.93, 49.2807)   (198.93, 49.5614)      (198.93, 161.0)\n",
       " (199.083, 49.0)  (199.083, 49.2807)  (199.083, 49.5614)     (199.083, 161.0)\n",
       " (199.236, 49.0)  (199.236, 49.2807)  (199.236, 49.5614)     (199.236, 161.0)\n",
       " (199.388, 49.0)  (199.388, 49.2807)  (199.388, 49.5614)  …  (199.388, 161.0)\n",
       " (199.541, 49.0)  (199.541, 49.2807)  (199.541, 49.5614)     (199.541, 161.0)\n",
       " (199.694, 49.0)  (199.694, 49.2807)  (199.694, 49.5614)     (199.694, 161.0)\n",
       " (199.847, 49.0)  (199.847, 49.2807)  (199.847, 49.5614)     (199.847, 161.0)\n",
       " (200.0, 49.0)    (200.0, 49.2807)    (200.0, 49.5614)       (200.0, 161.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "height_range =\n",
    "\trange(minimum(X.Height) - 1, maximum(X.Height) + 1, length = 400)\n",
    "weight_range =\n",
    "range(minimum(X.Weight) - 1, maximum(X.Weight) + 1, length = 400)\n",
    "grid_points = [(h, w) for h in height_range, w in weight_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the grid with the machine before and after undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions =[\n",
    "    predict(mach, Tables.table(reshape(collect(point), 1, 2)))[1] for\n",
    " \tpoint in grid_points\n",
    " ]\n",
    " \n",
    "grid_predictions_under = [\n",
    "    predict(mach_under, Tables.table(reshape(collect(point), 1, 2)))[1] for\n",
    "    point in grid_points\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make two contour plots using the grid predictions before and after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "colors = [:green, :aqua, :violet, :red, :blue, :yellow]\n",
    "p = contourf(weight_range, height_range, grid_predictions,\n",
    "levels = 6, color = colors, colorbar = false)\n",
    "p_under = contourf(weight_range, height_range,  grid_predictions_under,\n",
    "levels = 6, color = colors, colorbar = false)\n",
    "println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = unique(y)\n",
    "colors = Dict(\n",
    "\t0 => \"green\",\n",
    "\t1 => \"cyan3\",\n",
    "\t2 => \"violet\",\n",
    "\t3 => \"red\",\n",
    "\t4 => \"dodgerblue\",\n",
    "\t5 => \"gold2\",\n",
    ")\n",
    "\n",
    "for label in labels\n",
    "\tscatter!(p, X.Weight[y.==label], X.Height[y.==label],\n",
    "\t\tcolor = colors[label], label = label, markerstrokewidth = 1.5,\n",
    "\t\ttitle = \"Before Undersampling\")\n",
    "\tscatter!(p_under, X_under.Weight[y_under.==label], X_under.Height[y_under.==label],\n",
    "\t\tcolor = colors[label], label = label, markerstrokewidth = 1.5,\n",
    "\t\ttitle = \"After Undersampling\")\n",
    "end\n",
    "\n",
    "plot_res = plot(\n",
    "\tp,\n",
    "\tp_under,\n",
    "\tlayout = (1, 2),\n",
    "\txlabel = \"Height\",\n",
    "\tylabel = \"Width\",\n",
    "\tsize = (1200, 450),\n",
    "\tmargin = 5mm, dpi = 200,\n",
    "\tlegend = :outerbottomright,\n",
    ")\n",
    "savefig(plot_res, \"./assets/ENN-before-after.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![enn comparison](./assets/ENN-before-after.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of $k$ Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's study the cleaning effect as `k` increases for all types of keep conditions of undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = @animate for k ∈ 1:15\n",
    "\tconditions = [\"exists\", \"mode\", \"only mode\", \"all\"]\n",
    "\tplots = [plot() for _ in 1:4]\n",
    "\tdata_list = []\n",
    "\n",
    "\tfor i in 1:4\n",
    "\n",
    "\t\tX_under, y_under = enn_undersample(\n",
    "\t\t\tX,\n",
    "\t\t\ty;\n",
    "\t\t\tk = k,\n",
    "\t\t\tkeep_condition = conditions[i],\n",
    "\t\t\tmin_ratios = 0.01,\n",
    "\t\t\trng = 42,\n",
    "\t\t)\n",
    "\n",
    "\t\t# fit machine\n",
    "\t\tmach_under = machine(model, X_under, y_under)\n",
    "\t\tfit!(mach_under, verbosity = 0)\n",
    "\n",
    "\t\t# grid predictions\n",
    "\t\tgrid_predictions_under = [\n",
    "\t\t\tpredict(mach_under, Tables.table(reshape(collect(point), 1, 2)))[1] for\n",
    "\t\t\tpoint in grid_points\n",
    "\t\t]\n",
    "\n",
    "\t\t# plot\n",
    "\t\tcolors = [:green, :aqua, :violet, :red, :blue, :yellow]\n",
    "\t\tcontourf!(plots[i], weight_range, height_range, grid_predictions_under,\n",
    "\t\t\tlevels = 6, color = colors, colorbar = false)\n",
    "\n",
    "\t\tcolors = Dict(\n",
    "\t\t\t0 => \"green\",\n",
    "\t\t\t1 => \"cyan3\",\n",
    "\t\t\t2 => \"violet\",\n",
    "\t\t\t3 => \"red\",\n",
    "\t\t\t4 => \"dodgerblue\",\n",
    "\t\t\t5 => \"gold2\",\n",
    "\t\t)\n",
    "\t\tfor label in labels\n",
    "\t\t\tscatter!(plots[i], X_under.Weight[y_under.==label],\n",
    "\t\t\t\tX_under.Height[y_under.==label],\n",
    "\t\t\t\tcolor = colors[label], label = label, markerstrokewidth = 1.5,\n",
    "\t\t\t\ttitle = \"$(conditions[i])\", legend = ((i == 2) ? :bottomright : :none))\n",
    "\t\tend\n",
    "\t\tplot!(\n",
    "\t\t\tplots[1], plots[2], plots[3], plots[4],\n",
    "\t\t\tlayout = (1, 4),\n",
    "\t\t\tsize = (1300, 420),\n",
    "\t\t\tplot_title = \"Undersampling with k =$k\",\n",
    "\t\t)\n",
    "\tend\n",
    "\tplot!(dpi = 150)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif(anim, \"./assets/enn-k-animation.gif\", fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![enn-gif-hyperparameter](./assets/enn-k-animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the most constraining condition is `all`. It deletes any point where the label is different than any of the nearest `k` neighbors which also explains why it's the most sensitive to \n",
    "the hyperparameter `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook effect_of_k_enn.ipynb to markdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied ENN-before-after.png to ../assets/ENN-before-after.png\n",
      "Copied enn-k-animation.gif to ../assets/enn-k-animation.gif\n",
      "Conversion Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Writing 15168 bytes to effect_of_k_enn.md\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "from convert import convert_to_md; convert_to_md('effect_of_k_enn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
