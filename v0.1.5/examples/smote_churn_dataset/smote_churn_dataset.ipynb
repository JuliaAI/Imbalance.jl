{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fff55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this installs Julia 1.7\n",
    "%%capture\n",
    "%%shell\n",
    "wget -O - https://raw.githubusercontent.com/JuliaAI/Imbalance.jl/dev/docs/src/examples/colab.sh | bash\n",
    "#This should take around one minute to finish. Once it does, change the runtime to `Julia` by choosing `Runtime` \n",
    "# from the toolbar then `Change runtime type`. You can then delete this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074180d",
   "metadata": {},
   "source": [
    "# SMOTE on Customer Churn Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "287bfd79",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import Pkg;\n",
    "Pkg.add([\"Random\", \"CSV\", \"DataFrames\", \"MLJ\", \"Imbalance\", \"MLJBalancing\", \n",
    "         \"ScientificTypes\",\"Impute\", \"StatsBase\",  \"Plots\", \"Measures\", \"HTTP\"])\n",
    "\n",
    "using Imbalance\n",
    "using MLJBalancing\n",
    "using CSV\n",
    "using DataFrames\n",
    "using ScientificTypes\n",
    "using CategoricalArrays\n",
    "using MLJ\n",
    "using Plots\n",
    "using Random\n",
    "using HTTP: download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430997fb",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "In this example, we will consider the [Churn for Bank Customers](https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers) found on Kaggle where the objective is to predict whether a customer is likely to leave a bank given financial and demographic features.\n",
    "\n",
    "`CSV` gives us the ability to easily read the dataset after it's downloaded as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b09a517",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────┬────────────┬──────────┬─────────────┬───────────┬─────────┬───────┬────────┬────────────┬───────────────┬───────────┬────────────────┬─────────────────┬────────┐\n",
      "│\u001b[1m RowNumber \u001b[0m│\u001b[1m CustomerId \u001b[0m│\u001b[1m Surname  \u001b[0m│\u001b[1m CreditScore \u001b[0m│\u001b[1m Geography \u001b[0m│\u001b[1m Gender  \u001b[0m│\u001b[1m Age   \u001b[0m│\u001b[1m Tenure \u001b[0m│\u001b[1m Balance    \u001b[0m│\u001b[1m NumOfProducts \u001b[0m│\u001b[1m HasCrCard \u001b[0m│\u001b[1m IsActiveMember \u001b[0m│\u001b[1m EstimatedSalary \u001b[0m│\u001b[1m Exited \u001b[0m│\n",
      "│\u001b[90m Int64     \u001b[0m│\u001b[90m Int64      \u001b[0m│\u001b[90m String31 \u001b[0m│\u001b[90m Int64       \u001b[0m│\u001b[90m String7   \u001b[0m│\u001b[90m String7 \u001b[0m│\u001b[90m Int64 \u001b[0m│\u001b[90m Int64  \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Int64         \u001b[0m│\u001b[90m Int64     \u001b[0m│\u001b[90m Int64          \u001b[0m│\u001b[90m Float64         \u001b[0m│\u001b[90m Int64  \u001b[0m│\n",
      "│\u001b[90m Count     \u001b[0m│\u001b[90m Count      \u001b[0m│\u001b[90m Textual  \u001b[0m│\u001b[90m Count       \u001b[0m│\u001b[90m Textual   \u001b[0m│\u001b[90m Textual \u001b[0m│\u001b[90m Count \u001b[0m│\u001b[90m Count  \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Count         \u001b[0m│\u001b[90m Count     \u001b[0m│\u001b[90m Count          \u001b[0m│\u001b[90m Continuous      \u001b[0m│\u001b[90m Count  \u001b[0m│\n",
      "├───────────┼────────────┼──────────┼─────────────┼───────────┼─────────┼───────┼────────┼────────────┼───────────────┼───────────┼────────────────┼─────────────────┼────────┤\n",
      "│ 1         │ 15634602   │ Hargrave │ 619         │ France    │ Female  │ 42    │ 2      │ 0.0        │ 1             │ 1         │ 1              │ 1.01349e5       │ 1      │\n",
      "│ 2         │ 15647311   │ Hill     │ 608         │ Spain     │ Female  │ 41    │ 1      │ 83807.9    │ 1             │ 0         │ 1              │ 1.12543e5       │ 0      │\n",
      "│ 3         │ 15619304   │ Onio     │ 502         │ France    │ Female  │ 42    │ 8      │ 1.59661e5  │ 3             │ 1         │ 0              │ 1.13932e5       │ 1      │\n",
      "│ 4         │ 15701354   │ Boni     │ 699         │ France    │ Female  │ 39    │ 1      │ 0.0        │ 2             │ 0         │ 0              │ 93826.6         │ 0      │\n",
      "│ 5         │ 15737888   │ Mitchell │ 850         │ Spain     │ Female  │ 43    │ 2      │ 1.25511e5  │ 1             │ 1         │ 1              │ 79084.1         │ 0      │\n",
      "└───────────┴────────────┴──────────┴─────────────┴───────────┴─────────┴───────┴────────┴────────────┴───────────────┴───────────┴────────────────┴─────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "download(\"https://raw.githubusercontent.com/JuliaAI/Imbalance.jl/dev/docs/src/examples/smote_churn_dataset/churn.csv\", \"./\")\n",
    "df = CSV.read(\"./churn.csv\", DataFrame)\n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f9119",
   "metadata": {},
   "source": [
    "There are plenty of useless columns that we can get rid of such as `RowNumber` and `CustomerID`. We also have to get rid of the categoircal features because SMOTE won't be able to deal with those; however, other variants such as SMOTE-NC can which we will consider in another tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a995bf8",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────┬───────┬────────┬────────────┬───────────────┬───────────┬────────────────┬─────────────────┬────────┐\n",
      "│\u001b[1m CreditScore \u001b[0m│\u001b[1m Age   \u001b[0m│\u001b[1m Tenure \u001b[0m│\u001b[1m Balance    \u001b[0m│\u001b[1m NumOfProducts \u001b[0m│\u001b[1m HasCrCard \u001b[0m│\u001b[1m IsActiveMember \u001b[0m│\u001b[1m EstimatedSalary \u001b[0m│\u001b[1m Exited \u001b[0m│\n",
      "│\u001b[90m Int64       \u001b[0m│\u001b[90m Int64 \u001b[0m│\u001b[90m Int64  \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Int64         \u001b[0m│\u001b[90m Int64     \u001b[0m│\u001b[90m Int64          \u001b[0m│\u001b[90m Float64         \u001b[0m│\u001b[90m Int64  \u001b[0m│\n",
      "│\u001b[90m Count       \u001b[0m│\u001b[90m Count \u001b[0m│\u001b[90m Count  \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Count         \u001b[0m│\u001b[90m Count     \u001b[0m│\u001b[90m Count          \u001b[0m│\u001b[90m Continuous      \u001b[0m│\u001b[90m Count  \u001b[0m│\n",
      "├─────────────┼───────┼────────┼────────────┼───────────────┼───────────┼────────────────┼─────────────────┼────────┤\n",
      "│ 619.0       │ 42.0  │ 2.0    │ 0.0        │ 1.0           │ 1.0       │ 1.0            │ 1.01349e5       │ 1.0    │\n",
      "│ 608.0       │ 41.0  │ 1.0    │ 83807.9    │ 1.0           │ 0.0       │ 1.0            │ 1.12543e5       │ 0.0    │\n",
      "│ 502.0       │ 42.0  │ 8.0    │ 1.59661e5  │ 3.0           │ 1.0       │ 0.0            │ 1.13932e5       │ 1.0    │\n",
      "│ 699.0       │ 39.0  │ 1.0    │ 0.0        │ 2.0           │ 0.0       │ 0.0            │ 93826.6         │ 0.0    │\n",
      "│ 850.0       │ 43.0  │ 2.0    │ 1.25511e5  │ 1.0           │ 1.0       │ 1.0            │ 79084.1         │ 0.0    │\n",
      "└─────────────┴───────┴────────┴────────────┴───────────────┴───────────┴────────────────┴─────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "df = df[:, Not([:RowNumber, :CustomerId, :Surname, \n",
    "           :Geography, :Gender])]\n",
    "\n",
    "first(df, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb3cac",
   "metadata": {},
   "source": [
    "Ideally, we may even remove ordinal variables because SMOTE will treat them as continuous and the synthetic data it generates will taking floating point values which will not occur in future data. Some models may be robust to this whatsoever and the main purpose of this tutorial is to later compare SMOTE-NC with SMOTE.\n",
    "\n",
    "## Coercing Data\n",
    "\n",
    "Let's coerce everything to continuous except for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd54965e",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────────┬───────────────┬─────────────────────────────────┐\n",
       "│\u001b[22m names           \u001b[0m│\u001b[22m scitypes      \u001b[0m│\u001b[22m types                           \u001b[0m│\n",
       "├─────────────────┼───────────────┼─────────────────────────────────┤\n",
       "│ CreditScore     │ Count         │ Int64                           │\n",
       "│ Age             │ Continuous    │ Float64                         │\n",
       "│ Tenure          │ Continuous    │ Float64                         │\n",
       "│ Balance         │ Continuous    │ Float64                         │\n",
       "│ NumOfProducts   │ Continuous    │ Float64                         │\n",
       "│ HasCrCard       │ Continuous    │ Float64                         │\n",
       "│ IsActiveMember  │ Continuous    │ Float64                         │\n",
       "│ EstimatedSalary │ Continuous    │ Float64                         │\n",
       "│ Exited          │ Multiclass{2} │ CategoricalValue{Int64, UInt32} │\n",
       "└─────────────────┴───────────────┴─────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = coerce(df, :Age=>Continuous,\n",
    "                :Tenure=>Continuous,\n",
    "                :Balance=>Continuous,\n",
    "                :NumOfProducts=>Continuous,\n",
    "                :HasCrCard=>Continuous,\n",
    "                :IsActiveMember=>Continuous,\n",
    "                :EstimatedSalary=>Continuous,\n",
    "                :Exited=>Multiclass)\n",
    "\n",
    "ScientificTypes.schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ea706",
   "metadata": {},
   "source": [
    "## Unpacking and Splitting Data\n",
    "\n",
    "Both `MLJ` and the pure functional interface of `Imbalance` assume that the observations table `X` and target vector `y` are separate. We can accomplish that by using `unpack` from `MLJ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784ec902",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────┬────────────┬────────────┬────────────┬───────────────┬────────────┬────────────────┬─────────────────┐\n",
      "│\u001b[1m CreditScore \u001b[0m│\u001b[1m Age        \u001b[0m│\u001b[1m Tenure     \u001b[0m│\u001b[1m Balance    \u001b[0m│\u001b[1m NumOfProducts \u001b[0m│\u001b[1m HasCrCard  \u001b[0m│\u001b[1m IsActiveMember \u001b[0m│\u001b[1m EstimatedSalary \u001b[0m│\n",
      "│\u001b[90m Int64       \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64       \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64        \u001b[0m│\u001b[90m Float64         \u001b[0m│\n",
      "│\u001b[90m Count       \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous    \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous     \u001b[0m│\u001b[90m Continuous      \u001b[0m│\n",
      "├─────────────┼────────────┼────────────┼────────────┼───────────────┼────────────┼────────────────┼─────────────────┤\n",
      "│ 669.0       │ 31.0       │ 6.0        │ 1.13001e5  │ 1.0           │ 1.0        │ 0.0            │ 40467.8         │\n",
      "│ 822.0       │ 37.0       │ 3.0        │ 105563.0   │ 1.0           │ 1.0        │ 0.0            │ 1.82625e5       │\n",
      "│ 423.0       │ 36.0       │ 5.0        │ 97665.6    │ 1.0           │ 1.0        │ 0.0            │ 1.18373e5       │\n",
      "│ 623.0       │ 21.0       │ 10.0       │ 0.0        │ 2.0           │ 0.0        │ 1.0            │ 1.35851e5       │\n",
      "│ 691.0       │ 37.0       │ 7.0        │ 1.23068e5  │ 1.0           │ 1.0        │ 1.0            │ 98162.4         │\n",
      "└─────────────┴────────────┴────────────┴────────────┴───────────────┴────────────┴────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "y, X = unpack(df, ==(:Exited); rng=123);\n",
    "first(X, 5) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95081762",
   "metadata": {},
   "source": [
    "Splitting the data into train and test portions is also easy using `MLJ`'s `partition` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e39afd",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalValue{Int64, UInt32}[0, 1, 1, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 1, 0, 0, 0, 0, 1, 0], CategoricalValue{Int64, UInt32}[0, 0, 0, 0, 0, 1, 1, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_inds, test_inds = partition(eachindex(y), 0.8, shuffle=true, rng=Random.Xoshiro(42))\n",
    "X_train, X_test = X[train_inds, :], X[test_inds, :]\n",
    "y_train, y_test = y[train_inds], y[test_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad9aad",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "\n",
    "\n",
    "\n",
    "Before deciding to oversample, let's see how adverse is the imbalance problem, if it exists. Ideally, you may as well check if the classification model is robust to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54542119",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ▇▇▇▇▇▇▇▇▇▇▇▇▇ 2037 (25.6%) \n",
      "0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 7963 (100.0%) \n"
     ]
    }
   ],
   "source": [
    "checkbalance(y)         # comes from Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b452b9",
   "metadata": {},
   "source": [
    "Looks like we have a class imbalance problem. Let's oversample with SMOTE and set the desired ratios so that the positive minority class is 90% of the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc2a40ef",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 5736 (90.0%) \n",
      "0: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 6373 (100.0%) \n"
     ]
    }
   ],
   "source": [
    "Xover, yover = smote(X_train, y_train; k=3, ratios=Dict(1=>0.9), rng=42)\n",
    "checkbalance(yover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb003c",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "\n",
    "\n",
    "Because we have scientific types setup, we can easily check what models will be able to train on our data. This should guarantee that the model we choose won't throw an error due to types after feeding it the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecf01e8c",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n",
       " (name = AdaBoostClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianLDA, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianQDA, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = CatBoostClassifier, package_name = CatBoost, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = BetaML, ... )\n",
       " ⋮\n",
       " (name = SGDClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVMLinearClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = SVMNuClassifier, package_name = MLJScikitLearnInterface, ... )\n",
       " (name = StableForestClassifier, package_name = SIRUS, ... )\n",
       " (name = StableRulesClassifier, package_name = SIRUS, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models(matching(Xover, yover))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29569bb3",
   "metadata": {},
   "source": [
    "Let's go for a logistic classifier form MLJLinearModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e5817",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add(\"MLJLinearModels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b88a0",
   "metadata": {},
   "source": [
    "### Before Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ce29f20",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: LogisticClassifier(lambda = 2.220446049250313e-16, …)\n",
       "  args: \n",
       "    1:\tSource @113 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}\n",
       "    2:\tSource @972 ⏎ AbstractVector{Multiclass{2}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load the model\n",
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0\n",
    "\n",
    "# 2. Instantiate it\n",
    "model = LogisticClassifier()\n",
    "\n",
    "# 3. Wrap it with the data in a machine\n",
    "mach = machine(model, X_train, y_train, scitype_check_level=0)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach, verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6f6d9",
   "metadata": {},
   "source": [
    "### After Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a8cd4b",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Wrap it with the data in a machine\n",
    "mach_over = machine(model, Xover, yover)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fefc08",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "\n",
    "\n",
    "To evaluate the model, we will use the balanced accuracy metric which equally account for all classes. \n",
    "\n",
    "### Before Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "947863ce",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = predict_mode(mach, X_test)                         \n",
    "\n",
    "score = round(balanced_accuracy(y_pred, y_test), digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced371d6",
   "metadata": {},
   "source": [
    "### After Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4861534d",
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_over = predict_mode(mach_over, X_test)\n",
    "\n",
    "score = round(balanced_accuracy(y_pred_over, y_test), digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80608d",
   "metadata": {},
   "source": [
    "## Evaluating the Model - Revisited\n",
    "\n",
    "We have previously evaluated the model using a single point estimate of the balanced accuracy resulting in a `7%` improvement. A more precise evaluation would use cross validation to combine many different point estimates into a more precise one (their average). The standard deviation among such point estimates also allows us to quantify the uncertainty of the estimate; a smaller standard deviation would imply a smaller confidence interval at the same probability.\n",
    "\n",
    "### Before Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abaec270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  50%[============>            ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds: 100%[=========================] Time: 0:00:00\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  model, measure, operation, measurement, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_rows, resampling, repeats\n",
       "Extract:\n",
       "┌─────────────────────┬──────────────┬─────────────┬──────────┬─────────────────\n",
       "│\u001b[22m measure             \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE  \u001b[0m│\u001b[22m per_fold      \u001b[0m ⋯\n",
       "├─────────────────────┼──────────────┼─────────────┼──────────┼─────────────────\n",
       "│ BalancedAccuracy(   │ predict_mode │ 0.5         │ 3.29e-16 │ [0.5, 0.5, 0.5 ⋯\n",
       "│   adjusted = false) │              │             │          │                ⋯\n",
       "└─────────────────────┴──────────────┴─────────────┴──────────┴─────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv=CV(nfolds=10)\n",
    "evaluate!(mach, resampling=cv, measure=balanced_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af3749",
   "metadata": {},
   "source": [
    "This looks good. Negligble standard deviation; point estimates are all centered around `0.5`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09215739",
   "metadata": {},
   "source": [
    "### After Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b30ec1",
   "metadata": {},
   "source": [
    "At first glance, this seems really nontrivial since resampling will have to be performed before training the model on each fold during cross-validation. Thankfully, the `MLJBalancing` helps us avoid doing this manually by offering `BalancedModel` where we can wrap any `MLJ` classification model with an arbitrary number of `Imbalance.jl` resamplers in a pipeline that behaves like a single `MLJ` model.\n",
    "\n",
    "In this, we must construct the resampling model via it's `MLJ` interface then pass it along with the classification model to `BalancedModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deaa9630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trained Machine; does not cache data\n",
       "  model: BalancedModelProbabilistic(model = LogisticClassifier(lambda = 2.220446049250313e-16, …), …)\n",
       "  args: \n",
       "    1:\tSource @991 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}\n",
       "    2:\tSource @939 ⏎ AbstractVector{Multiclass{2}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Instantiate the models\n",
    "oversampler = Imbalance.MLJ.SMOTE(k=3, ratios=Dict(1=>0.9), rng=42)\n",
    "\n",
    "# 2.1 Wrap them in one model\n",
    "balanced_model = BalancedModel(model=model, balancer1=oversampler)\n",
    "\n",
    "# 3. Wrap it with the data in a machine\n",
    "mach_over = machine(balanced_model, X_train, y_train, scitype_check_level=0)\n",
    "\n",
    "# 4. fit the machine learning model\n",
    "fit!(mach_over, verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588479e0",
   "metadata": {},
   "source": [
    "We can easily confirm that this is equivalent to what we had earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5093b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_mode(mach_over, X_test) == y_pred_over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c206d",
   "metadata": {},
   "source": [
    "Now let's cross-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d36b47dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  20%[=====>                   ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  50%[============>            ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  70%[=================>       ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds:  90%[======================>  ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 10 folds: 100%[=========================] Time: 0:00:00\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  model, measure, operation, measurement, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_rows, resampling, repeats\n",
       "Extract:\n",
       "┌─────────────────────┬──────────────┬─────────────┬─────────┬──────────────────\n",
       "│\u001b[22m measure             \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\u001b[22m per_fold       \u001b[0m ⋯\n",
       "├─────────────────────┼──────────────┼─────────────┼─────────┼──────────────────\n",
       "│ BalancedAccuracy(   │ predict_mode │ 0.552       │ 0.0145  │ [0.549, 0.563,  ⋯\n",
       "│   adjusted = false) │              │             │         │                 ⋯\n",
       "└─────────────────────┴──────────────┴─────────────┴─────────┴──────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv=CV(nfolds=10)\n",
    "evaluate!(mach_over, resampling=cv, measure=balanced_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3dafc",
   "metadata": {},
   "source": [
    "The improvement is about `5.2%` after cross-validation. If we are further to assume scores to be normally distributed, then the `95%` confidence interval is `5.2±1.45%` improvement. Let's see if this gets any better when we rather use `SMOTE-NC` in a later example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a1aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook smote_churn_dataset.ipynb to markdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno 2] No such file or directory: './assets'\n",
      "Conversion Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Writing 18812 bytes to smote_churn_dataset.md\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "from convert import convert_to_md\n",
    "convert_to_md('smote_churn_dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
